{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 217742,
     "status": "ok",
     "timestamp": 1599182954850,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "1l32f6OR7VJr",
    "outputId": "4c5ce303-6205-43dc-f5c2-1bbb7f2c5ad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at IEEE\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('IEEE')\n",
    "import os\n",
    " \n",
    "# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n",
    "os.chdir(\"IEEE/My Drive/IEEE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280,
     "status": "error",
     "timestamp": 1598529475609,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "Xv-dBHCzgEgS",
    "outputId": "575d899f-e758-45f6-efba-70020f60372c"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-835af91ab931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IEEE/My Drive/IEEE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'IEEE/My Drive/IEEE'"
     ]
    }
   ],
   "source": [
    "import os\n",
    " \n",
    "# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n",
    "os.chdir(\"IEEE/My Drive/IEEE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17168,
     "status": "error",
     "timestamp": 1597310396637,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "o-sMsEbsFtlh",
    "outputId": "d9d2e2dd-859b-4b70-abbf-44f23262eb75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f430bd00ceb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apt-get -y install -qq google-drive-ocamlfuse fuse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuthorizationError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mauthorization\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m   \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GOOGLE_APPLICATION_CREDENTIALS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_adc_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_check_adc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;31m# Avoid forcing a kernel restart on users updating google.auth if they haven't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m# yet used google.auth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_google_auth\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequests\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_auth_requests\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;31m# google-auth wants to warn the user if no project is set, which makes sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_recalculate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_fill_cache\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: '/content/IEEE/My Drive/IEEE'"
     ]
    }
   ],
   "source": [
    "#授权绑定下面的代码\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6557,
     "status": "ok",
     "timestamp": 1599182972600,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "4xKG8P5V7xeH",
    "outputId": "7b197094-f0e4-499c-a5fe-c7200587faaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==2.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
      "\r",
      "\u001b[K     |▋                               | 10kB 25.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 20kB 6.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 30kB 7.1MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 40kB 7.7MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 51kB 7.1MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 61kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 71kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 81kB 8.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 92kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 102kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 112kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 122kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 133kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 143kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 153kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 163kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 174kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 184kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 194kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 204kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 215kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 225kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 235kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 245kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 256kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 266kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 276kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 286kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 296kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 307kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 317kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 327kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 337kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 348kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 358kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 368kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 378kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 389kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 399kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 409kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 419kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 430kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 440kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 450kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 460kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 471kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 481kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 491kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 501kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 512kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 522kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 532kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 542kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 552kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 563kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 573kB 8.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (3.0.12)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 22.7MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 57.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 58.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.14.48)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.17.48)\n",
      "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->transformers==2.8.0) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=34eb25badec4fa63d516aa94d9160140564f0ce68d21c0dbaf08365f4b8103e1\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.5.2 transformers-2.8.0\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==2.8.0 pandas gensim scikit-learn filelock gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4799,
     "status": "ok",
     "timestamp": 1599182982733,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "b4xOEt5I75Ax",
    "outputId": "fbc49fd7-ef82-4cb6-9201-0e78639edfc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import datetime\n",
    "import pickle\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "middlef='middle/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3F0z9MFS8Gua"
   },
   "outputs": [],
   "source": [
    "milestones=pd.read_csv(\"data/IBI_case_milestones_anonymized.csv\")\n",
    "case_status=pd.read_csv(\"data/IBI_case_status_history_v2.csv\")\n",
    "test_cases=pd.read_csv(\"data/IBI_test_cases_no_target.csv\")\n",
    "del test_cases['INV_TIME_TO_NEXT_ESCALATION']\n",
    "test=pd.merge(test_cases, case_status, on=['REFERENCEID', 'SECONDS_SINCE_CASE_START'])\n",
    "caset=case_status[~case_status['INV_TIME_TO_NEXT_ESCALATION'].isnull()]\n",
    "#把重大事件表划分为测试和训练两部分\n",
    "milestones_train=milestones[milestones['REFERENCEID'].isin(caset['REFERENCEID'])]\n",
    "milestones_test=milestones[milestones['REFERENCEID'].isin(test['REFERENCEID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46Fxk8rg8k68"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "def getmilevector(df,istrain,needfit,n_fea):\n",
    "    \"\"\"\n",
    "    塞进来一个包含短文本的dataframe,把每个文本转换成n_fea维的向量，\n",
    "    istrain决定是否训练，needfit为包含短文本描述的列\n",
    "    返回一个dataframe，多出来了文本得到的向量\n",
    "    \"\"\"\n",
    "    feature=[]\n",
    "    for col in needfit:\n",
    "        doc=df[col]\n",
    "        \n",
    "        if istrain:\n",
    "            tfidf_vec = TfidfVectorizer(ngram_range=(1,2),analyzer='word',smooth_idf=1)\n",
    "            discuss_tf  = tfidf_vec.fit_transform(doc)\n",
    "            pickle.dump(tfidf_vec, open(col+\".pickle\", \"wb\"))\n",
    "\n",
    "            svd_tag_tmp = TruncatedSVD(n_components=n_fea, n_iter=20, random_state=2019)\n",
    "            tag_svd_tmp = svd_tag_tmp.fit_transform(discuss_tf )\n",
    "            pickle.dump(svd_tag_tmp, open(col+\"svd_tag_tmp.pickle\", \"wb\"))\n",
    "        else:\n",
    "            tfidf_vec = pickle.load(open(col+\".pickle\" ,\"rb\"))\n",
    "            discuss_tf  =tfidf_vec.transform(doc)\n",
    "\n",
    "            svd_tag_tmp = pickle.load(open(col+\"svd_tag_tmp.pickle\", \"rb\"))\n",
    "            tag_svd_tmp = svd_tag_tmp.transform(discuss_tf)\n",
    "        tag_svd_tmp = pd.DataFrame(tag_svd_tmp)\n",
    "        tag_svd_tmp.columns = [col+f'b_svd_{i}' for i in range(n_fea)]    \n",
    "        feature.append(tag_svd_tmp)\n",
    "    vecfeature=pd.concat(feature,axis=1)\n",
    "    df1=df.reset_index()\n",
    "    df2=pd.concat([df1,vecfeature],axis=1)\n",
    "    return df2\n",
    "\n",
    "mt=getmilevector(milestones_train,True,['MILESTONEDESCRIPTION','NOTEDESCRIPTION'],40)\n",
    "mtest=getmilevector(milestones_test,False,['MILESTONEDESCRIPTION','NOTEDESCRIPTION'],40)\n",
    "def changeOthertodigital(df,istrain):\n",
    "    del df['index']\n",
    "    del df['MILESTONEDESCRIPTION']\n",
    "    del df['NOTEDESCRIPTION']\n",
    "    df['UPDATED_BY']=df['UPDATED_BY'].astype('category')\n",
    "    df['CREATED_BY']=df['CREATED_BY'].astype('category')\n",
    "    if istrain:\n",
    "        usrlist=list(set(list(milestones['UPDATED_BY'])+list(milestones['CREATED_BY'])))\n",
    "        usermap={v:i for i,v in enumerate(usrlist)}\n",
    "        pickle.dump(usermap, open(\"usermap.pickle\", \"wb\"))\n",
    "    else:\n",
    "        usermap = pickle.load(open(\"usermap.pickle\", \"rb\"))\n",
    "    \n",
    "    df['UPDATED_BY']=df['UPDATED_BY'].map(usermap)\n",
    "    df['CREATED_BY']=df['CREATED_BY'].map(usermap)\n",
    "    df=df.rename(columns = {\"SECONDS_SINCE_CASE_START\": \"milestone_SECONDS_SINCE_CASE_START\"})\n",
    "    df=df.rename(columns = {\"CREATED_BY\": \"milestone_CREATED_BY\"})\n",
    "    df=df.rename(columns = {\"UPDATED_BY\": \"milestone_UPDATED_BY\"})\n",
    "    return df\n",
    "mt=changeOthertodigital(mt,True)\n",
    "mtest=changeOthertodigital(mtest,False)\n",
    "\n",
    "mt.to_csv(middlef+\"miilestone_fortrain_digitle.csv\",index=False)\n",
    "mtest.to_csv(middlef+\"miilestone_fortest_digitle.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4248,
     "status": "ok",
     "timestamp": 1599182999163,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "BcDW9EygD0Fx",
    "outputId": "f64feab8-e322-4f9a-a51f-284fc03cb8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandarallel\n",
      "  Downloading https://files.pythonhosted.org/packages/62/30/3c2c89597bb01b75779432d469562a235c47538cf96152ed01d695ad41ce/pandarallel-1.5.1.tar.gz\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from pandarallel) (0.3.2)\n",
      "Building wheels for collected packages: pandarallel\n",
      "  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pandarallel: filename=pandarallel-1.5.1-cp36-none-any.whl size=17126 sha256=c512c5e8b9dec3e5e36493414254a98968bfa4739058cf855269ad493e1e3b37\n",
      "  Stored in directory: /root/.cache/pip/wheels/6f/c8/e5/d43fa63105ce1dd22f4df51bc2edfefd54d92ce64f25326314\n",
      "Successfully built pandarallel\n",
      "Installing collected packages: pandarallel\n",
      "Successfully installed pandarallel-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4McqFqzavZOS"
   },
   "outputs": [],
   "source": [
    "mt=pd.read_csv(middlef+\"miilestone_fortrain_digitle.csv\")\n",
    "mtest=pd.read_csv(middlef+\"miilestone_fortest_digitle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 353278,
     "status": "ok",
     "timestamp": 1596854167807,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "VhLbLU719k5l",
    "outputId": "6cf0c1be-634d-4ad7-a56c-b51ada5b2f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "\n",
    "def getsquen(x,tmt,columsbase):\n",
    "    caseID=x['REFERENCEID']\n",
    "    escalatedTime=x['SECONDS_SINCE_CASE_START']\n",
    "    if caseID in tmt:\n",
    "        milestonsession=tmt[caseID]\n",
    "    else:\n",
    "        milestonsession=pd.DataFrame(columns=columsbase)\n",
    "    #     print(type(escalatedTime))\n",
    "    milestonsession['neartime']=escalatedTime-milestonsession['milestone_SECONDS_SINCE_CASE_START']\n",
    "    milestonsession=milestonsession[milestonsession['neartime']>=0 ]#position embeding用\n",
    "    #拿些统计特征 序列 size,milestoneID unique,时间的unique，事件次数的sum,mean,std\n",
    "    sqe_size=len(milestonsession)\n",
    "    miles_unique=milestonsession['MILESTONEID'].nunique()\n",
    "    time_unique=milestonsession['milestone_SECONDS_SINCE_CASE_START'].nunique()\n",
    "    tmp=milestonsession['MILESTONEID'].value_counts()\n",
    "    milestone_times_sum=tmp.sum()\n",
    "    milestone_times_mean=tmp.mean()\n",
    "    milestone_times_std=tmp.std()\n",
    "    #拿到相应的时序序列，以及时间序列\n",
    "    milestone_seq=' '.join(list(milestonsession['MILESTONEID'].apply(str)))\n",
    "    time_seq=' '.join(list(milestonsession['neartime'].apply(str)))\n",
    "    return pd.Series({'REFERENCEID':caseID,'SECONDS_SINCE_CASE_START':escalatedTime,'milestone_seq':milestone_seq,'time_seq':time_seq,\n",
    "                      'CREATED_BY_seq':' '.join(list(milestonsession['milestone_CREATED_BY'].apply(str))),'UPDATED_BY_seq':' '.join(list(milestonsession['milestone_UPDATED_BY'].apply(str))),\n",
    "                   'milestones_size':sqe_size,'milestones_unique':miles_unique,'time_unique':time_unique,\n",
    "                    'milestone_times_sum':milestone_times_sum,'milestone_times_mean':milestone_times_mean,'milestone_times_std':milestone_times_std})\n",
    "     \n",
    "tmt={name:group for name, group in mt.groupby(mt['REFERENCEID'])}\n",
    "train_featurelist=caset.parallel_apply(lambda x:getsquen(x,tmt,mt.columns),axis=1)\n",
    "tmtest={name:group for name, group in mtest.groupby(mtest['REFERENCEID'])}\n",
    "test_featurelist=test.parallel_apply(lambda x:getsquen(x,tmtest,mtest.columns),axis=1)\n",
    "\n",
    "################################################################################\n",
    "print(\"Extract features done! saving data...\")\n",
    "train_featurelist.to_pickle(middlef+'train_milestone_sque.pkl')#dataframe for train\n",
    "test_featurelist.to_pickle(middlef+'test_milestone_sque.pkl')#dataframe for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20733,
     "status": "ok",
     "timestamp": 1596942584138,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "VbDEnOWM5Ldu",
    "outputId": "cfad6ed3-80f2-462e-9de2-88edf43fe8f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: middle/train_milestone_sque.pkl (deflated 82%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r a1.zip  middle/train_milestone_sque.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35067,
     "status": "ok",
     "timestamp": 1597891467870,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "W5xfVhPAqTJY",
    "outputId": "bc732d20-ad41-445e-be82-52078d2c6e37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (16,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_pickle('middle/train_milestone_sque.pkl')#这里面是序列化的数据\n",
    "test_df=pd.read_pickle('middle/test_milestone_sque.pkl')\n",
    "mytrain=pd.read_csv(\"middle/train.csv\")#这里面是最原始的按referrenceId和time做主键的数据\n",
    "mytest=pd.read_csv(\"middle/test.csv\")\n",
    "del mytrain['Unnamed: 0']\n",
    "del mytest['Unnamed: 0']\n",
    "allfeature=list(mytrain.columns)\n",
    "allfeature.remove('INV_TIME_TO_NEXT_ESCALATION')\n",
    "allfeature.remove('CLOUD')\n",
    "\n",
    "newtrain=pd.read_csv(\"middle/train_data.csv\")#这里面是最原始的按referrenceId做主键,按baseline处理得到的数据\n",
    "newtest=pd.read_csv(\"middle/test_data.csv\")\n",
    "res_ids=list(newtrain['REFERENCEID'].unique())\n",
    "test_ids=list(newtest['REFERENCEID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygFEA59-wljF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yySDy7GFxjfi"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('middle/densefeature.pkl', 'wb') as file:\n",
    "    pickle.dump(allfeature, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 962,
     "status": "ok",
     "timestamp": 1597196714771,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "SqhVMh_kVtMH",
    "outputId": "12441c9e-e6ee-40e5-ec17-e061a9f18a04"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REFERENCEID</th>\n",
       "      <th>SECONDS_SINCE_CASE_START</th>\n",
       "      <th>milestone_seq</th>\n",
       "      <th>time_seq</th>\n",
       "      <th>CREATED_BY_seq</th>\n",
       "      <th>UPDATED_BY_seq</th>\n",
       "      <th>milestones_size</th>\n",
       "      <th>milestones_unique</th>\n",
       "      <th>time_unique</th>\n",
       "      <th>milestone_times_sum</th>\n",
       "      <th>milestone_times_mean</th>\n",
       "      <th>milestone_times_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>137780</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      REFERENCEID  ...  milestone_times_std\n",
       "8467       137780  ...                  NaN\n",
       "\n",
       "[1 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['milestones_size']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1597054952706,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "3KvZ6Jud00qL",
    "outputId": "cc6cbea6-2066-4300-d35d-8debcb1bf00c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REFERENCEID</th>\n",
       "      <th>SECONDS_SINCE_CASE_START</th>\n",
       "      <th>milestone_seq</th>\n",
       "      <th>time_seq</th>\n",
       "      <th>CREATED_BY_seq</th>\n",
       "      <th>UPDATED_BY_seq</th>\n",
       "      <th>milestones_size</th>\n",
       "      <th>milestones_unique</th>\n",
       "      <th>time_unique</th>\n",
       "      <th>milestone_times_sum</th>\n",
       "      <th>milestone_times_mean</th>\n",
       "      <th>milestone_times_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1 12</td>\n",
       "      <td>0.0 0.0</td>\n",
       "      <td>54 54</td>\n",
       "      <td>54 54</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>1 12 36 35</td>\n",
       "      <td>2114.0 2114.0 0.0 0.0</td>\n",
       "      <td>54 54 433 433</td>\n",
       "      <td>54 54 433 433</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REFERENCEID  ...  milestone_times_std\n",
       "0       100001  ...                  0.0\n",
       "1       100001  ...                  0.0\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SG5AGXRLqy79"
   },
   "outputs": [],
   "source": [
    "alldata=mytrain.append(mytest)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for name,dtype in mytrain.dtypes.iteritems():\n",
    "  try:\n",
    "    if dtype=='object':\n",
    "      encoder = LabelEncoder().fit(alldata[name])   \n",
    "      mytrain[name]=encoder.transform(mytrain[name])\n",
    "      # print(mytrain[name])\n",
    "      mytest[name]=encoder.transform(mytest[name])\n",
    "  except:\n",
    "    alldata[name]=alldata[name].astype(str)\n",
    "    mytrain[name]=mytrain[name].astype(str)\n",
    "    mytest[name]=mytest[name].astype(str)\n",
    "    encoder = LabelEncoder().fit(alldata[name])\n",
    "    mytrain[name]=encoder.transform(mytrain[name])\n",
    "    mytest[name]=encoder.transform(mytest[name])\n",
    "\n",
    "mytrain=mytrain.dropna(subset=['milestone_SECONDS_SINCE_CASE_START'])\n",
    "mytrain=mytrain.dropna(subset=['comments_SECONDS_SINCE_CASE_START'])\n",
    "alltrain=pd.merge(mytrain,train_df,on=['REFERENCEID','SECONDS_SINCE_CASE_START'])\n",
    "alltest=pd.merge(mytest,test_df,on=['REFERENCEID','SECONDS_SINCE_CASE_START'])\n",
    "alltrain.to_pickle(middlef+'train_all.pkl')#dataframe for train\n",
    "alltest.to_pickle(middlef+'test_all.pkl')#dataframe for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1378,
     "status": "ok",
     "timestamp": 1597892601960,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "imD_LD92wzAw",
    "outputId": "a36ca5f0-e612-4026-d853-3c205152e1fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIMARYPRODUCTOSPLATFORMID\n"
     ]
    }
   ],
   "source": [
    "needcolums=[]\n",
    "for c in allfeature:\n",
    "  if alltrain[c].isnull().any():\n",
    "    needcolums.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25363,
     "status": "ok",
     "timestamp": 1597197016087,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "8m9qbFzztgl3",
    "outputId": "24e6b664-5075-409c-940e-54fe63b13b65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: middle/train_all.pkl (deflated 91%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r a1.zip  middle/train_all.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4458,
     "status": "ok",
     "timestamp": 1597201015197,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "nlapqT8sk0_Y",
    "outputId": "9ca5a9ee-203a-4d6e-ee4f-f94eb4236341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Bert.zip\n",
      "   creating: Bert/__pycache__/\n",
      "  inflating: Bert/__pycache__/model.cpython-37.pyc  \n",
      "  inflating: Bert/model.py           \n",
      "  inflating: Bert/run.py             \n",
      "   creating: Bert/saved_models/\n"
     ]
    }
   ],
   "source": [
    "!unzip Bert.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27FifOC9m0bd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2426,
     "status": "ok",
     "timestamp": 1597055218943,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "DzjIjQpYraif",
    "outputId": "c9ccb16b-274a-4e78-ca45-8d79ac31d92a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REFERENCEID</th>\n",
       "      <th>SITECODE</th>\n",
       "      <th>SITENAME</th>\n",
       "      <th>CONTACTCOMPANY</th>\n",
       "      <th>COMPANYID</th>\n",
       "      <th>COMPANYOID</th>\n",
       "      <th>INITIALUSERGROUPID</th>\n",
       "      <th>INITIALUSERGROUPDESC</th>\n",
       "      <th>MEDPROJECTID</th>\n",
       "      <th>MEDPROJECTAREA</th>\n",
       "      <th>MEDPROJOPENBY</th>\n",
       "      <th>IWAYJIRAISSUEID</th>\n",
       "      <th>NEWIWAYJIRAISSUEID</th>\n",
       "      <th>PREMIUMCODE</th>\n",
       "      <th>PRIMARYPRODUCTFAMILYID</th>\n",
       "      <th>PRIMARYPRODUCTFAMILYDESC</th>\n",
       "      <th>PRIMARYPRODUCTID</th>\n",
       "      <th>PRIMARYPRODUCTDESC</th>\n",
       "      <th>PRIMARYRELEASEID</th>\n",
       "      <th>PRIMARYRELEASEDESC</th>\n",
       "      <th>PRIMARYPRODUCTAREAID</th>\n",
       "      <th>PRIMARYPRODUCTAREADESC</th>\n",
       "      <th>PRIMARYPRODUCTOSFAMILYID</th>\n",
       "      <th>PRIMARYPRODUCTOSFAMILYDESC</th>\n",
       "      <th>PRIMARYPRODUCTOSPLATFORMID</th>\n",
       "      <th>PRIMARYPRODUCTOSPLATFORMDESC</th>\n",
       "      <th>CONTACTMETHODFLAG</th>\n",
       "      <th>CUSTOMERFIRST</th>\n",
       "      <th>CUSTOMERMIDDLE</th>\n",
       "      <th>CUSTOMERLAST</th>\n",
       "      <th>CUSTOMERNAME</th>\n",
       "      <th>CONTACTPHONE</th>\n",
       "      <th>CONTACTMOBILEPHONE</th>\n",
       "      <th>CONTACTEMAIL</th>\n",
       "      <th>IBICUSTOMERFIRST</th>\n",
       "      <th>IBICUSTOMERMI</th>\n",
       "      <th>IBICUSTOMERLAST</th>\n",
       "      <th>IBICUSTOMERNAME</th>\n",
       "      <th>IBIPHONE</th>\n",
       "      <th>IBIMOBILE</th>\n",
       "      <th>IBIEMAIL</th>\n",
       "      <th>CUSTOMERLABEL</th>\n",
       "      <th>BRANCHCODE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AGENT_ID</th>\n",
       "      <th>AGENT_NAME</th>\n",
       "      <th>ASM_NAME</th>\n",
       "      <th>SITECOMPANYNAME</th>\n",
       "      <th>SITECOMPANY_OID</th>\n",
       "      <th>SITECOMPANYID</th>\n",
       "      <th>PRIMARYPRODUCTVERSION</th>\n",
       "      <th>CLOUD</th>\n",
       "      <th>CASENUM</th>\n",
       "      <th>PROJNUM</th>\n",
       "      <th>IWAYJIRA</th>\n",
       "      <th>PNOTARGET</th>\n",
       "      <th>PNOCRITICALUSER</th>\n",
       "      <th>ISPREMIUM</th>\n",
       "      <th>CUSTOMER_NAME</th>\n",
       "      <th>CUSTOMER_LABEL</th>\n",
       "      <th>GLOBAL_ID</th>\n",
       "      <th>CUSTOMER_PHASE</th>\n",
       "      <th>P1PHONE</th>\n",
       "      <th>SITEINSTALLYEAR</th>\n",
       "      <th>SECONDS_SINCE_CASE_START</th>\n",
       "      <th>SEVERITY</th>\n",
       "      <th>ISESCALATE</th>\n",
       "      <th>INV_TIME_TO_NEXT_ESCALATION</th>\n",
       "      <th>formerbugtimes</th>\n",
       "      <th>formercomtimes</th>\n",
       "      <th>milestone_seq</th>\n",
       "      <th>time_seq</th>\n",
       "      <th>CREATED_BY_seq</th>\n",
       "      <th>UPDATED_BY_seq</th>\n",
       "      <th>milestones_size</th>\n",
       "      <th>milestones_unique</th>\n",
       "      <th>time_unique</th>\n",
       "      <th>milestone_times_sum</th>\n",
       "      <th>milestone_times_mean</th>\n",
       "      <th>milestone_times_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>1302</td>\n",
       "      <td>935</td>\n",
       "      <td>973</td>\n",
       "      <td>932</td>\n",
       "      <td>595</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>653</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>78</td>\n",
       "      <td>89</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>169.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1664</td>\n",
       "      <td>51</td>\n",
       "      <td>461</td>\n",
       "      <td>1454</td>\n",
       "      <td>1423</td>\n",
       "      <td>278</td>\n",
       "      <td>284</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>1199</td>\n",
       "      <td>72</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>853</td>\n",
       "      <td>506</td>\n",
       "      <td>114</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31295</td>\n",
       "      <td>2839</td>\n",
       "      <td>172</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1583</td>\n",
       "      <td>10096</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>1532</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1 12</td>\n",
       "      <td>0.0 0.0</td>\n",
       "      <td>54 54</td>\n",
       "      <td>54 54</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>1302</td>\n",
       "      <td>935</td>\n",
       "      <td>973</td>\n",
       "      <td>932</td>\n",
       "      <td>595</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>653</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>78</td>\n",
       "      <td>89</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>169.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1664</td>\n",
       "      <td>51</td>\n",
       "      <td>461</td>\n",
       "      <td>1454</td>\n",
       "      <td>1423</td>\n",
       "      <td>278</td>\n",
       "      <td>284</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>1199</td>\n",
       "      <td>72</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>853</td>\n",
       "      <td>506</td>\n",
       "      <td>114</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31295</td>\n",
       "      <td>2839</td>\n",
       "      <td>172</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1583</td>\n",
       "      <td>10096</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>1532</td>\n",
       "      <td>2013</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 12 36 35</td>\n",
       "      <td>2114.0 2114.0 0.0 0.0</td>\n",
       "      <td>54 54 433 433</td>\n",
       "      <td>54 54 433 433</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REFERENCEID  SITECODE  ...  milestone_times_mean  milestone_times_std\n",
       "0       100001      1302  ...                   1.0                  0.0\n",
       "1       100001      1302  ...                   1.0                  0.0\n",
       "\n",
       "[2 rows x 80 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plQsBfqZIqsR"
   },
   "outputs": [],
   "source": [
    "alltrain['nescated']=alltrain.parallel_apply(lambda x: 0 if x['INV_TIME_TO_NEXT_ESCALATION']==0 else 1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 322718,
     "status": "ok",
     "timestamp": 1597998415224,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "jiO_lyREhxBs",
    "outputId": "c1fe6589-de94-4b14-e287-17ab79db37d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v milestone_seq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/21/2020 08:22:07 - INFO - gensim.models.word2vec -   collecting all words and their counts\n",
      "08/21/2020 08:22:07 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "08/21/2020 08:22:07 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #10000, processed 253166 words, keeping 58 word types\n",
      "08/21/2020 08:22:07 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #20000, processed 463255 words, keeping 59 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #30000, processed 654538 words, keeping 62 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #40000, processed 859787 words, keeping 62 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #50000, processed 1090795 words, keeping 62 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #60000, processed 1300595 words, keeping 63 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Num 720924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #70000, processed 1495792 words, keeping 64 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #80000, processed 1691255 words, keeping 64 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #90000, processed 1871970 words, keeping 64 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #100000, processed 2044905 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #110000, processed 2235888 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #120000, processed 2450267 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #130000, processed 2631056 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #140000, processed 2847702 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #150000, processed 3051075 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #160000, processed 3261944 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #170000, processed 3468793 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #180000, processed 3648499 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #190000, processed 3872120 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #200000, processed 4089524 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #210000, processed 4285801 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #220000, processed 4486835 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #230000, processed 4698869 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #240000, processed 4896532 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #250000, processed 5092070 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #260000, processed 5288337 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #270000, processed 5486555 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #280000, processed 5686075 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #290000, processed 5856127 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #300000, processed 6068771 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #310000, processed 6261154 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #320000, processed 6466914 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #330000, processed 6656830 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #340000, processed 6877273 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #350000, processed 7059156 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #360000, processed 7238260 words, keeping 65 word types\n",
      "08/21/2020 08:22:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #370000, processed 7414528 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #380000, processed 7592132 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #390000, processed 7784320 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #400000, processed 7979436 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #410000, processed 8176514 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #420000, processed 8385745 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #430000, processed 8598276 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #440000, processed 8808814 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #450000, processed 8989847 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #460000, processed 9184403 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #470000, processed 9360158 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #480000, processed 9554464 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #490000, processed 9725976 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #500000, processed 9903270 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #510000, processed 10116322 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #520000, processed 10298790 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #530000, processed 10518470 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #540000, processed 10713688 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #550000, processed 10941425 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #560000, processed 11145934 words, keeping 65 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #570000, processed 11356832 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #580000, processed 11595837 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #590000, processed 11802406 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #600000, processed 11996163 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #610000, processed 12209361 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #620000, processed 12403990 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #630000, processed 12595419 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #640000, processed 12775493 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #650000, processed 12951363 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #660000, processed 13131967 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #670000, processed 13309378 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #680000, processed 13539557 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #690000, processed 13722575 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #700000, processed 13932816 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #710000, processed 14091582 words, keeping 67 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #720000, processed 14202631 words, keeping 68 word types\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   collected 68 word types from a corpus of 14212917 raw words and 720924 sentences\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   Loading a fresh vocabulary\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   effective_min_count=1 retains 68 unique words (100% of original 68, drops 0)\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   effective_min_count=1 leaves 14212917 word corpus (100% of original 14212917, drops 0)\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   deleting the raw counts dictionary of 68 items\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   sample=0.001 downsamples 29 most-common words\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   downsampling leaves estimated 2688223 word corpus (18.9% of prior 14212917)\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.base_any2vec -   estimated required memory for 68 words and 128 dimensions: 103632 bytes\n",
      "08/21/2020 08:22:09 - INFO - gensim.models.word2vec -   resetting layer weights\n",
      "08/21/2020 08:22:10 - INFO - gensim.models.base_any2vec -   training model with 16 workers on 68 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "08/21/2020 08:22:11 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 13.95% examples, 381212 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:22:12 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 29.24% examples, 395680 words/s, in_qsize 32, out_qsize 6\n",
      "08/21/2020 08:22:13 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 44.52% examples, 402113 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:14 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 59.77% examples, 403327 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:22:15 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 75.32% examples, 403789 words/s, in_qsize 28, out_qsize 3\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 90.37% examples, 405055 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:22:16 - INFO - gensim.models.base_any2vec -   EPOCH - 1 : training on 14212917 raw words (2687667 effective words) took 6.6s, 405343 effective words/s\n",
      "08/21/2020 08:22:17 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 13.78% examples, 381231 words/s, in_qsize 32, out_qsize 4\n",
      "08/21/2020 08:22:18 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 28.50% examples, 389860 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:22:19 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 43.60% examples, 395039 words/s, in_qsize 26, out_qsize 5\n",
      "08/21/2020 08:22:20 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 59.28% examples, 400230 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:21 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 75.16% examples, 404217 words/s, in_qsize 31, out_qsize 1\n",
      "08/21/2020 08:22:22 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 89.83% examples, 404143 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:22:23 - INFO - gensim.models.base_any2vec -   EPOCH - 2 : training on 14212917 raw words (2689321 effective words) took 6.6s, 404844 effective words/s\n",
      "08/21/2020 08:22:24 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 14.21% examples, 392124 words/s, in_qsize 30, out_qsize 0\n",
      "08/21/2020 08:22:25 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 28.73% examples, 395234 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:26 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 43.60% examples, 396098 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:27 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 58.97% examples, 399078 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:28 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 74.22% examples, 399791 words/s, in_qsize 30, out_qsize 0\n",
      "08/21/2020 08:22:29 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 88.49% examples, 398946 words/s, in_qsize 32, out_qsize 3\n",
      "08/21/2020 08:22:29 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:22:29 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:22:29 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:22:29 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:22:29 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:22:30 - INFO - gensim.models.base_any2vec -   EPOCH - 3 : training on 14212917 raw words (2689089 effective words) took 6.7s, 401894 effective words/s\n",
      "08/21/2020 08:22:31 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 14.15% examples, 390504 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:22:32 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 28.66% examples, 394898 words/s, in_qsize 31, out_qsize 1\n",
      "08/21/2020 08:22:33 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 42.81% examples, 388968 words/s, in_qsize 25, out_qsize 6\n",
      "08/21/2020 08:22:34 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 58.59% examples, 394708 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:35 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 74.74% examples, 401122 words/s, in_qsize 28, out_qsize 0\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 89.25% examples, 400626 words/s, in_qsize 32, out_qsize 1\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:22:36 - INFO - gensim.models.base_any2vec -   EPOCH - 4 : training on 14212917 raw words (2689141 effective words) took 6.7s, 400564 effective words/s\n",
      "08/21/2020 08:22:37 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 14.20% examples, 390430 words/s, in_qsize 31, out_qsize 1\n",
      "08/21/2020 08:22:38 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 28.74% examples, 395494 words/s, in_qsize 32, out_qsize 4\n",
      "08/21/2020 08:22:39 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 44.01% examples, 401417 words/s, in_qsize 32, out_qsize 1\n",
      "08/21/2020 08:22:40 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 58.96% examples, 399837 words/s, in_qsize 29, out_qsize 10\n",
      "08/21/2020 08:22:41 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 75.10% examples, 405372 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:42 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 89.40% examples, 402892 words/s, in_qsize 32, out_qsize 3\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:22:43 - INFO - gensim.models.base_any2vec -   EPOCH - 5 : training on 14212917 raw words (2686535 effective words) took 6.6s, 405155 effective words/s\n",
      "08/21/2020 08:22:44 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 14.16% examples, 385066 words/s, in_qsize 32, out_qsize 2\n",
      "08/21/2020 08:22:45 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 29.07% examples, 395565 words/s, in_qsize 29, out_qsize 0\n",
      "08/21/2020 08:22:46 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 43.48% examples, 392392 words/s, in_qsize 28, out_qsize 3\n",
      "08/21/2020 08:22:47 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 59.21% examples, 398887 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:48 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 74.48% examples, 396804 words/s, in_qsize 32, out_qsize 2\n",
      "08/21/2020 08:22:49 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 89.64% examples, 400357 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:22:50 - INFO - gensim.models.base_any2vec -   EPOCH - 6 : training on 14212917 raw words (2687424 effective words) took 6.7s, 401569 effective words/s\n",
      "08/21/2020 08:22:51 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 14.12% examples, 389453 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:22:52 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 29.25% examples, 402618 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:53 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 44.00% examples, 401005 words/s, in_qsize 31, out_qsize 4\n",
      "08/21/2020 08:22:54 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 59.49% examples, 404201 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:55 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 75.10% examples, 405719 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 89.52% examples, 403714 words/s, in_qsize 32, out_qsize 2\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:22:56 - INFO - gensim.models.base_any2vec -   EPOCH - 7 : training on 14212917 raw words (2687442 effective words) took 6.6s, 405231 effective words/s\n",
      "08/21/2020 08:22:57 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 14.49% examples, 399537 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:22:58 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 29.18% examples, 396477 words/s, in_qsize 32, out_qsize 4\n",
      "08/21/2020 08:22:59 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 44.02% examples, 397571 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:23:00 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 59.51% examples, 398554 words/s, in_qsize 32, out_qsize 2\n",
      "08/21/2020 08:23:01 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 75.37% examples, 402778 words/s, in_qsize 31, out_qsize 2\n",
      "08/21/2020 08:23:02 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 89.90% examples, 400567 words/s, in_qsize 27, out_qsize 4\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:23:03 - INFO - gensim.models.base_any2vec -   EPOCH - 8 : training on 14212917 raw words (2688876 effective words) took 6.7s, 403155 effective words/s\n",
      "08/21/2020 08:23:04 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 13.77% examples, 379830 words/s, in_qsize 32, out_qsize 3\n",
      "08/21/2020 08:23:05 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 28.38% examples, 389861 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:06 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 43.11% examples, 391059 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:23:07 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 58.72% examples, 396423 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:08 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 73.92% examples, 396609 words/s, in_qsize 31, out_qsize 6\n",
      "08/21/2020 08:23:09 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 88.11% examples, 395074 words/s, in_qsize 32, out_qsize 3\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:23:10 - INFO - gensim.models.base_any2vec -   EPOCH - 9 : training on 14212917 raw words (2687853 effective words) took 6.8s, 397530 effective words/s\n",
      "08/21/2020 08:23:11 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 13.77% examples, 369348 words/s, in_qsize 25, out_qsize 6\n",
      "08/21/2020 08:23:12 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 28.65% examples, 389418 words/s, in_qsize 31, out_qsize 3\n",
      "08/21/2020 08:23:13 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 43.46% examples, 392973 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:14 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 58.67% examples, 395203 words/s, in_qsize 29, out_qsize 0\n",
      "08/21/2020 08:23:15 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 73.85% examples, 394858 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:16 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 88.40% examples, 394804 words/s, in_qsize 25, out_qsize 5\n",
      "08/21/2020 08:23:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:23:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:23:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:23:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:23:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:23:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   EPOCH - 10 : training on 14212917 raw words (2689931 effective words) took 6.7s, 398948 effective words/s\n",
      "08/21/2020 08:23:17 - INFO - gensim.models.base_any2vec -   training on a 142129170 raw words (26883279 effective words) took 67.0s, 401222 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save w2v to word2vecf/milestone_seq.128d\n",
      "w2v CREATED_BY_seq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   collecting all words and their counts\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #10000, processed 253166 words, keeping 205 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #20000, processed 463255 words, keeping 269 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #30000, processed 654538 words, keeping 310 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #40000, processed 859787 words, keeping 348 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #50000, processed 1090795 words, keeping 377 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #60000, processed 1300595 words, keeping 397 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Num 720924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #70000, processed 1495792 words, keeping 415 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #80000, processed 1691255 words, keeping 436 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #90000, processed 1871970 words, keeping 453 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #100000, processed 2044905 words, keeping 466 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #110000, processed 2235888 words, keeping 472 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #120000, processed 2450267 words, keeping 482 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #130000, processed 2631056 words, keeping 491 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #140000, processed 2847702 words, keeping 504 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #150000, processed 3051075 words, keeping 511 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #160000, processed 3261944 words, keeping 520 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #170000, processed 3468793 words, keeping 528 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #180000, processed 3648499 words, keeping 531 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #190000, processed 3872120 words, keeping 543 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #200000, processed 4089524 words, keeping 549 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #210000, processed 4285801 words, keeping 554 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #220000, processed 4486835 words, keeping 558 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #230000, processed 4698869 words, keeping 565 word types\n",
      "08/21/2020 08:23:19 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #240000, processed 4896532 words, keeping 571 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #250000, processed 5092070 words, keeping 578 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #260000, processed 5288337 words, keeping 583 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #270000, processed 5486555 words, keeping 585 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #280000, processed 5686075 words, keeping 586 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #290000, processed 5856127 words, keeping 589 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #300000, processed 6068771 words, keeping 596 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #310000, processed 6261154 words, keeping 599 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #320000, processed 6466914 words, keeping 603 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #330000, processed 6656830 words, keeping 607 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #340000, processed 6877273 words, keeping 610 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #350000, processed 7059156 words, keeping 610 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #360000, processed 7238260 words, keeping 615 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #370000, processed 7414528 words, keeping 617 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #380000, processed 7592132 words, keeping 620 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #390000, processed 7784320 words, keeping 622 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #400000, processed 7979436 words, keeping 623 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #410000, processed 8176514 words, keeping 625 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #420000, processed 8385745 words, keeping 625 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #430000, processed 8598276 words, keeping 629 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #440000, processed 8808814 words, keeping 631 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #450000, processed 8989847 words, keeping 634 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #460000, processed 9184403 words, keeping 635 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #470000, processed 9360158 words, keeping 639 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #480000, processed 9554464 words, keeping 641 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #490000, processed 9725976 words, keeping 644 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #500000, processed 9903270 words, keeping 646 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #510000, processed 10116322 words, keeping 648 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #520000, processed 10298790 words, keeping 650 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #530000, processed 10518470 words, keeping 652 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #540000, processed 10713688 words, keeping 654 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #550000, processed 10941425 words, keeping 656 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #560000, processed 11145934 words, keeping 657 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #570000, processed 11356832 words, keeping 659 word types\n",
      "08/21/2020 08:23:20 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #580000, processed 11595837 words, keeping 661 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #590000, processed 11802406 words, keeping 662 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #600000, processed 11996163 words, keeping 663 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #610000, processed 12209361 words, keeping 664 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #620000, processed 12403990 words, keeping 664 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #630000, processed 12595419 words, keeping 664 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #640000, processed 12775493 words, keeping 667 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #650000, processed 12951363 words, keeping 668 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #660000, processed 13131967 words, keeping 670 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #670000, processed 13309378 words, keeping 671 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #680000, processed 13539557 words, keeping 673 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #690000, processed 13722575 words, keeping 674 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #700000, processed 13932816 words, keeping 674 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #710000, processed 14091582 words, keeping 693 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #720000, processed 14202631 words, keeping 725 word types\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   collected 730 word types from a corpus of 14212917 raw words and 720924 sentences\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   Loading a fresh vocabulary\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   effective_min_count=1 retains 730 unique words (100% of original 730, drops 0)\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   effective_min_count=1 leaves 14212917 word corpus (100% of original 14212917, drops 0)\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   deleting the raw counts dictionary of 730 items\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   sample=0.001 downsamples 38 most-common words\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   downsampling leaves estimated 4291934 word corpus (30.2% of prior 14212917)\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.base_any2vec -   estimated required memory for 730 words and 128 dimensions: 1112520 bytes\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.word2vec -   resetting layer weights\n",
      "08/21/2020 08:23:21 - INFO - gensim.models.base_any2vec -   training model with 16 workers on 730 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "08/21/2020 08:23:22 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 7.97% examples, 343145 words/s, in_qsize 26, out_qsize 5\n",
      "08/21/2020 08:23:23 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 18.28% examples, 382004 words/s, in_qsize 31, out_qsize 3\n",
      "08/21/2020 08:23:24 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 27.90% examples, 397316 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:23:25 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 36.75% examples, 393902 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:23:26 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 46.52% examples, 398959 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:27 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 56.54% examples, 396981 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:28 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 66.68% examples, 399639 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:23:29 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 76.35% examples, 401755 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:30 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 85.75% examples, 402416 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:31 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 96.05% examples, 403432 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:23:32 - INFO - gensim.models.base_any2vec -   EPOCH - 1 : training on 14212917 raw words (4291762 effective words) took 10.6s, 405949 effective words/s\n",
      "08/21/2020 08:23:33 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 8.47% examples, 381514 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:34 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 18.47% examples, 394523 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:23:35 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 27.44% examples, 394564 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:23:36 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 37.65% examples, 405877 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:23:37 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 47.01% examples, 407750 words/s, in_qsize 26, out_qsize 2\n",
      "08/21/2020 08:23:38 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 56.91% examples, 404658 words/s, in_qsize 20, out_qsize 11\n",
      "08/21/2020 08:23:39 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 67.18% examples, 408479 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:40 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 76.88% examples, 410317 words/s, in_qsize 28, out_qsize 3\n",
      "08/21/2020 08:23:41 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 86.61% examples, 412369 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 96.25% examples, 409867 words/s, in_qsize 25, out_qsize 6\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:23:42 - INFO - gensim.models.base_any2vec -   EPOCH - 2 : training on 14212917 raw words (4293843 effective words) took 10.4s, 414204 effective words/s\n",
      "08/21/2020 08:23:43 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 8.93% examples, 398386 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:44 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 19.06% examples, 408361 words/s, in_qsize 27, out_qsize 3\n",
      "08/21/2020 08:23:45 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 28.58% examples, 411999 words/s, in_qsize 29, out_qsize 1\n",
      "08/21/2020 08:23:46 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 37.98% examples, 411012 words/s, in_qsize 31, out_qsize 3\n",
      "08/21/2020 08:23:47 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 48.00% examples, 414031 words/s, in_qsize 29, out_qsize 0\n",
      "08/21/2020 08:23:48 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 57.80% examples, 410750 words/s, in_qsize 28, out_qsize 3\n",
      "08/21/2020 08:23:49 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 68.30% examples, 414647 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:23:50 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 77.56% examples, 413737 words/s, in_qsize 31, out_qsize 2\n",
      "08/21/2020 08:23:51 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 87.47% examples, 416022 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 97.60% examples, 416399 words/s, in_qsize 22, out_qsize 0\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:23:52 - INFO - gensim.models.base_any2vec -   EPOCH - 3 : training on 14212917 raw words (4293726 effective words) took 10.3s, 418493 effective words/s\n",
      "08/21/2020 08:23:53 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 8.45% examples, 377401 words/s, in_qsize 26, out_qsize 8\n",
      "08/21/2020 08:23:54 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 19.32% examples, 411938 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:23:55 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 28.68% examples, 410048 words/s, in_qsize 32, out_qsize 8\n",
      "08/21/2020 08:23:56 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 38.03% examples, 408120 words/s, in_qsize 31, out_qsize 5\n",
      "08/21/2020 08:23:57 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 47.68% examples, 410731 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:23:58 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 58.38% examples, 415243 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:23:59 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 68.65% examples, 417419 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:24:00 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 78.15% examples, 417678 words/s, in_qsize 32, out_qsize 2\n",
      "08/21/2020 08:24:01 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 87.56% examples, 413849 words/s, in_qsize 25, out_qsize 6\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 98.03% examples, 416469 words/s, in_qsize 15, out_qsize 3\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:24:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:24:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:24:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:24:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:24:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:24:03 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:24:03 - INFO - gensim.models.base_any2vec -   EPOCH - 4 : training on 14212917 raw words (4291301 effective words) took 10.2s, 419391 effective words/s\n",
      "08/21/2020 08:24:04 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 8.39% examples, 373650 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:05 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 19.30% examples, 411682 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:06 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 28.23% examples, 404199 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:24:07 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 38.10% examples, 409295 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:24:08 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 47.88% examples, 411734 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:09 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 58.15% examples, 412066 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:10 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 68.53% examples, 411750 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:11 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 77.76% examples, 409659 words/s, in_qsize 32, out_qsize 2\n",
      "08/21/2020 08:24:12 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 87.98% examples, 413638 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 97.85% examples, 411850 words/s, in_qsize 19, out_qsize 0\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:24:13 - INFO - gensim.models.base_any2vec -   EPOCH - 5 : training on 14212917 raw words (4289973 effective words) took 10.3s, 414648 effective words/s\n",
      "08/21/2020 08:24:14 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 8.36% examples, 363964 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:24:15 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 18.68% examples, 390269 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:16 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 28.22% examples, 398185 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:17 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 37.83% examples, 398058 words/s, in_qsize 22, out_qsize 9\n",
      "08/21/2020 08:24:18 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 48.09% examples, 401977 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:19 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 58.51% examples, 406457 words/s, in_qsize 30, out_qsize 5\n",
      "08/21/2020 08:24:20 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 68.53% examples, 407734 words/s, in_qsize 31, out_qsize 2\n",
      "08/21/2020 08:24:21 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 77.83% examples, 407928 words/s, in_qsize 31, out_qsize 2\n",
      "08/21/2020 08:24:22 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 87.56% examples, 409771 words/s, in_qsize 28, out_qsize 3\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 97.39% examples, 410389 words/s, in_qsize 21, out_qsize 4\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:24:23 - INFO - gensim.models.base_any2vec -   EPOCH - 6 : training on 14212917 raw words (4289831 effective words) took 10.4s, 413684 effective words/s\n",
      "08/21/2020 08:24:24 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 8.39% examples, 378167 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:24:25 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 18.49% examples, 395657 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:26 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 27.84% examples, 398459 words/s, in_qsize 26, out_qsize 5\n",
      "08/21/2020 08:24:27 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 37.70% examples, 402417 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:28 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 47.29% examples, 403984 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:24:29 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 58.32% examples, 408043 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:30 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 68.20% examples, 407621 words/s, in_qsize 27, out_qsize 4\n",
      "08/21/2020 08:24:31 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 77.52% examples, 407655 words/s, in_qsize 31, out_qsize 9\n",
      "08/21/2020 08:24:33 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 87.66% examples, 410648 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 97.36% examples, 410293 words/s, in_qsize 24, out_qsize 1\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:24:34 - INFO - gensim.models.base_any2vec -   EPOCH - 7 : training on 14212917 raw words (4291322 effective words) took 10.4s, 413860 effective words/s\n",
      "08/21/2020 08:24:35 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 7.89% examples, 357539 words/s, in_qsize 31, out_qsize 7\n",
      "08/21/2020 08:24:36 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 18.06% examples, 385607 words/s, in_qsize 32, out_qsize 1\n",
      "08/21/2020 08:24:37 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 28.18% examples, 405267 words/s, in_qsize 29, out_qsize 0\n",
      "08/21/2020 08:24:38 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 37.34% examples, 401709 words/s, in_qsize 32, out_qsize 11\n",
      "08/21/2020 08:24:39 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 47.17% examples, 406868 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:24:40 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 57.23% examples, 406879 words/s, in_qsize 26, out_qsize 13\n",
      "08/21/2020 08:24:41 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 67.78% examples, 412000 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:24:42 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 76.66% examples, 408714 words/s, in_qsize 28, out_qsize 7\n",
      "08/21/2020 08:24:43 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 86.61% examples, 412252 words/s, in_qsize 28, out_qsize 4\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 96.51% examples, 411018 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:24:44 - INFO - gensim.models.base_any2vec -   EPOCH - 8 : training on 14212917 raw words (4292300 effective words) took 10.4s, 413930 effective words/s\n",
      "08/21/2020 08:24:45 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 8.10% examples, 362458 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:46 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 17.81% examples, 374276 words/s, in_qsize 30, out_qsize 5\n",
      "08/21/2020 08:24:47 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 27.10% examples, 385253 words/s, in_qsize 31, out_qsize 2\n",
      "08/21/2020 08:24:48 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 36.48% examples, 387719 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:49 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 46.07% examples, 393212 words/s, in_qsize 32, out_qsize 6\n",
      "08/21/2020 08:24:50 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 56.41% examples, 397274 words/s, in_qsize 32, out_qsize 1\n",
      "08/21/2020 08:24:51 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 66.45% examples, 397331 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:52 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 75.97% examples, 399313 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:53 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 85.19% examples, 400265 words/s, in_qsize 31, out_qsize 1\n",
      "08/21/2020 08:24:54 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 94.35% examples, 397869 words/s, in_qsize 28, out_qsize 3\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:24:55 - INFO - gensim.models.base_any2vec -   EPOCH - 9 : training on 14212917 raw words (4293014 effective words) took 10.7s, 403079 effective words/s\n",
      "08/21/2020 08:24:56 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 8.33% examples, 353258 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:57 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 18.68% examples, 379564 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:58 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 28.14% examples, 387987 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:24:59 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 37.44% examples, 391632 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:00 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 46.87% examples, 394351 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:01 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 56.48% examples, 390963 words/s, in_qsize 32, out_qsize 7\n",
      "08/21/2020 08:25:02 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 66.56% examples, 392439 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:03 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 75.68% examples, 392328 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:25:04 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 85.09% examples, 393077 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:05 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 94.55% examples, 392846 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   EPOCH - 10 : training on 14212917 raw words (4291887 effective words) took 10.8s, 396213 effective words/s\n",
      "08/21/2020 08:25:06 - INFO - gensim.models.base_any2vec -   training on a 142129170 raw words (42918959 effective words) took 104.5s, 410541 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save w2v to word2vecf/CREATED_BY_seq.128d\n",
      "w2v UPDATED_BY_seq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   collecting all words and their counts\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #10000, processed 253166 words, keeping 204 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #20000, processed 463255 words, keeping 268 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #30000, processed 654538 words, keeping 309 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #40000, processed 859787 words, keeping 347 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #50000, processed 1090795 words, keeping 376 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #60000, processed 1300595 words, keeping 396 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Num 720924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #70000, processed 1495792 words, keeping 414 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #80000, processed 1691255 words, keeping 434 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #90000, processed 1871970 words, keeping 451 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #100000, processed 2044905 words, keeping 464 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #110000, processed 2235888 words, keeping 471 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #120000, processed 2450267 words, keeping 480 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #130000, processed 2631056 words, keeping 489 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #140000, processed 2847702 words, keeping 502 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #150000, processed 3051075 words, keeping 511 word types\n",
      "08/21/2020 08:25:08 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #160000, processed 3261944 words, keeping 520 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #170000, processed 3468793 words, keeping 528 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #180000, processed 3648499 words, keeping 531 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #190000, processed 3872120 words, keeping 543 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #200000, processed 4089524 words, keeping 549 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #210000, processed 4285801 words, keeping 554 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #220000, processed 4486835 words, keeping 558 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #230000, processed 4698869 words, keeping 565 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #240000, processed 4896532 words, keeping 571 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #250000, processed 5092070 words, keeping 578 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #260000, processed 5288337 words, keeping 583 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #270000, processed 5486555 words, keeping 585 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #280000, processed 5686075 words, keeping 586 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #290000, processed 5856127 words, keeping 589 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #300000, processed 6068771 words, keeping 596 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #310000, processed 6261154 words, keeping 599 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #320000, processed 6466914 words, keeping 603 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #330000, processed 6656830 words, keeping 607 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #340000, processed 6877273 words, keeping 610 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #350000, processed 7059156 words, keeping 610 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #360000, processed 7238260 words, keeping 615 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #370000, processed 7414528 words, keeping 617 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #380000, processed 7592132 words, keeping 620 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #390000, processed 7784320 words, keeping 622 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #400000, processed 7979436 words, keeping 623 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #410000, processed 8176514 words, keeping 625 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #420000, processed 8385745 words, keeping 625 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #430000, processed 8598276 words, keeping 629 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #440000, processed 8808814 words, keeping 631 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #450000, processed 8989847 words, keeping 634 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #460000, processed 9184403 words, keeping 635 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #470000, processed 9360158 words, keeping 639 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #480000, processed 9554464 words, keeping 641 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #490000, processed 9725976 words, keeping 644 word types\n",
      "08/21/2020 08:25:09 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #500000, processed 9903270 words, keeping 646 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #510000, processed 10116322 words, keeping 648 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #520000, processed 10298790 words, keeping 650 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #530000, processed 10518470 words, keeping 652 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #540000, processed 10713688 words, keeping 654 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #550000, processed 10941425 words, keeping 656 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #560000, processed 11145934 words, keeping 657 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #570000, processed 11356832 words, keeping 659 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #580000, processed 11595837 words, keeping 661 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #590000, processed 11802406 words, keeping 662 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #600000, processed 11996163 words, keeping 663 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #610000, processed 12209361 words, keeping 664 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #620000, processed 12403990 words, keeping 664 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #630000, processed 12595419 words, keeping 664 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #640000, processed 12775493 words, keeping 667 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #650000, processed 12951363 words, keeping 668 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #660000, processed 13131967 words, keeping 670 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #670000, processed 13309378 words, keeping 671 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #680000, processed 13539557 words, keeping 673 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #690000, processed 13722575 words, keeping 674 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #700000, processed 13932816 words, keeping 674 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #710000, processed 14091582 words, keeping 693 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   PROGRESS: at sentence #720000, processed 14202631 words, keeping 725 word types\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   collected 730 word types from a corpus of 14212917 raw words and 720924 sentences\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   Loading a fresh vocabulary\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   effective_min_count=1 retains 730 unique words (100% of original 730, drops 0)\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   effective_min_count=1 leaves 14212917 word corpus (100% of original 14212917, drops 0)\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   deleting the raw counts dictionary of 730 items\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   sample=0.001 downsamples 38 most-common words\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   downsampling leaves estimated 4292237 word corpus (30.2% of prior 14212917)\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.base_any2vec -   estimated required memory for 730 words and 128 dimensions: 1112520 bytes\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.word2vec -   resetting layer weights\n",
      "08/21/2020 08:25:10 - INFO - gensim.models.base_any2vec -   training model with 16 workers on 730 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "08/21/2020 08:25:11 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 8.19% examples, 369107 words/s, in_qsize 30, out_qsize 0\n",
      "08/21/2020 08:25:12 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 17.73% examples, 379892 words/s, in_qsize 27, out_qsize 4\n",
      "08/21/2020 08:25:13 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 27.31% examples, 394200 words/s, in_qsize 31, out_qsize 2\n",
      "08/21/2020 08:25:14 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 37.27% examples, 395150 words/s, in_qsize 27, out_qsize 4\n",
      "08/21/2020 08:25:15 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 47.87% examples, 407715 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:16 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 58.01% examples, 405832 words/s, in_qsize 31, out_qsize 3\n",
      "08/21/2020 08:25:17 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 68.20% examples, 408280 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:18 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 77.42% examples, 407595 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:25:19 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 87.51% examples, 411087 words/s, in_qsize 32, out_qsize 1\n",
      "08/21/2020 08:25:20 - INFO - gensim.models.base_any2vec -   EPOCH 1 - PROGRESS: at 97.27% examples, 411125 words/s, in_qsize 26, out_qsize 0\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:25:21 - INFO - gensim.models.base_any2vec -   EPOCH - 1 : training on 14212917 raw words (4293065 effective words) took 10.4s, 413458 effective words/s\n",
      "08/21/2020 08:25:22 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 8.83% examples, 392945 words/s, in_qsize 26, out_qsize 3\n",
      "08/21/2020 08:25:23 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 18.42% examples, 395632 words/s, in_qsize 19, out_qsize 12\n",
      "08/21/2020 08:25:24 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 28.42% examples, 408730 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:25 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 37.68% examples, 406704 words/s, in_qsize 31, out_qsize 8\n",
      "08/21/2020 08:25:26 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 48.08% examples, 414125 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:27 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 58.59% examples, 417382 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:25:28 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 68.73% examples, 414001 words/s, in_qsize 23, out_qsize 8\n",
      "08/21/2020 08:25:29 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 78.60% examples, 416484 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:25:30 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 88.27% examples, 416973 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   EPOCH 2 - PROGRESS: at 98.45% examples, 417500 words/s, in_qsize 12, out_qsize 3\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:25:31 - INFO - gensim.models.base_any2vec -   EPOCH - 2 : training on 14212917 raw words (4292813 effective words) took 10.2s, 420430 effective words/s\n",
      "08/21/2020 08:25:32 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 8.69% examples, 389031 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:33 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 18.65% examples, 397367 words/s, in_qsize 30, out_qsize 0\n",
      "08/21/2020 08:25:34 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 28.19% examples, 406311 words/s, in_qsize 28, out_qsize 4\n",
      "08/21/2020 08:25:35 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 37.64% examples, 405555 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:36 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 47.76% examples, 412913 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:37 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 57.99% examples, 413057 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:25:38 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 67.31% examples, 409183 words/s, in_qsize 31, out_qsize 6\n",
      "08/21/2020 08:25:39 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 76.56% examples, 409526 words/s, in_qsize 31, out_qsize 12\n",
      "08/21/2020 08:25:40 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 86.55% examples, 412860 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   EPOCH 3 - PROGRESS: at 96.72% examples, 413286 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:25:41 - INFO - gensim.models.base_any2vec -   EPOCH - 3 : training on 14212917 raw words (4293049 effective words) took 10.3s, 415880 effective words/s\n",
      "08/21/2020 08:25:42 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 8.66% examples, 378126 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:43 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 18.93% examples, 395825 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:44 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 28.58% examples, 403155 words/s, in_qsize 31, out_qsize 3\n",
      "08/21/2020 08:25:45 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 38.71% examples, 409488 words/s, in_qsize 32, out_qsize 2\n",
      "08/21/2020 08:25:46 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 48.71% examples, 414256 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:47 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 58.27% examples, 409339 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:48 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 67.87% examples, 408187 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:49 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 77.07% examples, 407881 words/s, in_qsize 32, out_qsize 1\n",
      "08/21/2020 08:25:50 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 86.95% examples, 411230 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:51 - INFO - gensim.models.base_any2vec -   EPOCH 4 - PROGRESS: at 96.53% examples, 409124 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:25:52 - INFO - gensim.models.base_any2vec -   EPOCH - 4 : training on 14212917 raw words (4291902 effective words) took 10.4s, 412057 effective words/s\n",
      "08/21/2020 08:25:53 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 8.82% examples, 369250 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:25:54 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 19.17% examples, 388242 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:25:55 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 28.82% examples, 399107 words/s, in_qsize 28, out_qsize 4\n",
      "08/21/2020 08:25:56 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 38.34% examples, 401109 words/s, in_qsize 31, out_qsize 9\n",
      "08/21/2020 08:25:57 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 48.41% examples, 406463 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:25:58 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 58.29% examples, 406425 words/s, in_qsize 23, out_qsize 15\n",
      "08/21/2020 08:25:59 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 68.60% examples, 409349 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:00 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 78.10% examples, 410539 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:01 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 87.48% examples, 410825 words/s, in_qsize 29, out_qsize 3\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   EPOCH 5 - PROGRESS: at 98.03% examples, 411838 words/s, in_qsize 17, out_qsize 0\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:26:02 - INFO - gensim.models.base_any2vec -   EPOCH - 5 : training on 14212917 raw words (4291076 effective words) took 10.3s, 414686 effective words/s\n",
      "08/21/2020 08:26:03 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 8.24% examples, 365052 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:04 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 18.97% examples, 399915 words/s, in_qsize 27, out_qsize 4\n",
      "08/21/2020 08:26:05 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 28.66% examples, 404609 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:26:06 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 38.01% examples, 404800 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:26:07 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 48.09% examples, 409828 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:26:08 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 58.85% examples, 414153 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:09 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 68.68% examples, 410929 words/s, in_qsize 31, out_qsize 4\n",
      "08/21/2020 08:26:10 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 77.92% examples, 409275 words/s, in_qsize 30, out_qsize 2\n",
      "08/21/2020 08:26:11 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 87.48% examples, 410593 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   EPOCH 6 - PROGRESS: at 97.84% examples, 412879 words/s, in_qsize 19, out_qsize 0\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:26:12 - INFO - gensim.models.base_any2vec -   EPOCH - 6 : training on 14212917 raw words (4292140 effective words) took 10.4s, 413644 effective words/s\n",
      "08/21/2020 08:26:13 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 8.34% examples, 378673 words/s, in_qsize 32, out_qsize 4\n",
      "08/21/2020 08:26:14 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 18.57% examples, 392521 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:16 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 27.27% examples, 386794 words/s, in_qsize 31, out_qsize 8\n",
      "08/21/2020 08:26:17 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 37.75% examples, 399627 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:18 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 47.09% examples, 402038 words/s, in_qsize 26, out_qsize 5\n",
      "08/21/2020 08:26:19 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 57.29% examples, 403710 words/s, in_qsize 28, out_qsize 3\n",
      "08/21/2020 08:26:20 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 66.76% examples, 400856 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:26:21 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 76.39% examples, 402348 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:22 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 86.10% examples, 405834 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   EPOCH 7 - PROGRESS: at 95.65% examples, 404170 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:26:23 - INFO - gensim.models.base_any2vec -   EPOCH - 7 : training on 14212917 raw words (4292236 effective words) took 10.5s, 406960 effective words/s\n",
      "08/21/2020 08:26:24 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 7.87% examples, 355887 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:25 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 18.10% examples, 380197 words/s, in_qsize 28, out_qsize 3\n",
      "08/21/2020 08:26:26 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 28.01% examples, 397682 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:27 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 37.75% examples, 398159 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:28 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 47.86% examples, 406735 words/s, in_qsize 30, out_qsize 0\n",
      "08/21/2020 08:26:29 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 58.35% examples, 406893 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:30 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 68.46% examples, 408252 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:31 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 77.74% examples, 407900 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:32 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 87.33% examples, 409694 words/s, in_qsize 28, out_qsize 3\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   EPOCH 8 - PROGRESS: at 96.40% examples, 406983 words/s, in_qsize 26, out_qsize 5\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:26:33 - INFO - gensim.models.base_any2vec -   EPOCH - 8 : training on 14212917 raw words (4290928 effective words) took 10.4s, 410950 effective words/s\n",
      "08/21/2020 08:26:34 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 8.30% examples, 374441 words/s, in_qsize 27, out_qsize 8\n",
      "08/21/2020 08:26:35 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 18.40% examples, 394220 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:36 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 27.42% examples, 396297 words/s, in_qsize 31, out_qsize 1\n",
      "08/21/2020 08:26:38 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 36.91% examples, 399162 words/s, in_qsize 31, out_qsize 2\n",
      "08/21/2020 08:26:39 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 46.26% examples, 400080 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:40 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 56.85% examples, 400821 words/s, in_qsize 18, out_qsize 13\n",
      "08/21/2020 08:26:41 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 67.64% examples, 406908 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:42 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 76.77% examples, 406254 words/s, in_qsize 31, out_qsize 3\n",
      "08/21/2020 08:26:43 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 85.38% examples, 402693 words/s, in_qsize 30, out_qsize 1\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   EPOCH 9 - PROGRESS: at 95.58% examples, 402667 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:26:44 - INFO - gensim.models.base_any2vec -   EPOCH - 9 : training on 14212917 raw words (4291985 effective words) took 10.6s, 406151 effective words/s\n",
      "08/21/2020 08:26:45 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 8.13% examples, 365388 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:26:46 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 17.89% examples, 382774 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:47 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 26.90% examples, 387153 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:48 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 36.21% examples, 393024 words/s, in_qsize 32, out_qsize 0\n",
      "08/21/2020 08:26:49 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 45.04% examples, 389604 words/s, in_qsize 32, out_qsize 1\n",
      "08/21/2020 08:26:50 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 54.86% examples, 392119 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:51 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 63.81% examples, 389346 words/s, in_qsize 29, out_qsize 2\n",
      "08/21/2020 08:26:52 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 73.71% examples, 392356 words/s, in_qsize 32, out_qsize 2\n",
      "08/21/2020 08:26:53 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 82.48% examples, 391685 words/s, in_qsize 32, out_qsize 4\n",
      "08/21/2020 08:26:54 - INFO - gensim.models.base_any2vec -   EPOCH 10 - PROGRESS: at 92.56% examples, 393718 words/s, in_qsize 31, out_qsize 0\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 15 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 14 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 13 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 12 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 11 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 10 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 9 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 8 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 7 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 6 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 5 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 4 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 3 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   EPOCH - 10 : training on 14212917 raw words (4292143 effective words) took 10.9s, 395471 effective words/s\n",
      "08/21/2020 08:26:55 - INFO - gensim.models.base_any2vec -   training on a 142129170 raw words (42921337 effective words) took 104.6s, 410196 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save w2v to word2vecf/UPDATED_BY_seq.128d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "def w2v(dfs,f,L=128):\n",
    "    print(\"w2v\",f)\n",
    "    sentences=[]\n",
    "    for df in dfs:\n",
    "        for line in df[f].values:\n",
    "            sentences.append(line.split())\n",
    "    print(\"Sentence Num {}\".format(len(sentences)))\n",
    "    w2v=Word2Vec(sentences,size=L, window=5,min_count=1,sg=1,workers=16,iter=10)\n",
    "    print(\"save w2v to {}\".format(os.path.join('word2vecf',f+\".{}d\".format(L))))\n",
    "    pickle.dump(w2v,open(os.path.join('word2vecf',f+\".{}d\".format(L)),'wb'))  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_df=pd.read_pickle('middle/train_all.pkl')\n",
    "    test_df=pd.read_pickle('middle/test_all.pkl')\n",
    "    #训练word2vector，维度为128\n",
    "    w2v([train_df,test_df],'milestone_seq',L=128)\n",
    "    w2v([train_df,test_df],'CREATED_BY_seq',L=128)\n",
    "    w2v([train_df,test_df],'UPDATED_BY_seq',L=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVou1HV4JeH3"
   },
   "outputs": [],
   "source": [
    "!rm -rf Bert/saved_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1235399,
     "status": "ok",
     "timestamp": 1598010647815,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "9jdrt0qzm154",
    "outputId": "9fd0580b-0f91-47b8-a0f6-1ae96ea87f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-21 08:36:18.516252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "08/21/2020 08:36:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "('milestone_seq', '40') 3\n",
      "('milestone_seq', '64') 4\n",
      "('milestone_seq', '6') 5\n",
      "('milestone_seq', '31') 6\n",
      "67\n",
      "('CREATED_BY_seq', '54') 70\n",
      "('CREATED_BY_seq', '404') 71\n",
      "('CREATED_BY_seq', '155') 72\n",
      "('CREATED_BY_seq', '209') 73\n",
      "670\n",
      "('UPDATED_BY_seq', '54') 740\n",
      "('UPDATED_BY_seq', '404') 741\n",
      "('UPDATED_BY_seq', '155') 742\n",
      "('UPDATED_BY_seq', '209') 743\n",
      "670\n",
      "08/21/2020 08:36:42 - INFO - __main__ -   RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 64,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 256,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_dim_v1\": 64,\n",
      "  \"vocab_size\": 5,\n",
      "  \"vocab_size_v1\": 1410\n",
      "}\n",
      "\n",
      "08/21/2020 08:36:42 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-06, block_size=128, cache_dir='', config_name='roberta-base', device=device(type='cuda'), dfg_size=64, do_eval=False, do_lower_case=False, do_train=False, eval_all_checkpoints=False, eval_data_file=None, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, lang=None, learning_rate=5e-05, local_rank=-1, log_file='', logging_steps=50, max_grad_norm=1.0, max_steps=100000, mlm=True, mlm_probability=0.2, model_name_or_path=None, model_type='roberta', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='Bert/saved_models', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, pretrain='', save_steps=10000, save_total_limit=500, seed=123456, server_ip='', server_port='', start_epoch=0, start_step=0, tensorboard_dir='saved_models/tensorboard_logs', tokenizer_name='', warmup_steps=10000, weight_decay=0.01)\n",
      "08/21/2020 08:36:42 - INFO - summarizer.preprocessing.cleaner -   'pattern' package not found; tag filters are not available for English\n",
      "['word2vecf/milestone_seq.128d', 'milestone_seq', 128, True]\n",
      "['word2vecf/CREATED_BY_seq.128d', 'CREATED_BY_seq', 128, True]\n",
      "['word2vecf/UPDATED_BY_seq.128d', 'UPDATED_BY_seq', 128, True]\n",
      "08/21/2020 08:37:02 - INFO - __main__ -   ***** Running training *****\n",
      "08/21/2020 08:37:02 - INFO - __main__ -     Num examples = 715924\n",
      "08/21/2020 08:37:02 - INFO - __main__ -     Num Epochs = 9\n",
      "08/21/2020 08:37:02 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n",
      "08/21/2020 08:37:02 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "08/21/2020 08:37:02 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "08/21/2020 08:37:02 - INFO - __main__ -     Total optimization steps = 100000\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
      "08/21/2020 08:37:14 - INFO - __main__ -     steps: 100  ppl: 47194628.8917\n",
      "08/21/2020 08:37:25 - INFO - __main__ -     steps: 200  ppl: 41872862.6731\n",
      "08/21/2020 08:37:37 - INFO - __main__ -     steps: 300  ppl: 31628304.456\n",
      "08/21/2020 08:37:48 - INFO - __main__ -     steps: 400  ppl: 20781669.2704\n",
      "08/21/2020 08:37:59 - INFO - __main__ -     steps: 500  ppl: 12804247.0621\n",
      "08/21/2020 08:38:11 - INFO - __main__ -     steps: 600  ppl: 7089795.1383\n",
      "08/21/2020 08:38:22 - INFO - __main__ -     steps: 700  ppl: 3697885.5874\n",
      "08/21/2020 08:38:33 - INFO - __main__ -     steps: 800  ppl: 1925327.9236\n",
      "08/21/2020 08:38:45 - INFO - __main__ -     steps: 900  ppl: 1015942.8231\n",
      "08/21/2020 08:38:56 - INFO - __main__ -     steps: 1000  ppl: 567703.0987\n",
      "08/21/2020 08:39:08 - INFO - __main__ -     steps: 1100  ppl: 319901.6216\n",
      "08/21/2020 08:39:19 - INFO - __main__ -     steps: 1200  ppl: 197982.8383\n",
      "08/21/2020 08:39:30 - INFO - __main__ -     steps: 1300  ppl: 142732.5059\n",
      "08/21/2020 08:39:42 - INFO - __main__ -     steps: 1400  ppl: 102590.7837\n",
      "08/21/2020 08:39:53 - INFO - __main__ -     steps: 1500  ppl: 72048.3992\n",
      "08/21/2020 08:40:04 - INFO - __main__ -     steps: 1600  ppl: 53894.7054\n",
      "08/21/2020 08:40:16 - INFO - __main__ -     steps: 1700  ppl: 38058.8637\n",
      "08/21/2020 08:40:27 - INFO - __main__ -     steps: 1800  ppl: 32952.8246\n",
      "08/21/2020 08:40:38 - INFO - __main__ -     steps: 1900  ppl: 23238.8925\n",
      "08/21/2020 08:40:50 - INFO - __main__ -     steps: 2000  ppl: 18775.0124\n",
      "08/21/2020 08:41:01 - INFO - __main__ -     steps: 2100  ppl: 15363.2821\n",
      "08/21/2020 08:41:12 - INFO - __main__ -     steps: 2200  ppl: 10586.5496\n",
      "08/21/2020 08:41:24 - INFO - __main__ -     steps: 2300  ppl: 9769.6918\n",
      "08/21/2020 08:41:35 - INFO - __main__ -     steps: 2400  ppl: 7912.5441\n",
      "08/21/2020 08:41:47 - INFO - __main__ -     steps: 2500  ppl: 5929.5052\n",
      "08/21/2020 08:41:58 - INFO - __main__ -     steps: 2600  ppl: 4533.499\n",
      "08/21/2020 08:42:10 - INFO - __main__ -     steps: 2700  ppl: 3673.1346\n",
      "08/21/2020 08:42:21 - INFO - __main__ -     steps: 2800  ppl: 2986.5057\n",
      "08/21/2020 08:42:32 - INFO - __main__ -     steps: 2900  ppl: 2238.1821\n",
      "08/21/2020 08:42:44 - INFO - __main__ -     steps: 3000  ppl: 2169.4668\n",
      "08/21/2020 08:42:55 - INFO - __main__ -     steps: 3100  ppl: 1492.5649\n",
      "08/21/2020 08:43:07 - INFO - __main__ -     steps: 3200  ppl: 1295.053\n",
      "08/21/2020 08:43:18 - INFO - __main__ -     steps: 3300  ppl: 1009.3543\n",
      "08/21/2020 08:43:29 - INFO - __main__ -     steps: 3400  ppl: 744.2301\n",
      "08/21/2020 08:43:41 - INFO - __main__ -     steps: 3500  ppl: 763.566\n",
      "08/21/2020 08:43:52 - INFO - __main__ -     steps: 3600  ppl: 593.1877\n",
      "08/21/2020 08:44:04 - INFO - __main__ -     steps: 3700  ppl: 536.0466\n",
      "08/21/2020 08:44:15 - INFO - __main__ -     steps: 3800  ppl: 367.7341\n",
      "08/21/2020 08:44:27 - INFO - __main__ -     steps: 3900  ppl: 359.6484\n",
      "08/21/2020 08:44:39 - INFO - __main__ -     steps: 4000  ppl: 302.3788\n",
      "08/21/2020 08:44:50 - INFO - __main__ -     steps: 4100  ppl: 310.3882\n",
      "08/21/2020 08:45:01 - INFO - __main__ -     steps: 4200  ppl: 214.0676\n",
      "08/21/2020 08:45:13 - INFO - __main__ -     steps: 4300  ppl: 196.6414\n",
      "08/21/2020 08:45:24 - INFO - __main__ -     steps: 4400  ppl: 172.4821\n",
      "08/21/2020 08:45:36 - INFO - __main__ -     steps: 4500  ppl: 166.9755\n",
      "08/21/2020 08:45:47 - INFO - __main__ -     steps: 4600  ppl: 155.372\n",
      "08/21/2020 08:45:59 - INFO - __main__ -     steps: 4700  ppl: 136.9423\n",
      "08/21/2020 08:46:10 - INFO - __main__ -     steps: 4800  ppl: 120.1629\n",
      "08/21/2020 08:46:22 - INFO - __main__ -     steps: 4900  ppl: 119.7768\n",
      "08/21/2020 08:46:33 - INFO - __main__ -     steps: 5000  ppl: 101.2374\n",
      "08/21/2020 08:46:45 - INFO - __main__ -     steps: 5100  ppl: 82.1868\n",
      "08/21/2020 08:46:56 - INFO - __main__ -     steps: 5200  ppl: 75.1605\n",
      "08/21/2020 08:47:07 - INFO - __main__ -     steps: 5300  ppl: 78.2532\n",
      "08/21/2020 08:47:19 - INFO - __main__ -     steps: 5400  ppl: 68.4786\n",
      "08/21/2020 08:47:31 - INFO - __main__ -     steps: 5500  ppl: 69.0535\n",
      "08/21/2020 08:47:42 - INFO - __main__ -     steps: 5600  ppl: 61.1467\n",
      "08/21/2020 08:47:54 - INFO - __main__ -     steps: 5700  ppl: 60.106\n",
      "08/21/2020 08:48:05 - INFO - __main__ -     steps: 5800  ppl: 58.3624\n",
      "08/21/2020 08:48:16 - INFO - __main__ -     steps: 5900  ppl: 50.4026\n",
      "08/21/2020 08:48:28 - INFO - __main__ -     steps: 6000  ppl: 47.3409\n",
      "08/21/2020 08:48:39 - INFO - __main__ -     steps: 6100  ppl: 46.7988\n",
      "08/21/2020 08:48:50 - INFO - __main__ -     steps: 6200  ppl: 43.9838\n",
      "08/21/2020 08:49:02 - INFO - __main__ -     steps: 6300  ppl: 43.3914\n",
      "08/21/2020 08:49:14 - INFO - __main__ -     steps: 6400  ppl: 38.294\n",
      "08/21/2020 08:49:25 - INFO - __main__ -     steps: 6500  ppl: 36.3502\n",
      "08/21/2020 08:49:37 - INFO - __main__ -     steps: 6600  ppl: 34.8737\n",
      "08/21/2020 08:49:49 - INFO - __main__ -     steps: 6700  ppl: 35.2484\n",
      "08/21/2020 08:50:00 - INFO - __main__ -     steps: 6800  ppl: 30.7057\n",
      "08/21/2020 08:50:12 - INFO - __main__ -     steps: 6900  ppl: 29.6901\n",
      "08/21/2020 08:50:23 - INFO - __main__ -     steps: 7000  ppl: 26.5097\n",
      "08/21/2020 08:50:35 - INFO - __main__ -     steps: 7100  ppl: 28.0516\n",
      "08/21/2020 08:50:46 - INFO - __main__ -     steps: 7200  ppl: 29.0312\n",
      "08/21/2020 08:50:58 - INFO - __main__ -     steps: 7300  ppl: 24.571\n",
      "08/21/2020 08:51:10 - INFO - __main__ -     steps: 7400  ppl: 23.8325\n",
      "08/21/2020 08:51:21 - INFO - __main__ -     steps: 7500  ppl: 25.4472\n",
      "08/21/2020 08:51:33 - INFO - __main__ -     steps: 7600  ppl: 24.0269\n",
      "08/21/2020 08:51:44 - INFO - __main__ -     steps: 7700  ppl: 22.9053\n",
      "08/21/2020 08:51:56 - INFO - __main__ -     steps: 7800  ppl: 20.9972\n",
      "08/21/2020 08:52:08 - INFO - __main__ -     steps: 7900  ppl: 21.5029\n",
      "08/21/2020 08:52:19 - INFO - __main__ -     steps: 8000  ppl: 19.8837\n",
      "08/21/2020 08:52:31 - INFO - __main__ -     steps: 8100  ppl: 21.3358\n",
      "08/21/2020 08:52:42 - INFO - __main__ -     steps: 8200  ppl: 18.5612\n",
      "08/21/2020 08:52:54 - INFO - __main__ -     steps: 8300  ppl: 18.1522\n",
      "08/21/2020 08:53:06 - INFO - __main__ -     steps: 8400  ppl: 18.0039\n",
      "08/21/2020 08:53:17 - INFO - __main__ -     steps: 8500  ppl: 16.7796\n",
      "08/21/2020 08:53:29 - INFO - __main__ -     steps: 8600  ppl: 15.7858\n",
      "08/21/2020 08:53:40 - INFO - __main__ -     steps: 8700  ppl: 15.8539\n",
      "08/21/2020 08:53:51 - INFO - __main__ -     steps: 8800  ppl: 15.4406\n",
      "08/21/2020 08:54:03 - INFO - __main__ -     steps: 8900  ppl: 15.0279\n",
      "08/21/2020 08:54:14 - INFO - __main__ -     steps: 9000  ppl: 15.3243\n",
      "08/21/2020 08:54:26 - INFO - __main__ -     steps: 9100  ppl: 14.4407\n",
      "08/21/2020 08:54:37 - INFO - __main__ -     steps: 9200  ppl: 13.8806\n",
      "08/21/2020 08:54:49 - INFO - __main__ -     steps: 9300  ppl: 12.7313\n",
      "08/21/2020 08:55:00 - INFO - __main__ -     steps: 9400  ppl: 13.356\n",
      "08/21/2020 08:55:12 - INFO - __main__ -     steps: 9500  ppl: 12.1103\n",
      "08/21/2020 08:55:24 - INFO - __main__ -     steps: 9600  ppl: 12.2877\n",
      "08/21/2020 08:55:35 - INFO - __main__ -     steps: 9700  ppl: 12.4623\n",
      "08/21/2020 08:55:47 - INFO - __main__ -     steps: 9800  ppl: 11.8048\n",
      "08/21/2020 08:55:59 - INFO - __main__ -     steps: 9900  ppl: 11.9038\n",
      "08/21/2020 08:56:11 - INFO - __main__ -     steps: 10000  ppl: 10.9803\n",
      "08/21/2020 08:56:16 - INFO - __main__ -     perplexity = 11.6487\n",
      "08/21/2020 08:56:16 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-10000-11.6487/config.json\n",
      "08/21/2020 08:56:16 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-10000-11.6487/pytorch_model.bin\n",
      "08/21/2020 08:56:16 - INFO - __main__ -   Saving model checkpoint to Bert/saved_models/checkpoint-10000-11.6487\n",
      "08/21/2020 08:56:16 - INFO - __main__ -   Saving linear to Bert/saved_models/linear.bin\n",
      "08/21/2020 08:56:16 - INFO - __main__ -   Saving embeddings to Bert/saved_models/embeddings.bin\n",
      "08/21/2020 08:56:16 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-last/config.json\n",
      "08/21/2020 08:56:16 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-last/pytorch_model.bin\n",
      "08/21/2020 08:56:16 - INFO - __main__ -   Saving linear to Bert/saved_models/checkpoint-last/linear.bin\n",
      "08/21/2020 08:56:16 - INFO - __main__ -   Saving embeddings to Bert/saved_models/checkpoint-last/embeddings.bin\n",
      "08/21/2020 08:56:16 - INFO - __main__ -   Saving model to Bert/saved_models/checkpoint-last/model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "08/21/2020 08:56:16 - INFO - __main__ -   Saving optimizer and scheduler states to Bert/saved_models/checkpoint-last\n",
      "08/21/2020 08:56:28 - INFO - __main__ -     steps: 10100  ppl: 11.5916\n",
      "08/21/2020 08:56:39 - INFO - __main__ -     steps: 10200  ppl: 11.4295\n",
      "08/21/2020 08:56:51 - INFO - __main__ -     steps: 10300  ppl: 10.7623\n",
      "08/21/2020 08:57:02 - INFO - __main__ -     steps: 10400  ppl: 10.2123\n",
      "08/21/2020 08:57:14 - INFO - __main__ -     steps: 10500  ppl: 9.9795\n",
      "08/21/2020 08:57:25 - INFO - __main__ -     steps: 10600  ppl: 10.4353\n",
      "08/21/2020 08:57:37 - INFO - __main__ -     steps: 10700  ppl: 9.9674\n",
      "08/21/2020 08:57:49 - INFO - __main__ -     steps: 10800  ppl: 9.1298\n",
      "08/21/2020 08:58:00 - INFO - __main__ -     steps: 10900  ppl: 9.164\n",
      "08/21/2020 08:58:12 - INFO - __main__ -     steps: 11000  ppl: 9.1588\n",
      "08/21/2020 08:58:24 - INFO - __main__ -     steps: 11100  ppl: 8.9433\n",
      "08/21/2020 08:58:36 - INFO - __main__ -     steps: 11200  ppl: 9.0177\n",
      "08/21/2020 08:58:48 - INFO - __main__ -     steps: 11300  ppl: 9.298\n",
      "08/21/2020 08:58:59 - INFO - __main__ -     steps: 11400  ppl: 8.3873\n",
      "08/21/2020 08:59:11 - INFO - __main__ -     steps: 11500  ppl: 8.5511\n",
      "08/21/2020 08:59:22 - INFO - __main__ -     steps: 11600  ppl: 8.1069\n",
      "08/21/2020 08:59:34 - INFO - __main__ -     steps: 11700  ppl: 8.0619\n",
      "08/21/2020 08:59:45 - INFO - __main__ -     steps: 11800  ppl: 8.2101\n",
      "08/21/2020 08:59:57 - INFO - __main__ -     steps: 11900  ppl: 8.0143\n",
      "08/21/2020 09:00:08 - INFO - __main__ -     steps: 12000  ppl: 7.9259\n",
      "08/21/2020 09:00:19 - INFO - __main__ -     steps: 12100  ppl: 7.6728\n",
      "08/21/2020 09:00:31 - INFO - __main__ -     steps: 12200  ppl: 7.3634\n",
      "08/21/2020 09:00:42 - INFO - __main__ -     steps: 12300  ppl: 7.7328\n",
      "08/21/2020 09:00:54 - INFO - __main__ -     steps: 12400  ppl: 7.8972\n",
      "08/21/2020 09:01:05 - INFO - __main__ -     steps: 12500  ppl: 7.365\n",
      "08/21/2020 09:01:16 - INFO - __main__ -     steps: 12600  ppl: 7.1554\n",
      "08/21/2020 09:01:28 - INFO - __main__ -     steps: 12700  ppl: 7.0709\n",
      "08/21/2020 09:01:39 - INFO - __main__ -     steps: 12800  ppl: 6.9788\n",
      "08/21/2020 09:01:50 - INFO - __main__ -     steps: 12900  ppl: 7.1565\n",
      "08/21/2020 09:02:02 - INFO - __main__ -     steps: 13000  ppl: 6.9555\n",
      "08/21/2020 09:02:13 - INFO - __main__ -     steps: 13100  ppl: 6.9634\n",
      "08/21/2020 09:02:24 - INFO - __main__ -     steps: 13200  ppl: 6.5742\n",
      "08/21/2020 09:02:35 - INFO - __main__ -     steps: 13300  ppl: 6.9685\n",
      "08/21/2020 09:02:47 - INFO - __main__ -     steps: 13400  ppl: 6.2749\n",
      "08/21/2020 09:02:58 - INFO - __main__ -     steps: 13500  ppl: 6.4225\n",
      "08/21/2020 09:03:09 - INFO - __main__ -     steps: 13600  ppl: 6.5072\n",
      "08/21/2020 09:03:20 - INFO - __main__ -     steps: 13700  ppl: 6.346\n",
      "08/21/2020 09:03:31 - INFO - __main__ -     steps: 13800  ppl: 6.3191\n",
      "08/21/2020 09:03:43 - INFO - __main__ -     steps: 13900  ppl: 6.2411\n",
      "08/21/2020 09:03:54 - INFO - __main__ -     steps: 14000  ppl: 6.2\n",
      "08/21/2020 09:04:06 - INFO - __main__ -     steps: 14100  ppl: 5.8475\n",
      "08/21/2020 09:04:17 - INFO - __main__ -     steps: 14200  ppl: 5.9935\n",
      "08/21/2020 09:04:28 - INFO - __main__ -     steps: 14300  ppl: 5.8055\n",
      "08/21/2020 09:04:40 - INFO - __main__ -     steps: 14400  ppl: 5.9853\n",
      "08/21/2020 09:04:51 - INFO - __main__ -     steps: 14500  ppl: 5.8661\n",
      "08/21/2020 09:05:02 - INFO - __main__ -     steps: 14600  ppl: 5.7879\n",
      "08/21/2020 09:05:14 - INFO - __main__ -     steps: 14700  ppl: 5.5783\n",
      "08/21/2020 09:05:25 - INFO - __main__ -     steps: 14800  ppl: 5.3641\n",
      "08/21/2020 09:05:36 - INFO - __main__ -     steps: 14900  ppl: 5.4656\n",
      "08/21/2020 09:05:48 - INFO - __main__ -     steps: 15000  ppl: 5.7944\n",
      "08/21/2020 09:05:59 - INFO - __main__ -     steps: 15100  ppl: 5.4989\n",
      "08/21/2020 09:06:11 - INFO - __main__ -     steps: 15200  ppl: 5.283\n",
      "08/21/2020 09:06:22 - INFO - __main__ -     steps: 15300  ppl: 5.7515\n",
      "08/21/2020 09:06:33 - INFO - __main__ -     steps: 15400  ppl: 5.2175\n",
      "08/21/2020 09:06:44 - INFO - __main__ -     steps: 15500  ppl: 5.4636\n",
      "08/21/2020 09:06:56 - INFO - __main__ -     steps: 15600  ppl: 5.562\n",
      "08/21/2020 09:07:08 - INFO - __main__ -     steps: 15700  ppl: 5.287\n",
      "08/21/2020 09:07:19 - INFO - __main__ -     steps: 15800  ppl: 5.2351\n",
      "08/21/2020 09:07:30 - INFO - __main__ -     steps: 15900  ppl: 5.1856\n",
      "08/21/2020 09:07:42 - INFO - __main__ -     steps: 16000  ppl: 5.3207\n",
      "08/21/2020 09:07:53 - INFO - __main__ -     steps: 16100  ppl: 5.1497\n",
      "08/21/2020 09:08:05 - INFO - __main__ -     steps: 16200  ppl: 5.25\n",
      "08/21/2020 09:08:17 - INFO - __main__ -     steps: 16300  ppl: 5.2216\n",
      "08/21/2020 09:08:28 - INFO - __main__ -     steps: 16400  ppl: 5.0687\n",
      "08/21/2020 09:08:39 - INFO - __main__ -     steps: 16500  ppl: 4.8685\n",
      "08/21/2020 09:08:51 - INFO - __main__ -     steps: 16600  ppl: 4.9619\n",
      "08/21/2020 09:09:02 - INFO - __main__ -     steps: 16700  ppl: 4.8614\n",
      "08/21/2020 09:09:13 - INFO - __main__ -     steps: 16800  ppl: 4.6072\n",
      "08/21/2020 09:09:25 - INFO - __main__ -     steps: 16900  ppl: 4.8804\n",
      "08/21/2020 09:09:36 - INFO - __main__ -     steps: 17000  ppl: 4.9452\n",
      "08/21/2020 09:09:48 - INFO - __main__ -     steps: 17100  ppl: 4.8137\n",
      "08/21/2020 09:09:59 - INFO - __main__ -     steps: 17200  ppl: 4.8215\n",
      "08/21/2020 09:10:11 - INFO - __main__ -     steps: 17300  ppl: 4.7871\n",
      "08/21/2020 09:10:22 - INFO - __main__ -     steps: 17400  ppl: 4.7864\n",
      "08/21/2020 09:10:34 - INFO - __main__ -     steps: 17500  ppl: 4.6248\n",
      "08/21/2020 09:10:45 - INFO - __main__ -     steps: 17600  ppl: 4.7085\n",
      "08/21/2020 09:10:57 - INFO - __main__ -     steps: 17700  ppl: 4.577\n",
      "08/21/2020 09:11:08 - INFO - __main__ -     steps: 17800  ppl: 4.6997\n",
      "08/21/2020 09:11:20 - INFO - __main__ -     steps: 17900  ppl: 4.4711\n",
      "08/21/2020 09:11:31 - INFO - __main__ -     steps: 18000  ppl: 4.5829\n",
      "08/21/2020 09:11:43 - INFO - __main__ -     steps: 18100  ppl: 4.5845\n",
      "08/21/2020 09:11:54 - INFO - __main__ -     steps: 18200  ppl: 4.3938\n",
      "08/21/2020 09:12:06 - INFO - __main__ -     steps: 18300  ppl: 4.4626\n",
      "08/21/2020 09:12:17 - INFO - __main__ -     steps: 18400  ppl: 4.444\n",
      "08/21/2020 09:12:29 - INFO - __main__ -     steps: 18500  ppl: 4.5657\n",
      "08/21/2020 09:12:40 - INFO - __main__ -     steps: 18600  ppl: 4.4181\n",
      "08/21/2020 09:12:52 - INFO - __main__ -     steps: 18700  ppl: 4.4953\n",
      "08/21/2020 09:13:03 - INFO - __main__ -     steps: 18800  ppl: 4.3647\n",
      "08/21/2020 09:13:14 - INFO - __main__ -     steps: 18900  ppl: 4.6189\n",
      "08/21/2020 09:13:26 - INFO - __main__ -     steps: 19000  ppl: 4.4865\n",
      "08/21/2020 09:13:37 - INFO - __main__ -     steps: 19100  ppl: 4.4212\n",
      "08/21/2020 09:13:49 - INFO - __main__ -     steps: 19200  ppl: 4.3532\n",
      "08/21/2020 09:14:00 - INFO - __main__ -     steps: 19300  ppl: 4.1753\n",
      "08/21/2020 09:14:12 - INFO - __main__ -     steps: 19400  ppl: 4.3093\n",
      "08/21/2020 09:14:23 - INFO - __main__ -     steps: 19500  ppl: 4.2631\n",
      "08/21/2020 09:14:34 - INFO - __main__ -     steps: 19600  ppl: 4.201\n",
      "08/21/2020 09:14:46 - INFO - __main__ -     steps: 19700  ppl: 4.1742\n",
      "08/21/2020 09:14:58 - INFO - __main__ -     steps: 19800  ppl: 4.1759\n",
      "08/21/2020 09:15:10 - INFO - __main__ -     steps: 19900  ppl: 4.4015\n",
      "08/21/2020 09:15:22 - INFO - __main__ -     steps: 20000  ppl: 3.9328\n",
      "08/21/2020 09:15:26 - INFO - __main__ -     perplexity = 3.9639\n",
      "08/21/2020 09:15:26 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-20000-3.9639/config.json\n",
      "08/21/2020 09:15:26 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-20000-3.9639/pytorch_model.bin\n",
      "08/21/2020 09:15:26 - INFO - __main__ -   Saving model checkpoint to Bert/saved_models/checkpoint-20000-3.9639\n",
      "08/21/2020 09:15:26 - INFO - __main__ -   Saving linear to Bert/saved_models/linear.bin\n",
      "08/21/2020 09:15:26 - INFO - __main__ -   Saving embeddings to Bert/saved_models/embeddings.bin\n",
      "08/21/2020 09:15:26 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-last/config.json\n",
      "08/21/2020 09:15:26 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-last/pytorch_model.bin\n",
      "08/21/2020 09:15:26 - INFO - __main__ -   Saving linear to Bert/saved_models/checkpoint-last/linear.bin\n",
      "08/21/2020 09:15:26 - INFO - __main__ -   Saving embeddings to Bert/saved_models/checkpoint-last/embeddings.bin\n",
      "08/21/2020 09:15:26 - INFO - __main__ -   Saving model to Bert/saved_models/checkpoint-last/model.bin\n",
      "08/21/2020 09:15:27 - INFO - __main__ -   Saving optimizer and scheduler states to Bert/saved_models/checkpoint-last\n",
      "08/21/2020 09:15:38 - INFO - __main__ -     steps: 20100  ppl: 4.0933\n",
      "08/21/2020 09:15:50 - INFO - __main__ -     steps: 20200  ppl: 4.1417\n",
      "08/21/2020 09:16:01 - INFO - __main__ -     steps: 20300  ppl: 4.2537\n",
      "08/21/2020 09:16:13 - INFO - __main__ -     steps: 20400  ppl: 4.1449\n",
      "08/21/2020 09:16:24 - INFO - __main__ -     steps: 20500  ppl: 4.0558\n",
      "08/21/2020 09:16:36 - INFO - __main__ -     steps: 20600  ppl: 4.3052\n",
      "08/21/2020 09:16:48 - INFO - __main__ -     steps: 20700  ppl: 4.1431\n",
      "08/21/2020 09:16:59 - INFO - __main__ -     steps: 20800  ppl: 3.9853\n",
      "08/21/2020 09:17:11 - INFO - __main__ -     steps: 20900  ppl: 4.1735\n",
      "08/21/2020 09:17:22 - INFO - __main__ -     steps: 21000  ppl: 4.2286\n",
      "08/21/2020 09:17:34 - INFO - __main__ -     steps: 21100  ppl: 4.0671\n",
      "08/21/2020 09:17:45 - INFO - __main__ -     steps: 21200  ppl: 3.8587\n",
      "08/21/2020 09:17:57 - INFO - __main__ -     steps: 21300  ppl: 3.9253\n",
      "08/21/2020 09:18:08 - INFO - __main__ -     steps: 21400  ppl: 4.0957\n",
      "08/21/2020 09:18:20 - INFO - __main__ -     steps: 21500  ppl: 4.2231\n",
      "08/21/2020 09:18:31 - INFO - __main__ -     steps: 21600  ppl: 4.0732\n",
      "08/21/2020 09:18:43 - INFO - __main__ -     steps: 21700  ppl: 3.9864\n",
      "08/21/2020 09:18:55 - INFO - __main__ -     steps: 21800  ppl: 3.9157\n",
      "08/21/2020 09:19:06 - INFO - __main__ -     steps: 21900  ppl: 3.9906\n",
      "08/21/2020 09:19:18 - INFO - __main__ -     steps: 22000  ppl: 3.8846\n",
      "08/21/2020 09:19:29 - INFO - __main__ -     steps: 22100  ppl: 3.9687\n",
      "08/21/2020 09:19:41 - INFO - __main__ -     steps: 22200  ppl: 3.9047\n",
      "08/21/2020 09:19:52 - INFO - __main__ -     steps: 22300  ppl: 3.7899\n",
      "08/21/2020 09:20:05 - INFO - __main__ -     steps: 22400  ppl: 3.8359\n",
      "08/21/2020 09:20:16 - INFO - __main__ -     steps: 22500  ppl: 4.0234\n",
      "08/21/2020 09:20:28 - INFO - __main__ -     steps: 22600  ppl: 3.8418\n",
      "08/21/2020 09:20:39 - INFO - __main__ -     steps: 22700  ppl: 3.8586\n",
      "08/21/2020 09:20:51 - INFO - __main__ -     steps: 22800  ppl: 3.8856\n",
      "08/21/2020 09:21:02 - INFO - __main__ -     steps: 22900  ppl: 3.8116\n",
      "08/21/2020 09:21:14 - INFO - __main__ -     steps: 23000  ppl: 3.6016\n",
      "08/21/2020 09:21:25 - INFO - __main__ -     steps: 23100  ppl: 3.8587\n",
      "08/21/2020 09:21:37 - INFO - __main__ -     steps: 23200  ppl: 3.9244\n",
      "08/21/2020 09:21:48 - INFO - __main__ -     steps: 23300  ppl: 3.7118\n",
      "08/21/2020 09:22:00 - INFO - __main__ -     steps: 23400  ppl: 3.7572\n",
      "08/21/2020 09:22:11 - INFO - __main__ -     steps: 23500  ppl: 3.749\n",
      "08/21/2020 09:22:23 - INFO - __main__ -     steps: 23600  ppl: 3.7125\n",
      "08/21/2020 09:22:34 - INFO - __main__ -     steps: 23700  ppl: 3.8098\n",
      "08/21/2020 09:22:46 - INFO - __main__ -     steps: 23800  ppl: 3.8019\n",
      "08/21/2020 09:22:57 - INFO - __main__ -     steps: 23900  ppl: 3.8493\n",
      "08/21/2020 09:23:08 - INFO - __main__ -     steps: 24000  ppl: 3.7848\n",
      "08/21/2020 09:23:19 - INFO - __main__ -     steps: 24100  ppl: 3.6678\n",
      "08/21/2020 09:23:31 - INFO - __main__ -     steps: 24200  ppl: 3.6357\n",
      "08/21/2020 09:23:42 - INFO - __main__ -     steps: 24300  ppl: 3.7742\n",
      "08/21/2020 09:23:54 - INFO - __main__ -     steps: 24400  ppl: 3.7416\n",
      "08/21/2020 09:24:05 - INFO - __main__ -     steps: 24500  ppl: 3.5811\n",
      "08/21/2020 09:24:17 - INFO - __main__ -     steps: 24600  ppl: 3.6001\n",
      "08/21/2020 09:24:28 - INFO - __main__ -     steps: 24700  ppl: 3.5246\n",
      "08/21/2020 09:24:40 - INFO - __main__ -     steps: 24800  ppl: 3.6284\n",
      "08/21/2020 09:24:51 - INFO - __main__ -     steps: 24900  ppl: 3.6699\n",
      "08/21/2020 09:25:03 - INFO - __main__ -     steps: 25000  ppl: 3.513\n",
      "08/21/2020 09:25:14 - INFO - __main__ -     steps: 25100  ppl: 3.595\n",
      "08/21/2020 09:25:26 - INFO - __main__ -     steps: 25200  ppl: 3.6753\n",
      "08/21/2020 09:25:37 - INFO - __main__ -     steps: 25300  ppl: 3.5762\n",
      "08/21/2020 09:25:48 - INFO - __main__ -     steps: 25400  ppl: 3.5402\n",
      "08/21/2020 09:26:00 - INFO - __main__ -     steps: 25500  ppl: 3.6257\n",
      "08/21/2020 09:26:11 - INFO - __main__ -     steps: 25600  ppl: 3.6854\n",
      "08/21/2020 09:26:22 - INFO - __main__ -     steps: 25700  ppl: 3.539\n",
      "08/21/2020 09:26:34 - INFO - __main__ -     steps: 25800  ppl: 3.5165\n",
      "08/21/2020 09:26:45 - INFO - __main__ -     steps: 25900  ppl: 3.5462\n",
      "08/21/2020 09:26:56 - INFO - __main__ -     steps: 26000  ppl: 3.6423\n",
      "08/21/2020 09:27:07 - INFO - __main__ -     steps: 26100  ppl: 3.5328\n",
      "08/21/2020 09:27:18 - INFO - __main__ -     steps: 26200  ppl: 3.5964\n",
      "08/21/2020 09:27:30 - INFO - __main__ -     steps: 26300  ppl: 3.5595\n",
      "08/21/2020 09:27:41 - INFO - __main__ -     steps: 26400  ppl: 3.5867\n",
      "08/21/2020 09:27:52 - INFO - __main__ -     steps: 26500  ppl: 3.4584\n",
      "08/21/2020 09:28:04 - INFO - __main__ -     steps: 26600  ppl: 3.4191\n",
      "08/21/2020 09:28:15 - INFO - __main__ -     steps: 26700  ppl: 3.5533\n",
      "08/21/2020 09:28:26 - INFO - __main__ -     steps: 26800  ppl: 3.3907\n",
      "08/21/2020 09:28:38 - INFO - __main__ -     steps: 26900  ppl: 3.4714\n",
      "08/21/2020 09:28:49 - INFO - __main__ -     steps: 27000  ppl: 3.4921\n",
      "08/21/2020 09:29:00 - INFO - __main__ -     steps: 27100  ppl: 3.4225\n",
      "08/21/2020 09:29:11 - INFO - __main__ -     steps: 27200  ppl: 3.5796\n",
      "08/21/2020 09:29:23 - INFO - __main__ -     steps: 27300  ppl: 3.4369\n",
      "08/21/2020 09:29:34 - INFO - __main__ -     steps: 27400  ppl: 3.4267\n",
      "08/21/2020 09:29:45 - INFO - __main__ -     steps: 27500  ppl: 3.4055\n",
      "08/21/2020 09:29:57 - INFO - __main__ -     steps: 27600  ppl: 3.3396\n",
      "08/21/2020 09:30:08 - INFO - __main__ -     steps: 27700  ppl: 3.4684\n",
      "08/21/2020 09:30:19 - INFO - __main__ -     steps: 27800  ppl: 3.4184\n",
      "08/21/2020 09:30:31 - INFO - __main__ -     steps: 27900  ppl: 3.3751\n",
      "08/21/2020 09:30:42 - INFO - __main__ -     steps: 28000  ppl: 3.4183\n",
      "08/21/2020 09:30:54 - INFO - __main__ -     steps: 28100  ppl: 3.4765\n",
      "08/21/2020 09:31:05 - INFO - __main__ -     steps: 28200  ppl: 3.3387\n",
      "08/21/2020 09:31:17 - INFO - __main__ -     steps: 28300  ppl: 3.2682\n",
      "08/21/2020 09:31:28 - INFO - __main__ -     steps: 28400  ppl: 3.4088\n",
      "08/21/2020 09:31:40 - INFO - __main__ -     steps: 28500  ppl: 3.3686\n",
      "08/21/2020 09:31:52 - INFO - __main__ -     steps: 28600  ppl: 3.4885\n",
      "08/21/2020 09:32:03 - INFO - __main__ -     steps: 28700  ppl: 3.5306\n",
      "08/21/2020 09:32:15 - INFO - __main__ -     steps: 28800  ppl: 3.2966\n",
      "08/21/2020 09:32:26 - INFO - __main__ -     steps: 28900  ppl: 3.4462\n",
      "08/21/2020 09:32:37 - INFO - __main__ -     steps: 29000  ppl: 3.3307\n",
      "08/21/2020 09:32:49 - INFO - __main__ -     steps: 29100  ppl: 3.2009\n",
      "08/21/2020 09:33:01 - INFO - __main__ -     steps: 29200  ppl: 3.4086\n",
      "08/21/2020 09:33:12 - INFO - __main__ -     steps: 29300  ppl: 3.3293\n",
      "08/21/2020 09:33:23 - INFO - __main__ -     steps: 29400  ppl: 3.3251\n",
      "08/21/2020 09:33:35 - INFO - __main__ -     steps: 29500  ppl: 3.4213\n",
      "08/21/2020 09:33:46 - INFO - __main__ -     steps: 29600  ppl: 3.3676\n",
      "08/21/2020 09:33:58 - INFO - __main__ -     steps: 29700  ppl: 3.3413\n",
      "08/21/2020 09:34:09 - INFO - __main__ -     steps: 29800  ppl: 3.2495\n",
      "08/21/2020 09:34:21 - INFO - __main__ -     steps: 29900  ppl: 3.3507\n",
      "08/21/2020 09:34:32 - INFO - __main__ -     steps: 30000  ppl: 3.3513\n",
      "08/21/2020 09:34:37 - INFO - __main__ -     perplexity = 3.1798\n",
      "08/21/2020 09:34:37 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-30000-3.1798/config.json\n",
      "08/21/2020 09:34:37 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-30000-3.1798/pytorch_model.bin\n",
      "08/21/2020 09:34:37 - INFO - __main__ -   Saving model checkpoint to Bert/saved_models/checkpoint-30000-3.1798\n",
      "08/21/2020 09:34:37 - INFO - __main__ -   Saving linear to Bert/saved_models/linear.bin\n",
      "08/21/2020 09:34:37 - INFO - __main__ -   Saving embeddings to Bert/saved_models/embeddings.bin\n",
      "08/21/2020 09:34:37 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-last/config.json\n",
      "08/21/2020 09:34:37 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-last/pytorch_model.bin\n",
      "08/21/2020 09:34:37 - INFO - __main__ -   Saving linear to Bert/saved_models/checkpoint-last/linear.bin\n",
      "08/21/2020 09:34:37 - INFO - __main__ -   Saving embeddings to Bert/saved_models/checkpoint-last/embeddings.bin\n",
      "08/21/2020 09:34:37 - INFO - __main__ -   Saving model to Bert/saved_models/checkpoint-last/model.bin\n",
      "08/21/2020 09:34:37 - INFO - __main__ -   Saving optimizer and scheduler states to Bert/saved_models/checkpoint-last\n",
      "08/21/2020 09:34:49 - INFO - __main__ -     steps: 30100  ppl: 3.3704\n",
      "08/21/2020 09:35:01 - INFO - __main__ -     steps: 30200  ppl: 3.2152\n",
      "08/21/2020 09:35:12 - INFO - __main__ -     steps: 30300  ppl: 3.2521\n",
      "08/21/2020 09:35:24 - INFO - __main__ -     steps: 30400  ppl: 3.2928\n",
      "08/21/2020 09:35:35 - INFO - __main__ -     steps: 30500  ppl: 3.1903\n",
      "08/21/2020 09:35:47 - INFO - __main__ -     steps: 30600  ppl: 3.2427\n",
      "08/21/2020 09:35:59 - INFO - __main__ -     steps: 30700  ppl: 3.2836\n",
      "08/21/2020 09:36:11 - INFO - __main__ -     steps: 30800  ppl: 3.2417\n",
      "08/21/2020 09:36:22 - INFO - __main__ -     steps: 30900  ppl: 3.3188\n",
      "08/21/2020 09:36:34 - INFO - __main__ -     steps: 31000  ppl: 3.1803\n",
      "08/21/2020 09:36:46 - INFO - __main__ -     steps: 31100  ppl: 3.1256\n",
      "08/21/2020 09:36:57 - INFO - __main__ -     steps: 31200  ppl: 3.2089\n",
      "08/21/2020 09:37:09 - INFO - __main__ -     steps: 31300  ppl: 3.3186\n",
      "08/21/2020 09:37:20 - INFO - __main__ -     steps: 31400  ppl: 3.209\n",
      "08/21/2020 09:37:32 - INFO - __main__ -     steps: 31500  ppl: 3.2163\n",
      "08/21/2020 09:37:44 - INFO - __main__ -     steps: 31600  ppl: 3.2574\n",
      "08/21/2020 09:37:55 - INFO - __main__ -     steps: 31700  ppl: 3.1723\n",
      "08/21/2020 09:38:07 - INFO - __main__ -     steps: 31800  ppl: 3.1094\n",
      "08/21/2020 09:38:18 - INFO - __main__ -     steps: 31900  ppl: 3.204\n",
      "08/21/2020 09:38:30 - INFO - __main__ -     steps: 32000  ppl: 3.1029\n",
      "08/21/2020 09:38:41 - INFO - __main__ -     steps: 32100  ppl: 3.2691\n",
      "08/21/2020 09:38:53 - INFO - __main__ -     steps: 32200  ppl: 3.2319\n",
      "08/21/2020 09:39:04 - INFO - __main__ -     steps: 32300  ppl: 3.1036\n",
      "08/21/2020 09:39:16 - INFO - __main__ -     steps: 32400  ppl: 3.1379\n",
      "08/21/2020 09:39:28 - INFO - __main__ -     steps: 32500  ppl: 3.2003\n",
      "08/21/2020 09:39:40 - INFO - __main__ -     steps: 32600  ppl: 3.0787\n",
      "08/21/2020 09:39:51 - INFO - __main__ -     steps: 32700  ppl: 3.1193\n",
      "08/21/2020 09:40:03 - INFO - __main__ -     steps: 32800  ppl: 3.1182\n",
      "08/21/2020 09:40:15 - INFO - __main__ -     steps: 32900  ppl: 3.1594\n",
      "08/21/2020 09:40:26 - INFO - __main__ -     steps: 33000  ppl: 3.2423\n",
      "08/21/2020 09:40:38 - INFO - __main__ -     steps: 33100  ppl: 3.1135\n",
      "08/21/2020 09:40:49 - INFO - __main__ -     steps: 33200  ppl: 3.125\n",
      "08/21/2020 09:41:01 - INFO - __main__ -     steps: 33300  ppl: 3.2341\n",
      "08/21/2020 09:41:13 - INFO - __main__ -     steps: 33400  ppl: 3.1186\n",
      "08/21/2020 09:41:24 - INFO - __main__ -     steps: 33500  ppl: 3.1685\n",
      "08/21/2020 09:41:36 - INFO - __main__ -     steps: 33600  ppl: 3.1724\n",
      "08/21/2020 09:41:48 - INFO - __main__ -     steps: 33700  ppl: 3.0657\n",
      "08/21/2020 09:42:00 - INFO - __main__ -     steps: 33800  ppl: 3.1374\n",
      "08/21/2020 09:42:11 - INFO - __main__ -     steps: 33900  ppl: 3.1377\n",
      "08/21/2020 09:42:23 - INFO - __main__ -     steps: 34000  ppl: 3.074\n",
      "08/21/2020 09:42:34 - INFO - __main__ -     steps: 34100  ppl: 3.0826\n",
      "08/21/2020 09:42:46 - INFO - __main__ -     steps: 34200  ppl: 3.1562\n",
      "08/21/2020 09:42:58 - INFO - __main__ -     steps: 34300  ppl: 3.0318\n",
      "08/21/2020 09:43:09 - INFO - __main__ -     steps: 34400  ppl: 3.1485\n",
      "08/21/2020 09:43:20 - INFO - __main__ -     steps: 34500  ppl: 3.0448\n",
      "08/21/2020 09:43:32 - INFO - __main__ -     steps: 34600  ppl: 3.0748\n",
      "08/21/2020 09:43:44 - INFO - __main__ -     steps: 34700  ppl: 3.212\n",
      "08/21/2020 09:43:55 - INFO - __main__ -     steps: 34800  ppl: 3.1353\n",
      "08/21/2020 09:44:06 - INFO - __main__ -     steps: 34900  ppl: 3.1108\n",
      "08/21/2020 09:44:17 - INFO - __main__ -     steps: 35000  ppl: 3.0301\n",
      "08/21/2020 09:44:29 - INFO - __main__ -     steps: 35100  ppl: 3.0631\n",
      "08/21/2020 09:44:40 - INFO - __main__ -     steps: 35200  ppl: 3.0657\n",
      "08/21/2020 09:44:52 - INFO - __main__ -     steps: 35300  ppl: 2.9931\n",
      "08/21/2020 09:45:03 - INFO - __main__ -     steps: 35400  ppl: 3.0593\n",
      "08/21/2020 09:45:14 - INFO - __main__ -     steps: 35500  ppl: 3.183\n",
      "08/21/2020 09:45:26 - INFO - __main__ -     steps: 35600  ppl: 2.9378\n",
      "08/21/2020 09:45:38 - INFO - __main__ -     steps: 35700  ppl: 3.1256\n",
      "08/21/2020 09:45:49 - INFO - __main__ -     steps: 35800  ppl: 2.9968\n",
      "08/21/2020 09:46:00 - INFO - __main__ -     steps: 35900  ppl: 2.998\n",
      "08/21/2020 09:46:12 - INFO - __main__ -     steps: 36000  ppl: 3.1701\n",
      "08/21/2020 09:46:24 - INFO - __main__ -     steps: 36100  ppl: 3.0694\n",
      "08/21/2020 09:46:35 - INFO - __main__ -     steps: 36200  ppl: 2.8856\n",
      "08/21/2020 09:46:46 - INFO - __main__ -     steps: 36300  ppl: 2.9756\n",
      "08/21/2020 09:46:58 - INFO - __main__ -     steps: 36400  ppl: 3.0764\n",
      "08/21/2020 09:47:10 - INFO - __main__ -     steps: 36500  ppl: 2.8853\n",
      "08/21/2020 09:47:21 - INFO - __main__ -     steps: 36600  ppl: 3.1065\n",
      "08/21/2020 09:47:33 - INFO - __main__ -     steps: 36700  ppl: 3.0064\n",
      "08/21/2020 09:47:45 - INFO - __main__ -     steps: 36800  ppl: 3.1215\n",
      "08/21/2020 09:47:56 - INFO - __main__ -     steps: 36900  ppl: 3.0904\n",
      "08/21/2020 09:48:07 - INFO - __main__ -     steps: 37000  ppl: 3.0607\n",
      "08/21/2020 09:48:19 - INFO - __main__ -     steps: 37100  ppl: 2.9813\n",
      "08/21/2020 09:48:30 - INFO - __main__ -     steps: 37200  ppl: 3.0304\n",
      "08/21/2020 09:48:42 - INFO - __main__ -     steps: 37300  ppl: 3.0033\n",
      "08/21/2020 09:48:53 - INFO - __main__ -     steps: 37400  ppl: 2.9834\n",
      "08/21/2020 09:49:04 - INFO - __main__ -     steps: 37500  ppl: 3.1402\n",
      "08/21/2020 09:49:16 - INFO - __main__ -     steps: 37600  ppl: 2.9569\n",
      "08/21/2020 09:49:27 - INFO - __main__ -     steps: 37700  ppl: 3.1492\n",
      "08/21/2020 09:49:39 - INFO - __main__ -     steps: 37800  ppl: 2.9855\n",
      "08/21/2020 09:49:50 - INFO - __main__ -     steps: 37900  ppl: 2.9733\n",
      "08/21/2020 09:50:01 - INFO - __main__ -     steps: 38000  ppl: 2.9761\n",
      "08/21/2020 09:50:13 - INFO - __main__ -     steps: 38100  ppl: 2.9523\n",
      "08/21/2020 09:50:25 - INFO - __main__ -     steps: 38200  ppl: 3.0032\n",
      "08/21/2020 09:50:36 - INFO - __main__ -     steps: 38300  ppl: 3.1816\n",
      "08/21/2020 09:50:47 - INFO - __main__ -     steps: 38400  ppl: 2.9244\n",
      "08/21/2020 09:50:59 - INFO - __main__ -     steps: 38500  ppl: 2.9763\n",
      "08/21/2020 09:51:11 - INFO - __main__ -     steps: 38600  ppl: 3.0099\n",
      "08/21/2020 09:51:22 - INFO - __main__ -     steps: 38700  ppl: 3.0316\n",
      "08/21/2020 09:51:34 - INFO - __main__ -     steps: 38800  ppl: 2.9203\n",
      "08/21/2020 09:51:46 - INFO - __main__ -     steps: 38900  ppl: 3.045\n",
      "08/21/2020 09:51:58 - INFO - __main__ -     steps: 39000  ppl: 2.947\n",
      "08/21/2020 09:52:09 - INFO - __main__ -     steps: 39100  ppl: 2.9109\n",
      "08/21/2020 09:52:21 - INFO - __main__ -     steps: 39200  ppl: 2.9727\n",
      "08/21/2020 09:52:32 - INFO - __main__ -     steps: 39300  ppl: 2.937\n",
      "08/21/2020 09:52:43 - INFO - __main__ -     steps: 39400  ppl: 2.9759\n",
      "08/21/2020 09:52:55 - INFO - __main__ -     steps: 39500  ppl: 2.9411\n",
      "08/21/2020 09:53:06 - INFO - __main__ -     steps: 39600  ppl: 3.0337\n",
      "08/21/2020 09:53:18 - INFO - __main__ -     steps: 39700  ppl: 2.9261\n",
      "08/21/2020 09:53:29 - INFO - __main__ -     steps: 39800  ppl: 2.8994\n",
      "08/21/2020 09:53:41 - INFO - __main__ -     steps: 39900  ppl: 2.8495\n",
      "08/21/2020 09:53:53 - INFO - __main__ -     steps: 40000  ppl: 2.9296\n",
      "08/21/2020 09:53:57 - INFO - __main__ -     perplexity = 2.8219\n",
      "08/21/2020 09:53:57 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-40000-2.8219/config.json\n",
      "08/21/2020 09:53:57 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-40000-2.8219/pytorch_model.bin\n",
      "08/21/2020 09:53:57 - INFO - __main__ -   Saving model checkpoint to Bert/saved_models/checkpoint-40000-2.8219\n",
      "08/21/2020 09:53:57 - INFO - __main__ -   Saving linear to Bert/saved_models/linear.bin\n",
      "08/21/2020 09:53:57 - INFO - __main__ -   Saving embeddings to Bert/saved_models/embeddings.bin\n",
      "08/21/2020 09:53:57 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-last/config.json\n",
      "08/21/2020 09:53:57 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-last/pytorch_model.bin\n",
      "08/21/2020 09:53:57 - INFO - __main__ -   Saving linear to Bert/saved_models/checkpoint-last/linear.bin\n",
      "08/21/2020 09:53:57 - INFO - __main__ -   Saving embeddings to Bert/saved_models/checkpoint-last/embeddings.bin\n",
      "08/21/2020 09:53:57 - INFO - __main__ -   Saving model to Bert/saved_models/checkpoint-last/model.bin\n",
      "08/21/2020 09:53:58 - INFO - __main__ -   Saving optimizer and scheduler states to Bert/saved_models/checkpoint-last\n",
      "08/21/2020 09:54:10 - INFO - __main__ -     steps: 40100  ppl: 3.0648\n",
      "08/21/2020 09:54:21 - INFO - __main__ -     steps: 40200  ppl: 2.9482\n",
      "08/21/2020 09:54:33 - INFO - __main__ -     steps: 40300  ppl: 2.8816\n",
      "08/21/2020 09:54:44 - INFO - __main__ -     steps: 40400  ppl: 2.9312\n",
      "08/21/2020 09:54:56 - INFO - __main__ -     steps: 40500  ppl: 2.9189\n",
      "08/21/2020 09:55:07 - INFO - __main__ -     steps: 40600  ppl: 2.9493\n",
      "08/21/2020 09:55:19 - INFO - __main__ -     steps: 40700  ppl: 2.844\n",
      "08/21/2020 09:55:30 - INFO - __main__ -     steps: 40800  ppl: 2.9398\n",
      "08/21/2020 09:55:42 - INFO - __main__ -     steps: 40900  ppl: 2.9195\n",
      "08/21/2020 09:55:54 - INFO - __main__ -     steps: 41000  ppl: 2.8247\n",
      "08/21/2020 09:56:05 - INFO - __main__ -     steps: 41100  ppl: 2.8545\n",
      "08/21/2020 09:56:17 - INFO - __main__ -     steps: 41200  ppl: 2.9591\n",
      "08/21/2020 09:56:28 - INFO - __main__ -     steps: 41300  ppl: 2.8966\n",
      "08/21/2020 09:56:40 - INFO - __main__ -     steps: 41400  ppl: 2.8661\n",
      "08/21/2020 09:56:51 - INFO - __main__ -     steps: 41500  ppl: 2.8297\n",
      "08/21/2020 09:57:03 - INFO - __main__ -     steps: 41600  ppl: 2.94\n",
      "08/21/2020 09:57:15 - INFO - __main__ -     steps: 41700  ppl: 2.9845\n",
      "08/21/2020 09:57:26 - INFO - __main__ -     steps: 41800  ppl: 2.8007\n",
      "08/21/2020 09:57:38 - INFO - __main__ -     steps: 41900  ppl: 2.8511\n",
      "08/21/2020 09:57:49 - INFO - __main__ -     steps: 42000  ppl: 2.9449\n",
      "08/21/2020 09:58:01 - INFO - __main__ -     steps: 42100  ppl: 2.8518\n",
      "08/21/2020 09:58:13 - INFO - __main__ -     steps: 42200  ppl: 2.8341\n",
      "08/21/2020 09:58:25 - INFO - __main__ -     steps: 42300  ppl: 2.8576\n",
      "08/21/2020 09:58:36 - INFO - __main__ -     steps: 42400  ppl: 2.8391\n",
      "08/21/2020 09:58:48 - INFO - __main__ -     steps: 42500  ppl: 2.8903\n",
      "08/21/2020 09:59:00 - INFO - __main__ -     steps: 42600  ppl: 2.8985\n",
      "08/21/2020 09:59:12 - INFO - __main__ -     steps: 42700  ppl: 2.9236\n",
      "08/21/2020 09:59:24 - INFO - __main__ -     steps: 42800  ppl: 2.9546\n",
      "08/21/2020 09:59:35 - INFO - __main__ -     steps: 42900  ppl: 2.7704\n",
      "08/21/2020 09:59:47 - INFO - __main__ -     steps: 43000  ppl: 2.7875\n",
      "08/21/2020 09:59:59 - INFO - __main__ -     steps: 43100  ppl: 2.8107\n",
      "08/21/2020 10:00:10 - INFO - __main__ -     steps: 43200  ppl: 2.8439\n",
      "08/21/2020 10:00:22 - INFO - __main__ -     steps: 43300  ppl: 2.8981\n",
      "08/21/2020 10:00:34 - INFO - __main__ -     steps: 43400  ppl: 2.9\n",
      "08/21/2020 10:00:45 - INFO - __main__ -     steps: 43500  ppl: 2.9363\n",
      "08/21/2020 10:00:57 - INFO - __main__ -     steps: 43600  ppl: 2.9416\n",
      "08/21/2020 10:01:08 - INFO - __main__ -     steps: 43700  ppl: 2.7735\n",
      "08/21/2020 10:01:20 - INFO - __main__ -     steps: 43800  ppl: 2.866\n",
      "08/21/2020 10:01:32 - INFO - __main__ -     steps: 43900  ppl: 2.8824\n",
      "08/21/2020 10:01:44 - INFO - __main__ -     steps: 44000  ppl: 2.8776\n",
      "08/21/2020 10:01:56 - INFO - __main__ -     steps: 44100  ppl: 2.9019\n",
      "08/21/2020 10:02:08 - INFO - __main__ -     steps: 44200  ppl: 2.808\n",
      "08/21/2020 10:02:19 - INFO - __main__ -     steps: 44300  ppl: 2.7976\n",
      "08/21/2020 10:02:31 - INFO - __main__ -     steps: 44400  ppl: 2.9156\n",
      "08/21/2020 10:02:43 - INFO - __main__ -     steps: 44500  ppl: 2.6936\n",
      "08/21/2020 10:02:54 - INFO - __main__ -     steps: 44600  ppl: 2.7194\n",
      "08/21/2020 10:03:06 - INFO - __main__ -     steps: 44700  ppl: 2.7711\n",
      "08/21/2020 10:03:18 - INFO - __main__ -     steps: 44800  ppl: 2.8776\n",
      "08/21/2020 10:03:30 - INFO - __main__ -     steps: 44900  ppl: 2.736\n",
      "08/21/2020 10:03:42 - INFO - __main__ -     steps: 45000  ppl: 2.8758\n",
      "08/21/2020 10:03:54 - INFO - __main__ -     steps: 45100  ppl: 2.8472\n",
      "08/21/2020 10:04:06 - INFO - __main__ -     steps: 45200  ppl: 2.8392\n",
      "08/21/2020 10:04:17 - INFO - __main__ -     steps: 45300  ppl: 2.7878\n",
      "08/21/2020 10:04:29 - INFO - __main__ -     steps: 45400  ppl: 2.7808\n",
      "08/21/2020 10:04:41 - INFO - __main__ -     steps: 45500  ppl: 2.6698\n",
      "08/21/2020 10:04:52 - INFO - __main__ -     steps: 45600  ppl: 2.845\n",
      "08/21/2020 10:05:04 - INFO - __main__ -     steps: 45700  ppl: 2.8635\n",
      "08/21/2020 10:05:16 - INFO - __main__ -     steps: 45800  ppl: 2.8432\n",
      "08/21/2020 10:05:27 - INFO - __main__ -     steps: 45900  ppl: 2.9317\n",
      "08/21/2020 10:05:40 - INFO - __main__ -     steps: 46000  ppl: 2.7557\n",
      "08/21/2020 10:05:51 - INFO - __main__ -     steps: 46100  ppl: 2.8045\n",
      "08/21/2020 10:06:03 - INFO - __main__ -     steps: 46200  ppl: 2.7061\n",
      "08/21/2020 10:06:15 - INFO - __main__ -     steps: 46300  ppl: 2.8805\n",
      "08/21/2020 10:06:26 - INFO - __main__ -     steps: 46400  ppl: 2.7529\n",
      "08/21/2020 10:06:38 - INFO - __main__ -     steps: 46500  ppl: 2.8483\n",
      "08/21/2020 10:06:50 - INFO - __main__ -     steps: 46600  ppl: 2.7066\n",
      "08/21/2020 10:07:01 - INFO - __main__ -     steps: 46700  ppl: 2.8896\n",
      "08/21/2020 10:07:13 - INFO - __main__ -     steps: 46800  ppl: 2.911\n",
      "08/21/2020 10:07:25 - INFO - __main__ -     steps: 46900  ppl: 2.862\n",
      "08/21/2020 10:07:37 - INFO - __main__ -     steps: 47000  ppl: 2.7601\n",
      "08/21/2020 10:07:48 - INFO - __main__ -     steps: 47100  ppl: 2.7145\n",
      "08/21/2020 10:08:00 - INFO - __main__ -     steps: 47200  ppl: 2.7005\n",
      "08/21/2020 10:08:12 - INFO - __main__ -     steps: 47300  ppl: 2.7263\n",
      "08/21/2020 10:08:24 - INFO - __main__ -     steps: 47400  ppl: 2.7393\n",
      "08/21/2020 10:08:35 - INFO - __main__ -     steps: 47500  ppl: 2.8363\n",
      "08/21/2020 10:08:47 - INFO - __main__ -     steps: 47600  ppl: 2.7484\n",
      "08/21/2020 10:08:59 - INFO - __main__ -     steps: 47700  ppl: 2.8326\n",
      "08/21/2020 10:09:10 - INFO - __main__ -     steps: 47800  ppl: 2.8029\n",
      "08/21/2020 10:09:22 - INFO - __main__ -     steps: 47900  ppl: 2.7753\n",
      "08/21/2020 10:09:34 - INFO - __main__ -     steps: 48000  ppl: 2.8908\n",
      "08/21/2020 10:09:45 - INFO - __main__ -     steps: 48100  ppl: 2.6964\n",
      "08/21/2020 10:09:57 - INFO - __main__ -     steps: 48200  ppl: 2.8008\n",
      "08/21/2020 10:10:09 - INFO - __main__ -     steps: 48300  ppl: 2.788\n",
      "08/21/2020 10:10:20 - INFO - __main__ -     steps: 48400  ppl: 2.8099\n",
      "08/21/2020 10:10:32 - INFO - __main__ -     steps: 48500  ppl: 2.7056\n",
      "08/21/2020 10:10:43 - INFO - __main__ -     steps: 48600  ppl: 2.7014\n",
      "08/21/2020 10:10:55 - INFO - __main__ -     steps: 48700  ppl: 2.7142\n",
      "08/21/2020 10:11:06 - INFO - __main__ -     steps: 48800  ppl: 2.6685\n",
      "08/21/2020 10:11:18 - INFO - __main__ -     steps: 48900  ppl: 2.7536\n",
      "08/21/2020 10:11:29 - INFO - __main__ -     steps: 49000  ppl: 2.6854\n",
      "08/21/2020 10:11:41 - INFO - __main__ -     steps: 49100  ppl: 2.6786\n",
      "08/21/2020 10:11:53 - INFO - __main__ -     steps: 49200  ppl: 2.8303\n",
      "08/21/2020 10:12:04 - INFO - __main__ -     steps: 49300  ppl: 2.7749\n",
      "08/21/2020 10:12:16 - INFO - __main__ -     steps: 49400  ppl: 2.8174\n",
      "08/21/2020 10:12:27 - INFO - __main__ -     steps: 49500  ppl: 2.7591\n",
      "08/21/2020 10:12:39 - INFO - __main__ -     steps: 49600  ppl: 2.7541\n",
      "08/21/2020 10:12:51 - INFO - __main__ -     steps: 49700  ppl: 2.7268\n",
      "08/21/2020 10:13:03 - INFO - __main__ -     steps: 49800  ppl: 2.7656\n",
      "08/21/2020 10:13:15 - INFO - __main__ -     steps: 49900  ppl: 2.7758\n",
      "08/21/2020 10:13:27 - INFO - __main__ -     steps: 50000  ppl: 2.7841\n",
      "08/21/2020 10:13:31 - INFO - __main__ -     perplexity = 2.6156\n",
      "08/21/2020 10:13:31 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-50000-2.6156/config.json\n",
      "08/21/2020 10:13:31 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-50000-2.6156/pytorch_model.bin\n",
      "08/21/2020 10:13:31 - INFO - __main__ -   Saving model checkpoint to Bert/saved_models/checkpoint-50000-2.6156\n",
      "08/21/2020 10:13:31 - INFO - __main__ -   Saving linear to Bert/saved_models/linear.bin\n",
      "08/21/2020 10:13:31 - INFO - __main__ -   Saving embeddings to Bert/saved_models/embeddings.bin\n",
      "08/21/2020 10:13:31 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-last/config.json\n",
      "08/21/2020 10:13:31 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-last/pytorch_model.bin\n",
      "08/21/2020 10:13:31 - INFO - __main__ -   Saving linear to Bert/saved_models/checkpoint-last/linear.bin\n",
      "08/21/2020 10:13:31 - INFO - __main__ -   Saving embeddings to Bert/saved_models/checkpoint-last/embeddings.bin\n",
      "08/21/2020 10:13:31 - INFO - __main__ -   Saving model to Bert/saved_models/checkpoint-last/model.bin\n",
      "08/21/2020 10:13:32 - INFO - __main__ -   Saving optimizer and scheduler states to Bert/saved_models/checkpoint-last\n",
      "08/21/2020 10:13:43 - INFO - __main__ -     steps: 50100  ppl: 2.7347\n",
      "08/21/2020 10:13:55 - INFO - __main__ -     steps: 50200  ppl: 2.6812\n",
      "08/21/2020 10:14:06 - INFO - __main__ -     steps: 50300  ppl: 2.7751\n",
      "08/21/2020 10:14:18 - INFO - __main__ -     steps: 50400  ppl: 2.6878\n",
      "08/21/2020 10:14:30 - INFO - __main__ -     steps: 50500  ppl: 2.7882\n",
      "08/21/2020 10:14:42 - INFO - __main__ -     steps: 50600  ppl: 2.7225\n",
      "08/21/2020 10:14:53 - INFO - __main__ -     steps: 50700  ppl: 2.7352\n",
      "08/21/2020 10:15:05 - INFO - __main__ -     steps: 50800  ppl: 2.7285\n",
      "08/21/2020 10:15:16 - INFO - __main__ -     steps: 50900  ppl: 2.7991\n",
      "08/21/2020 10:15:28 - INFO - __main__ -     steps: 51000  ppl: 2.7621\n",
      "08/21/2020 10:15:40 - INFO - __main__ -     steps: 51100  ppl: 2.8348\n",
      "08/21/2020 10:15:51 - INFO - __main__ -     steps: 51200  ppl: 2.7473\n",
      "08/21/2020 10:16:03 - INFO - __main__ -     steps: 51300  ppl: 2.7932\n",
      "08/21/2020 10:16:15 - INFO - __main__ -     steps: 51400  ppl: 2.7781\n",
      "08/21/2020 10:16:26 - INFO - __main__ -     steps: 51500  ppl: 2.6933\n",
      "08/21/2020 10:16:38 - INFO - __main__ -     steps: 51600  ppl: 2.7044\n",
      "08/21/2020 10:16:49 - INFO - __main__ -     steps: 51700  ppl: 2.7823\n",
      "08/21/2020 10:17:01 - INFO - __main__ -     steps: 51800  ppl: 2.6994\n",
      "08/21/2020 10:17:12 - INFO - __main__ -     steps: 51900  ppl: 2.6587\n",
      "08/21/2020 10:17:24 - INFO - __main__ -     steps: 52000  ppl: 2.7407\n",
      "08/21/2020 10:17:36 - INFO - __main__ -     steps: 52100  ppl: 2.6677\n",
      "08/21/2020 10:17:48 - INFO - __main__ -     steps: 52200  ppl: 2.7261\n",
      "08/21/2020 10:17:59 - INFO - __main__ -     steps: 52300  ppl: 2.67\n",
      "08/21/2020 10:18:11 - INFO - __main__ -     steps: 52400  ppl: 2.7449\n",
      "08/21/2020 10:18:23 - INFO - __main__ -     steps: 52500  ppl: 2.7649\n",
      "08/21/2020 10:18:35 - INFO - __main__ -     steps: 52600  ppl: 2.673\n",
      "08/21/2020 10:18:46 - INFO - __main__ -     steps: 52700  ppl: 2.6607\n",
      "08/21/2020 10:18:58 - INFO - __main__ -     steps: 52800  ppl: 2.698\n",
      "08/21/2020 10:19:09 - INFO - __main__ -     steps: 52900  ppl: 2.722\n",
      "08/21/2020 10:19:21 - INFO - __main__ -     steps: 53000  ppl: 2.681\n",
      "08/21/2020 10:19:32 - INFO - __main__ -     steps: 53100  ppl: 2.6891\n",
      "08/21/2020 10:19:44 - INFO - __main__ -     steps: 53200  ppl: 2.7706\n",
      "08/21/2020 10:19:56 - INFO - __main__ -     steps: 53300  ppl: 2.7162\n",
      "08/21/2020 10:20:07 - INFO - __main__ -     steps: 53400  ppl: 2.7181\n",
      "08/21/2020 10:20:19 - INFO - __main__ -     steps: 53500  ppl: 2.6039\n",
      "08/21/2020 10:20:31 - INFO - __main__ -     steps: 53600  ppl: 2.6219\n",
      "08/21/2020 10:20:43 - INFO - __main__ -     steps: 53700  ppl: 2.7266\n",
      "08/21/2020 10:20:54 - INFO - __main__ -     steps: 53800  ppl: 2.7561\n",
      "08/21/2020 10:21:06 - INFO - __main__ -     steps: 53900  ppl: 2.6442\n",
      "08/21/2020 10:21:17 - INFO - __main__ -     steps: 54000  ppl: 2.7067\n",
      "08/21/2020 10:21:29 - INFO - __main__ -     steps: 54100  ppl: 2.7002\n",
      "08/21/2020 10:21:41 - INFO - __main__ -     steps: 54200  ppl: 2.5985\n",
      "08/21/2020 10:21:52 - INFO - __main__ -     steps: 54300  ppl: 2.7724\n",
      "08/21/2020 10:22:04 - INFO - __main__ -     steps: 54400  ppl: 2.7111\n",
      "08/21/2020 10:22:15 - INFO - __main__ -     steps: 54500  ppl: 2.7906\n",
      "08/21/2020 10:22:27 - INFO - __main__ -     steps: 54600  ppl: 2.7782\n",
      "08/21/2020 10:22:39 - INFO - __main__ -     steps: 54700  ppl: 2.791\n",
      "08/21/2020 10:22:51 - INFO - __main__ -     steps: 54800  ppl: 2.7359\n",
      "08/21/2020 10:23:03 - INFO - __main__ -     steps: 54900  ppl: 2.6901\n",
      "08/21/2020 10:23:14 - INFO - __main__ -     steps: 55000  ppl: 2.737\n",
      "08/21/2020 10:23:26 - INFO - __main__ -     steps: 55100  ppl: 2.6856\n",
      "08/21/2020 10:23:38 - INFO - __main__ -     steps: 55200  ppl: 2.7021\n",
      "08/21/2020 10:23:50 - INFO - __main__ -     steps: 55300  ppl: 2.6554\n",
      "08/21/2020 10:24:02 - INFO - __main__ -     steps: 55400  ppl: 2.6564\n",
      "08/21/2020 10:24:13 - INFO - __main__ -     steps: 55500  ppl: 2.7304\n",
      "08/21/2020 10:24:25 - INFO - __main__ -     steps: 55600  ppl: 2.6814\n",
      "08/21/2020 10:24:37 - INFO - __main__ -     steps: 55700  ppl: 2.7969\n",
      "08/21/2020 10:24:49 - INFO - __main__ -     steps: 55800  ppl: 2.6496\n",
      "08/21/2020 10:25:00 - INFO - __main__ -     steps: 55900  ppl: 2.8461\n",
      "08/21/2020 10:25:13 - INFO - __main__ -     steps: 56000  ppl: 2.7175\n",
      "08/21/2020 10:25:24 - INFO - __main__ -     steps: 56100  ppl: 2.5856\n",
      "08/21/2020 10:25:36 - INFO - __main__ -     steps: 56200  ppl: 2.6365\n",
      "08/21/2020 10:25:48 - INFO - __main__ -     steps: 56300  ppl: 2.6471\n",
      "08/21/2020 10:26:01 - INFO - __main__ -     steps: 56400  ppl: 2.7096\n",
      "08/21/2020 10:26:13 - INFO - __main__ -     steps: 56500  ppl: 2.5937\n",
      "08/21/2020 10:26:24 - INFO - __main__ -     steps: 56600  ppl: 2.6142\n",
      "08/21/2020 10:26:36 - INFO - __main__ -     steps: 56700  ppl: 2.6254\n",
      "08/21/2020 10:26:48 - INFO - __main__ -     steps: 56800  ppl: 2.5959\n",
      "08/21/2020 10:27:00 - INFO - __main__ -     steps: 56900  ppl: 2.6753\n",
      "08/21/2020 10:27:11 - INFO - __main__ -     steps: 57000  ppl: 2.7383\n",
      "08/21/2020 10:27:23 - INFO - __main__ -     steps: 57100  ppl: 2.6723\n",
      "08/21/2020 10:27:34 - INFO - __main__ -     steps: 57200  ppl: 2.6346\n",
      "08/21/2020 10:27:46 - INFO - __main__ -     steps: 57300  ppl: 2.6193\n",
      "08/21/2020 10:27:58 - INFO - __main__ -     steps: 57400  ppl: 2.617\n",
      "08/21/2020 10:28:09 - INFO - __main__ -     steps: 57500  ppl: 2.7187\n",
      "08/21/2020 10:28:21 - INFO - __main__ -     steps: 57600  ppl: 2.7127\n",
      "08/21/2020 10:28:32 - INFO - __main__ -     steps: 57700  ppl: 2.5969\n",
      "08/21/2020 10:28:44 - INFO - __main__ -     steps: 57800  ppl: 2.6791\n",
      "08/21/2020 10:28:56 - INFO - __main__ -     steps: 57900  ppl: 2.6608\n",
      "08/21/2020 10:29:08 - INFO - __main__ -     steps: 58000  ppl: 2.6326\n",
      "08/21/2020 10:29:19 - INFO - __main__ -     steps: 58100  ppl: 2.6846\n",
      "08/21/2020 10:29:31 - INFO - __main__ -     steps: 58200  ppl: 2.564\n",
      "08/21/2020 10:29:43 - INFO - __main__ -     steps: 58300  ppl: 2.56\n",
      "08/21/2020 10:29:54 - INFO - __main__ -     steps: 58400  ppl: 2.6896\n",
      "08/21/2020 10:30:06 - INFO - __main__ -     steps: 58500  ppl: 2.5842\n",
      "08/21/2020 10:30:18 - INFO - __main__ -     steps: 58600  ppl: 2.6626\n",
      "08/21/2020 10:30:30 - INFO - __main__ -     steps: 58700  ppl: 2.7362\n",
      "08/21/2020 10:30:42 - INFO - __main__ -     steps: 58800  ppl: 2.567\n",
      "08/21/2020 10:30:53 - INFO - __main__ -     steps: 58900  ppl: 2.7009\n",
      "08/21/2020 10:31:05 - INFO - __main__ -     steps: 59000  ppl: 2.751\n",
      "08/21/2020 10:31:16 - INFO - __main__ -     steps: 59100  ppl: 2.703\n",
      "08/21/2020 10:31:28 - INFO - __main__ -     steps: 59200  ppl: 2.6706\n",
      "08/21/2020 10:31:40 - INFO - __main__ -     steps: 59300  ppl: 2.6083\n",
      "08/21/2020 10:31:52 - INFO - __main__ -     steps: 59400  ppl: 2.6647\n",
      "08/21/2020 10:32:03 - INFO - __main__ -     steps: 59500  ppl: 2.5504\n",
      "08/21/2020 10:32:15 - INFO - __main__ -     steps: 59600  ppl: 2.5224\n",
      "08/21/2020 10:32:27 - INFO - __main__ -     steps: 59700  ppl: 2.613\n",
      "08/21/2020 10:32:38 - INFO - __main__ -     steps: 59800  ppl: 2.705\n",
      "08/21/2020 10:32:50 - INFO - __main__ -     steps: 59900  ppl: 2.6438\n",
      "08/21/2020 10:33:02 - INFO - __main__ -     steps: 60000  ppl: 2.5659\n",
      "08/21/2020 10:33:06 - INFO - __main__ -     perplexity = 2.5034\n",
      "08/21/2020 10:33:06 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-60000-2.5034/config.json\n",
      "08/21/2020 10:33:06 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-60000-2.5034/pytorch_model.bin\n",
      "08/21/2020 10:33:06 - INFO - __main__ -   Saving model checkpoint to Bert/saved_models/checkpoint-60000-2.5034\n",
      "08/21/2020 10:33:06 - INFO - __main__ -   Saving linear to Bert/saved_models/linear.bin\n",
      "08/21/2020 10:33:06 - INFO - __main__ -   Saving embeddings to Bert/saved_models/embeddings.bin\n",
      "08/21/2020 10:33:06 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-last/config.json\n",
      "08/21/2020 10:33:06 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-last/pytorch_model.bin\n",
      "08/21/2020 10:33:06 - INFO - __main__ -   Saving linear to Bert/saved_models/checkpoint-last/linear.bin\n",
      "08/21/2020 10:33:06 - INFO - __main__ -   Saving embeddings to Bert/saved_models/checkpoint-last/embeddings.bin\n",
      "08/21/2020 10:33:06 - INFO - __main__ -   Saving model to Bert/saved_models/checkpoint-last/model.bin\n",
      "08/21/2020 10:33:06 - INFO - __main__ -   Saving optimizer and scheduler states to Bert/saved_models/checkpoint-last\n",
      "08/21/2020 10:33:18 - INFO - __main__ -     steps: 60100  ppl: 2.5602\n",
      "08/21/2020 10:33:30 - INFO - __main__ -     steps: 60200  ppl: 2.7124\n",
      "08/21/2020 10:33:42 - INFO - __main__ -     steps: 60300  ppl: 2.6195\n",
      "08/21/2020 10:33:53 - INFO - __main__ -     steps: 60400  ppl: 2.6438\n",
      "08/21/2020 10:34:04 - INFO - __main__ -     steps: 60500  ppl: 2.6355\n",
      "08/21/2020 10:34:16 - INFO - __main__ -     steps: 60600  ppl: 2.5141\n",
      "08/21/2020 10:34:28 - INFO - __main__ -     steps: 60700  ppl: 2.6352\n",
      "08/21/2020 10:34:40 - INFO - __main__ -     steps: 60800  ppl: 2.6319\n",
      "08/21/2020 10:34:52 - INFO - __main__ -     steps: 60900  ppl: 2.6589\n",
      "08/21/2020 10:35:04 - INFO - __main__ -     steps: 61000  ppl: 2.5866\n",
      "08/21/2020 10:35:16 - INFO - __main__ -     steps: 61100  ppl: 2.6546\n",
      "08/21/2020 10:35:27 - INFO - __main__ -     steps: 61200  ppl: 2.6684\n",
      "08/21/2020 10:35:39 - INFO - __main__ -     steps: 61300  ppl: 2.608\n",
      "08/21/2020 10:35:51 - INFO - __main__ -     steps: 61400  ppl: 2.5851\n",
      "08/21/2020 10:36:03 - INFO - __main__ -     steps: 61500  ppl: 2.625\n",
      "08/21/2020 10:36:15 - INFO - __main__ -     steps: 61600  ppl: 2.6422\n",
      "08/21/2020 10:36:27 - INFO - __main__ -     steps: 61700  ppl: 2.583\n",
      "08/21/2020 10:36:38 - INFO - __main__ -     steps: 61800  ppl: 2.5937\n",
      "08/21/2020 10:36:50 - INFO - __main__ -     steps: 61900  ppl: 2.6527\n",
      "08/21/2020 10:37:01 - INFO - __main__ -     steps: 62000  ppl: 2.6979\n",
      "08/21/2020 10:37:13 - INFO - __main__ -     steps: 62100  ppl: 2.5899\n",
      "08/21/2020 10:37:24 - INFO - __main__ -     steps: 62200  ppl: 2.5792\n",
      "08/21/2020 10:37:36 - INFO - __main__ -     steps: 62300  ppl: 2.6389\n",
      "08/21/2020 10:37:47 - INFO - __main__ -     steps: 62400  ppl: 2.5793\n",
      "08/21/2020 10:37:59 - INFO - __main__ -     steps: 62500  ppl: 2.5674\n",
      "08/21/2020 10:38:11 - INFO - __main__ -     steps: 62600  ppl: 2.6117\n",
      "08/21/2020 10:38:22 - INFO - __main__ -     steps: 62700  ppl: 2.6394\n",
      "08/21/2020 10:38:34 - INFO - __main__ -     steps: 62800  ppl: 2.6601\n",
      "08/21/2020 10:38:46 - INFO - __main__ -     steps: 62900  ppl: 2.6881\n",
      "08/21/2020 10:38:57 - INFO - __main__ -     steps: 63000  ppl: 2.6043\n",
      "08/21/2020 10:39:09 - INFO - __main__ -     steps: 63100  ppl: 2.6257\n",
      "08/21/2020 10:39:21 - INFO - __main__ -     steps: 63200  ppl: 2.6674\n",
      "08/21/2020 10:39:33 - INFO - __main__ -     steps: 63300  ppl: 2.5329\n",
      "08/21/2020 10:39:44 - INFO - __main__ -     steps: 63400  ppl: 2.5729\n",
      "08/21/2020 10:39:56 - INFO - __main__ -     steps: 63500  ppl: 2.6801\n",
      "08/21/2020 10:40:08 - INFO - __main__ -     steps: 63600  ppl: 2.5858\n",
      "08/21/2020 10:40:19 - INFO - __main__ -     steps: 63700  ppl: 2.5428\n",
      "08/21/2020 10:40:31 - INFO - __main__ -     steps: 63800  ppl: 2.6257\n",
      "08/21/2020 10:40:43 - INFO - __main__ -     steps: 63900  ppl: 2.5754\n",
      "08/21/2020 10:40:54 - INFO - __main__ -     steps: 64000  ppl: 2.5319\n",
      "08/21/2020 10:41:06 - INFO - __main__ -     steps: 64100  ppl: 2.6214\n",
      "08/21/2020 10:41:18 - INFO - __main__ -     steps: 64200  ppl: 2.617\n",
      "08/21/2020 10:41:29 - INFO - __main__ -     steps: 64300  ppl: 2.5864\n",
      "08/21/2020 10:41:41 - INFO - __main__ -     steps: 64400  ppl: 2.5555\n",
      "08/21/2020 10:41:52 - INFO - __main__ -     steps: 64500  ppl: 2.6305\n",
      "08/21/2020 10:42:03 - INFO - __main__ -     steps: 64600  ppl: 2.6379\n",
      "08/21/2020 10:42:15 - INFO - __main__ -     steps: 64700  ppl: 2.638\n",
      "08/21/2020 10:42:27 - INFO - __main__ -     steps: 64800  ppl: 2.5639\n",
      "08/21/2020 10:42:38 - INFO - __main__ -     steps: 64900  ppl: 2.5388\n",
      "08/21/2020 10:42:50 - INFO - __main__ -     steps: 65000  ppl: 2.6119\n",
      "08/21/2020 10:43:01 - INFO - __main__ -     steps: 65100  ppl: 2.5702\n",
      "08/21/2020 10:43:13 - INFO - __main__ -     steps: 65200  ppl: 2.5675\n",
      "08/21/2020 10:43:25 - INFO - __main__ -     steps: 65300  ppl: 2.5561\n",
      "08/21/2020 10:43:36 - INFO - __main__ -     steps: 65400  ppl: 2.5276\n",
      "08/21/2020 10:43:48 - INFO - __main__ -     steps: 65500  ppl: 2.568\n",
      "08/21/2020 10:44:00 - INFO - __main__ -     steps: 65600  ppl: 2.6296\n",
      "08/21/2020 10:44:11 - INFO - __main__ -     steps: 65700  ppl: 2.5748\n",
      "08/21/2020 10:44:23 - INFO - __main__ -     steps: 65800  ppl: 2.6806\n",
      "08/21/2020 10:44:34 - INFO - __main__ -     steps: 65900  ppl: 2.643\n",
      "08/21/2020 10:44:46 - INFO - __main__ -     steps: 66000  ppl: 2.6743\n",
      "08/21/2020 10:44:58 - INFO - __main__ -     steps: 66100  ppl: 2.6302\n",
      "08/21/2020 10:45:09 - INFO - __main__ -     steps: 66200  ppl: 2.615\n",
      "08/21/2020 10:45:20 - INFO - __main__ -     steps: 66300  ppl: 2.5702\n",
      "08/21/2020 10:45:32 - INFO - __main__ -     steps: 66400  ppl: 2.6239\n",
      "08/21/2020 10:45:44 - INFO - __main__ -     steps: 66500  ppl: 2.4911\n",
      "08/21/2020 10:45:55 - INFO - __main__ -     steps: 66600  ppl: 2.5775\n",
      "08/21/2020 10:46:07 - INFO - __main__ -     steps: 66700  ppl: 2.5415\n",
      "08/21/2020 10:46:18 - INFO - __main__ -     steps: 66800  ppl: 2.5531\n",
      "08/21/2020 10:46:30 - INFO - __main__ -     steps: 66900  ppl: 2.5365\n",
      "08/21/2020 10:46:42 - INFO - __main__ -     steps: 67000  ppl: 2.551\n",
      "08/21/2020 10:46:53 - INFO - __main__ -     steps: 67100  ppl: 2.5747\n",
      "08/21/2020 10:47:05 - INFO - __main__ -     steps: 67200  ppl: 2.5866\n",
      "08/21/2020 10:47:17 - INFO - __main__ -     steps: 67300  ppl: 2.5983\n",
      "08/21/2020 10:47:28 - INFO - __main__ -     steps: 67400  ppl: 2.5528\n",
      "08/21/2020 10:47:40 - INFO - __main__ -     steps: 67500  ppl: 2.5851\n",
      "08/21/2020 10:47:52 - INFO - __main__ -     steps: 67600  ppl: 2.4599\n",
      "08/21/2020 10:48:04 - INFO - __main__ -     steps: 67700  ppl: 2.5112\n",
      "08/21/2020 10:48:15 - INFO - __main__ -     steps: 67800  ppl: 2.5699\n",
      "08/21/2020 10:48:27 - INFO - __main__ -     steps: 67900  ppl: 2.5836\n",
      "08/21/2020 10:48:39 - INFO - __main__ -     steps: 68000  ppl: 2.5063\n",
      "08/21/2020 10:48:50 - INFO - __main__ -     steps: 68100  ppl: 2.5049\n",
      "08/21/2020 10:49:02 - INFO - __main__ -     steps: 68200  ppl: 2.4639\n",
      "08/21/2020 10:49:14 - INFO - __main__ -     steps: 68300  ppl: 2.511\n",
      "08/21/2020 10:49:25 - INFO - __main__ -     steps: 68400  ppl: 2.627\n",
      "08/21/2020 10:49:36 - INFO - __main__ -     steps: 68500  ppl: 2.5293\n",
      "08/21/2020 10:49:48 - INFO - __main__ -     steps: 68600  ppl: 2.4586\n",
      "08/21/2020 10:49:59 - INFO - __main__ -     steps: 68700  ppl: 2.6216\n",
      "08/21/2020 10:50:11 - INFO - __main__ -     steps: 68800  ppl: 2.5978\n",
      "08/21/2020 10:50:23 - INFO - __main__ -     steps: 68900  ppl: 2.5796\n",
      "08/21/2020 10:50:34 - INFO - __main__ -     steps: 69000  ppl: 2.4897\n",
      "08/21/2020 10:50:46 - INFO - __main__ -     steps: 69100  ppl: 2.4656\n",
      "08/21/2020 10:50:57 - INFO - __main__ -     steps: 69200  ppl: 2.6208\n",
      "08/21/2020 10:51:09 - INFO - __main__ -     steps: 69300  ppl: 2.501\n",
      "08/21/2020 10:51:20 - INFO - __main__ -     steps: 69400  ppl: 2.4926\n",
      "08/21/2020 10:51:32 - INFO - __main__ -     steps: 69500  ppl: 2.5111\n",
      "08/21/2020 10:51:44 - INFO - __main__ -     steps: 69600  ppl: 2.5412\n",
      "08/21/2020 10:51:55 - INFO - __main__ -     steps: 69700  ppl: 2.5011\n",
      "08/21/2020 10:52:07 - INFO - __main__ -     steps: 69800  ppl: 2.5884\n",
      "08/21/2020 10:52:18 - INFO - __main__ -     steps: 69900  ppl: 2.5081\n",
      "08/21/2020 10:52:30 - INFO - __main__ -     steps: 70000  ppl: 2.4933\n",
      "08/21/2020 10:52:34 - INFO - __main__ -     perplexity = 2.4108\n",
      "08/21/2020 10:52:34 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-70000-2.4108/config.json\n",
      "08/21/2020 10:52:34 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-70000-2.4108/pytorch_model.bin\n",
      "08/21/2020 10:52:34 - INFO - __main__ -   Saving model checkpoint to Bert/saved_models/checkpoint-70000-2.4108\n",
      "08/21/2020 10:52:34 - INFO - __main__ -   Saving linear to Bert/saved_models/linear.bin\n",
      "08/21/2020 10:52:34 - INFO - __main__ -   Saving embeddings to Bert/saved_models/embeddings.bin\n",
      "08/21/2020 10:52:34 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-last/config.json\n",
      "08/21/2020 10:52:34 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-last/pytorch_model.bin\n",
      "08/21/2020 10:52:34 - INFO - __main__ -   Saving linear to Bert/saved_models/checkpoint-last/linear.bin\n",
      "08/21/2020 10:52:34 - INFO - __main__ -   Saving embeddings to Bert/saved_models/checkpoint-last/embeddings.bin\n",
      "08/21/2020 10:52:34 - INFO - __main__ -   Saving model to Bert/saved_models/checkpoint-last/model.bin\n",
      "08/21/2020 10:52:35 - INFO - __main__ -   Saving optimizer and scheduler states to Bert/saved_models/checkpoint-last\n",
      "08/21/2020 10:52:46 - INFO - __main__ -     steps: 70100  ppl: 2.5664\n",
      "08/21/2020 10:52:58 - INFO - __main__ -     steps: 70200  ppl: 2.5651\n",
      "08/21/2020 10:53:09 - INFO - __main__ -     steps: 70300  ppl: 2.4975\n",
      "08/21/2020 10:53:21 - INFO - __main__ -     steps: 70400  ppl: 2.5357\n",
      "08/21/2020 10:53:33 - INFO - __main__ -     steps: 70500  ppl: 2.4955\n",
      "08/21/2020 10:53:44 - INFO - __main__ -     steps: 70600  ppl: 2.6162\n",
      "08/21/2020 10:53:56 - INFO - __main__ -     steps: 70700  ppl: 2.6123\n",
      "08/21/2020 10:54:07 - INFO - __main__ -     steps: 70800  ppl: 2.4645\n",
      "08/21/2020 10:54:19 - INFO - __main__ -     steps: 70900  ppl: 2.6016\n",
      "08/21/2020 10:54:30 - INFO - __main__ -     steps: 71000  ppl: 2.5252\n",
      "08/21/2020 10:54:42 - INFO - __main__ -     steps: 71100  ppl: 2.5055\n",
      "08/21/2020 10:54:53 - INFO - __main__ -     steps: 71200  ppl: 2.5236\n",
      "08/21/2020 10:55:05 - INFO - __main__ -     steps: 71300  ppl: 2.5662\n",
      "08/21/2020 10:55:16 - INFO - __main__ -     steps: 71400  ppl: 2.543\n",
      "08/21/2020 10:55:27 - INFO - __main__ -     steps: 71500  ppl: 2.5513\n",
      "08/21/2020 10:55:39 - INFO - __main__ -     steps: 71600  ppl: 2.5615\n",
      "08/21/2020 10:55:50 - INFO - __main__ -     steps: 71700  ppl: 2.5177\n",
      "08/21/2020 10:56:02 - INFO - __main__ -     steps: 71800  ppl: 2.5322\n",
      "08/21/2020 10:56:13 - INFO - __main__ -     steps: 71900  ppl: 2.4788\n",
      "08/21/2020 10:56:24 - INFO - __main__ -     steps: 72000  ppl: 2.5933\n",
      "08/21/2020 10:56:36 - INFO - __main__ -     steps: 72100  ppl: 2.4966\n",
      "08/21/2020 10:56:47 - INFO - __main__ -     steps: 72200  ppl: 2.5898\n",
      "08/21/2020 10:56:59 - INFO - __main__ -     steps: 72300  ppl: 2.6494\n",
      "08/21/2020 10:57:10 - INFO - __main__ -     steps: 72400  ppl: 2.5051\n",
      "08/21/2020 10:57:22 - INFO - __main__ -     steps: 72500  ppl: 2.5579\n",
      "08/21/2020 10:57:33 - INFO - __main__ -     steps: 72600  ppl: 2.4834\n",
      "08/21/2020 10:57:45 - INFO - __main__ -     steps: 72700  ppl: 2.5749\n",
      "08/21/2020 10:57:56 - INFO - __main__ -     steps: 72800  ppl: 2.535\n",
      "08/21/2020 10:58:08 - INFO - __main__ -     steps: 72900  ppl: 2.4504\n",
      "08/21/2020 10:58:20 - INFO - __main__ -     steps: 73000  ppl: 2.5372\n",
      "08/21/2020 10:58:32 - INFO - __main__ -     steps: 73100  ppl: 2.4066\n",
      "08/21/2020 10:58:44 - INFO - __main__ -     steps: 73200  ppl: 2.505\n",
      "08/21/2020 10:58:56 - INFO - __main__ -     steps: 73300  ppl: 2.5908\n",
      "08/21/2020 10:59:08 - INFO - __main__ -     steps: 73400  ppl: 2.4441\n",
      "08/21/2020 10:59:20 - INFO - __main__ -     steps: 73500  ppl: 2.5612\n",
      "08/21/2020 10:59:31 - INFO - __main__ -     steps: 73600  ppl: 2.482\n",
      "08/21/2020 10:59:42 - INFO - __main__ -     steps: 73700  ppl: 2.6188\n",
      "08/21/2020 10:59:54 - INFO - __main__ -     steps: 73800  ppl: 2.6234\n",
      "08/21/2020 11:00:06 - INFO - __main__ -     steps: 73900  ppl: 2.5994\n",
      "08/21/2020 11:00:18 - INFO - __main__ -     steps: 74000  ppl: 2.6398\n",
      "08/21/2020 11:00:29 - INFO - __main__ -     steps: 74100  ppl: 2.568\n",
      "08/21/2020 11:00:41 - INFO - __main__ -     steps: 74200  ppl: 2.5676\n",
      "08/21/2020 11:00:53 - INFO - __main__ -     steps: 74300  ppl: 2.548\n",
      "08/21/2020 11:01:04 - INFO - __main__ -     steps: 74400  ppl: 2.517\n",
      "08/21/2020 11:01:16 - INFO - __main__ -     steps: 74500  ppl: 2.5154\n",
      "08/21/2020 11:01:27 - INFO - __main__ -     steps: 74600  ppl: 2.5173\n",
      "08/21/2020 11:01:39 - INFO - __main__ -     steps: 74700  ppl: 2.529\n",
      "08/21/2020 11:01:50 - INFO - __main__ -     steps: 74800  ppl: 2.5184\n",
      "08/21/2020 11:02:02 - INFO - __main__ -     steps: 74900  ppl: 2.5273\n",
      "08/21/2020 11:02:13 - INFO - __main__ -     steps: 75000  ppl: 2.5182\n",
      "08/21/2020 11:02:25 - INFO - __main__ -     steps: 75100  ppl: 2.4865\n",
      "08/21/2020 11:02:36 - INFO - __main__ -     steps: 75200  ppl: 2.5296\n",
      "08/21/2020 11:02:48 - INFO - __main__ -     steps: 75300  ppl: 2.5\n",
      "08/21/2020 11:02:59 - INFO - __main__ -     steps: 75400  ppl: 2.5573\n",
      "08/21/2020 11:03:11 - INFO - __main__ -     steps: 75500  ppl: 2.4632\n",
      "08/21/2020 11:03:22 - INFO - __main__ -     steps: 75600  ppl: 2.4788\n",
      "08/21/2020 11:03:34 - INFO - __main__ -     steps: 75700  ppl: 2.5606\n",
      "08/21/2020 11:03:45 - INFO - __main__ -     steps: 75800  ppl: 2.5742\n",
      "08/21/2020 11:03:57 - INFO - __main__ -     steps: 75900  ppl: 2.4939\n",
      "08/21/2020 11:04:08 - INFO - __main__ -     steps: 76000  ppl: 2.5575\n",
      "08/21/2020 11:04:20 - INFO - __main__ -     steps: 76100  ppl: 2.4792\n",
      "08/21/2020 11:04:31 - INFO - __main__ -     steps: 76200  ppl: 2.5911\n",
      "08/21/2020 11:04:42 - INFO - __main__ -     steps: 76300  ppl: 2.5189\n",
      "08/21/2020 11:04:54 - INFO - __main__ -     steps: 76400  ppl: 2.5807\n",
      "08/21/2020 11:05:06 - INFO - __main__ -     steps: 76500  ppl: 2.4667\n",
      "08/21/2020 11:05:17 - INFO - __main__ -     steps: 76600  ppl: 2.6511\n",
      "08/21/2020 11:05:29 - INFO - __main__ -     steps: 76700  ppl: 2.5391\n",
      "08/21/2020 11:05:41 - INFO - __main__ -     steps: 76800  ppl: 2.4286\n",
      "08/21/2020 11:05:52 - INFO - __main__ -     steps: 76900  ppl: 2.5957\n",
      "08/21/2020 11:06:04 - INFO - __main__ -     steps: 77000  ppl: 2.3622\n",
      "08/21/2020 11:06:15 - INFO - __main__ -     steps: 77100  ppl: 2.5136\n",
      "08/21/2020 11:06:27 - INFO - __main__ -     steps: 77200  ppl: 2.4425\n",
      "08/21/2020 11:06:39 - INFO - __main__ -     steps: 77300  ppl: 2.5186\n",
      "08/21/2020 11:06:50 - INFO - __main__ -     steps: 77400  ppl: 2.5836\n",
      "08/21/2020 11:07:02 - INFO - __main__ -     steps: 77500  ppl: 2.5107\n",
      "08/21/2020 11:07:13 - INFO - __main__ -     steps: 77600  ppl: 2.4829\n",
      "08/21/2020 11:07:25 - INFO - __main__ -     steps: 77700  ppl: 2.5062\n",
      "08/21/2020 11:07:37 - INFO - __main__ -     steps: 77800  ppl: 2.5297\n",
      "08/21/2020 11:07:49 - INFO - __main__ -     steps: 77900  ppl: 2.5284\n",
      "08/21/2020 11:08:01 - INFO - __main__ -     steps: 78000  ppl: 2.5068\n",
      "08/21/2020 11:08:12 - INFO - __main__ -     steps: 78100  ppl: 2.5031\n",
      "08/21/2020 11:08:24 - INFO - __main__ -     steps: 78200  ppl: 2.4777\n",
      "08/21/2020 11:08:35 - INFO - __main__ -     steps: 78300  ppl: 2.4476\n",
      "08/21/2020 11:08:47 - INFO - __main__ -     steps: 78400  ppl: 2.4818\n",
      "08/21/2020 11:08:59 - INFO - __main__ -     steps: 78500  ppl: 2.4352\n",
      "08/21/2020 11:09:10 - INFO - __main__ -     steps: 78600  ppl: 2.5061\n",
      "08/21/2020 11:09:22 - INFO - __main__ -     steps: 78700  ppl: 2.485\n",
      "08/21/2020 11:09:34 - INFO - __main__ -     steps: 78800  ppl: 2.4918\n",
      "08/21/2020 11:09:45 - INFO - __main__ -     steps: 78900  ppl: 2.5655\n",
      "08/21/2020 11:09:56 - INFO - __main__ -     steps: 79000  ppl: 2.4853\n",
      "08/21/2020 11:10:08 - INFO - __main__ -     steps: 79100  ppl: 2.561\n",
      "08/21/2020 11:10:19 - INFO - __main__ -     steps: 79200  ppl: 2.5114\n",
      "08/21/2020 11:10:31 - INFO - __main__ -     steps: 79300  ppl: 2.5643\n",
      "08/21/2020 11:10:42 - INFO - __main__ -     steps: 79400  ppl: 2.5352\n",
      "08/21/2020 11:10:54 - INFO - __main__ -     steps: 79500  ppl: 2.4396\n",
      "08/21/2020 11:11:05 - INFO - __main__ -     steps: 79600  ppl: 2.5505\n",
      "08/21/2020 11:11:16 - INFO - __main__ -     steps: 79700  ppl: 2.5115\n",
      "08/21/2020 11:11:28 - INFO - __main__ -     steps: 79800  ppl: 2.6017\n",
      "08/21/2020 11:11:39 - INFO - __main__ -     steps: 79900  ppl: 2.4901\n",
      "08/21/2020 11:11:51 - INFO - __main__ -     steps: 80000  ppl: 2.5098\n",
      "08/21/2020 11:11:56 - INFO - __main__ -     perplexity = 2.3794\n",
      "08/21/2020 11:11:56 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-80000-2.3794/config.json\n",
      "08/21/2020 11:11:56 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-80000-2.3794/pytorch_model.bin\n",
      "08/21/2020 11:11:56 - INFO - __main__ -   Saving model checkpoint to Bert/saved_models/checkpoint-80000-2.3794\n",
      "08/21/2020 11:11:56 - INFO - __main__ -   Saving linear to Bert/saved_models/linear.bin\n",
      "08/21/2020 11:11:56 - INFO - __main__ -   Saving embeddings to Bert/saved_models/embeddings.bin\n",
      "08/21/2020 11:11:56 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-last/config.json\n",
      "08/21/2020 11:11:56 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-last/pytorch_model.bin\n",
      "08/21/2020 11:11:56 - INFO - __main__ -   Saving linear to Bert/saved_models/checkpoint-last/linear.bin\n",
      "08/21/2020 11:11:56 - INFO - __main__ -   Saving embeddings to Bert/saved_models/checkpoint-last/embeddings.bin\n",
      "08/21/2020 11:11:56 - INFO - __main__ -   Saving model to Bert/saved_models/checkpoint-last/model.bin\n",
      "08/21/2020 11:11:56 - INFO - __main__ -   Saving optimizer and scheduler states to Bert/saved_models/checkpoint-last\n",
      "08/21/2020 11:12:08 - INFO - __main__ -     steps: 80100  ppl: 2.5276\n",
      "08/21/2020 11:12:20 - INFO - __main__ -     steps: 80200  ppl: 2.4972\n",
      "08/21/2020 11:12:32 - INFO - __main__ -     steps: 80300  ppl: 2.4965\n",
      "08/21/2020 11:12:43 - INFO - __main__ -     steps: 80400  ppl: 2.5092\n",
      "08/21/2020 11:12:54 - INFO - __main__ -     steps: 80500  ppl: 2.4521\n",
      "08/21/2020 11:13:06 - INFO - __main__ -     steps: 80600  ppl: 2.4329\n",
      "08/21/2020 11:13:18 - INFO - __main__ -     steps: 80700  ppl: 2.532\n",
      "08/21/2020 11:13:29 - INFO - __main__ -     steps: 80800  ppl: 2.5269\n",
      "08/21/2020 11:13:41 - INFO - __main__ -     steps: 80900  ppl: 2.4902\n",
      "08/21/2020 11:13:52 - INFO - __main__ -     steps: 81000  ppl: 2.5316\n",
      "08/21/2020 11:14:03 - INFO - __main__ -     steps: 81100  ppl: 2.5496\n",
      "08/21/2020 11:14:15 - INFO - __main__ -     steps: 81200  ppl: 2.5827\n",
      "08/21/2020 11:14:27 - INFO - __main__ -     steps: 81300  ppl: 2.4805\n",
      "08/21/2020 11:14:38 - INFO - __main__ -     steps: 81400  ppl: 2.4298\n",
      "08/21/2020 11:14:49 - INFO - __main__ -     steps: 81500  ppl: 2.5033\n",
      "08/21/2020 11:15:01 - INFO - __main__ -     steps: 81600  ppl: 2.5136\n",
      "08/21/2020 11:15:12 - INFO - __main__ -     steps: 81700  ppl: 2.5391\n",
      "08/21/2020 11:15:24 - INFO - __main__ -     steps: 81800  ppl: 2.4711\n",
      "08/21/2020 11:15:35 - INFO - __main__ -     steps: 81900  ppl: 2.5587\n",
      "08/21/2020 11:15:47 - INFO - __main__ -     steps: 82000  ppl: 2.5971\n",
      "08/21/2020 11:15:59 - INFO - __main__ -     steps: 82100  ppl: 2.4892\n",
      "08/21/2020 11:16:10 - INFO - __main__ -     steps: 82200  ppl: 2.5315\n",
      "08/21/2020 11:16:22 - INFO - __main__ -     steps: 82300  ppl: 2.4218\n",
      "08/21/2020 11:16:33 - INFO - __main__ -     steps: 82400  ppl: 2.5599\n",
      "08/21/2020 11:16:44 - INFO - __main__ -     steps: 82500  ppl: 2.5777\n",
      "08/21/2020 11:16:56 - INFO - __main__ -     steps: 82600  ppl: 2.4634\n",
      "08/21/2020 11:17:07 - INFO - __main__ -     steps: 82700  ppl: 2.5499\n",
      "08/21/2020 11:17:19 - INFO - __main__ -     steps: 82800  ppl: 2.4259\n",
      "08/21/2020 11:17:30 - INFO - __main__ -     steps: 82900  ppl: 2.5065\n",
      "08/21/2020 11:17:42 - INFO - __main__ -     steps: 83000  ppl: 2.5517\n",
      "08/21/2020 11:17:53 - INFO - __main__ -     steps: 83100  ppl: 2.4842\n",
      "08/21/2020 11:18:05 - INFO - __main__ -     steps: 83200  ppl: 2.5049\n",
      "08/21/2020 11:18:17 - INFO - __main__ -     steps: 83300  ppl: 2.5472\n",
      "08/21/2020 11:18:28 - INFO - __main__ -     steps: 83400  ppl: 2.4424\n",
      "08/21/2020 11:18:40 - INFO - __main__ -     steps: 83500  ppl: 2.4873\n",
      "08/21/2020 11:18:51 - INFO - __main__ -     steps: 83600  ppl: 2.5256\n",
      "08/21/2020 11:19:03 - INFO - __main__ -     steps: 83700  ppl: 2.482\n",
      "08/21/2020 11:19:14 - INFO - __main__ -     steps: 83800  ppl: 2.493\n",
      "08/21/2020 11:19:26 - INFO - __main__ -     steps: 83900  ppl: 2.4089\n",
      "08/21/2020 11:19:38 - INFO - __main__ -     steps: 84000  ppl: 2.5287\n",
      "08/21/2020 11:19:49 - INFO - __main__ -     steps: 84100  ppl: 2.4531\n",
      "08/21/2020 11:20:01 - INFO - __main__ -     steps: 84200  ppl: 2.5277\n",
      "08/21/2020 11:20:12 - INFO - __main__ -     steps: 84300  ppl: 2.5992\n",
      "08/21/2020 11:20:24 - INFO - __main__ -     steps: 84400  ppl: 2.527\n",
      "08/21/2020 11:20:36 - INFO - __main__ -     steps: 84500  ppl: 2.4835\n",
      "08/21/2020 11:20:47 - INFO - __main__ -     steps: 84600  ppl: 2.5495\n",
      "08/21/2020 11:20:58 - INFO - __main__ -     steps: 84700  ppl: 2.4515\n",
      "08/21/2020 11:21:10 - INFO - __main__ -     steps: 84800  ppl: 2.4952\n",
      "08/21/2020 11:21:22 - INFO - __main__ -     steps: 84900  ppl: 2.5227\n",
      "08/21/2020 11:21:34 - INFO - __main__ -     steps: 85000  ppl: 2.5053\n",
      "08/21/2020 11:21:45 - INFO - __main__ -     steps: 85100  ppl: 2.5248\n",
      "08/21/2020 11:21:56 - INFO - __main__ -     steps: 85200  ppl: 2.4956\n",
      "08/21/2020 11:22:08 - INFO - __main__ -     steps: 85300  ppl: 2.4599\n",
      "08/21/2020 11:22:19 - INFO - __main__ -     steps: 85400  ppl: 2.5387\n",
      "08/21/2020 11:22:31 - INFO - __main__ -     steps: 85500  ppl: 2.4809\n",
      "08/21/2020 11:22:43 - INFO - __main__ -     steps: 85600  ppl: 2.4451\n",
      "08/21/2020 11:22:54 - INFO - __main__ -     steps: 85700  ppl: 2.4579\n",
      "08/21/2020 11:23:06 - INFO - __main__ -     steps: 85800  ppl: 2.4176\n",
      "08/21/2020 11:23:17 - INFO - __main__ -     steps: 85900  ppl: 2.492\n",
      "08/21/2020 11:23:29 - INFO - __main__ -     steps: 86000  ppl: 2.5465\n",
      "08/21/2020 11:23:41 - INFO - __main__ -     steps: 86100  ppl: 2.5068\n",
      "08/21/2020 11:23:52 - INFO - __main__ -     steps: 86200  ppl: 2.4707\n",
      "08/21/2020 11:24:04 - INFO - __main__ -     steps: 86300  ppl: 2.5204\n",
      "08/21/2020 11:24:15 - INFO - __main__ -     steps: 86400  ppl: 2.5605\n",
      "08/21/2020 11:24:27 - INFO - __main__ -     steps: 86500  ppl: 2.4773\n",
      "08/21/2020 11:24:38 - INFO - __main__ -     steps: 86600  ppl: 2.4879\n",
      "08/21/2020 11:24:50 - INFO - __main__ -     steps: 86700  ppl: 2.5744\n",
      "08/21/2020 11:25:02 - INFO - __main__ -     steps: 86800  ppl: 2.5562\n",
      "08/21/2020 11:25:13 - INFO - __main__ -     steps: 86900  ppl: 2.4854\n",
      "08/21/2020 11:25:25 - INFO - __main__ -     steps: 87000  ppl: 2.4773\n",
      "08/21/2020 11:25:36 - INFO - __main__ -     steps: 87100  ppl: 2.4641\n",
      "08/21/2020 11:25:48 - INFO - __main__ -     steps: 87200  ppl: 2.5411\n",
      "08/21/2020 11:25:59 - INFO - __main__ -     steps: 87300  ppl: 2.5231\n",
      "08/21/2020 11:26:11 - INFO - __main__ -     steps: 87400  ppl: 2.5629\n",
      "08/21/2020 11:26:23 - INFO - __main__ -     steps: 87500  ppl: 2.5141\n",
      "08/21/2020 11:26:35 - INFO - __main__ -     steps: 87600  ppl: 2.4488\n",
      "08/21/2020 11:26:46 - INFO - __main__ -     steps: 87700  ppl: 2.4896\n",
      "08/21/2020 11:26:58 - INFO - __main__ -     steps: 87800  ppl: 2.4208\n",
      "08/21/2020 11:27:09 - INFO - __main__ -     steps: 87900  ppl: 2.4863\n",
      "08/21/2020 11:27:21 - INFO - __main__ -     steps: 88000  ppl: 2.4838\n",
      "08/21/2020 11:27:33 - INFO - __main__ -     steps: 88100  ppl: 2.5007\n",
      "08/21/2020 11:27:44 - INFO - __main__ -     steps: 88200  ppl: 2.576\n",
      "08/21/2020 11:27:56 - INFO - __main__ -     steps: 88300  ppl: 2.526\n",
      "08/21/2020 11:28:07 - INFO - __main__ -     steps: 88400  ppl: 2.4838\n",
      "08/21/2020 11:28:19 - INFO - __main__ -     steps: 88500  ppl: 2.5158\n",
      "08/21/2020 11:28:30 - INFO - __main__ -     steps: 88600  ppl: 2.439\n",
      "08/21/2020 11:28:42 - INFO - __main__ -     steps: 88700  ppl: 2.5476\n",
      "08/21/2020 11:28:53 - INFO - __main__ -     steps: 88800  ppl: 2.4431\n",
      "08/21/2020 11:29:05 - INFO - __main__ -     steps: 88900  ppl: 2.4336\n",
      "08/21/2020 11:29:17 - INFO - __main__ -     steps: 89000  ppl: 2.6016\n",
      "08/21/2020 11:29:28 - INFO - __main__ -     steps: 89100  ppl: 2.4463\n",
      "08/21/2020 11:29:40 - INFO - __main__ -     steps: 89200  ppl: 2.4803\n",
      "08/21/2020 11:29:52 - INFO - __main__ -     steps: 89300  ppl: 2.4481\n",
      "08/21/2020 11:30:03 - INFO - __main__ -     steps: 89400  ppl: 2.4842\n",
      "08/21/2020 11:30:16 - INFO - __main__ -     steps: 89500  ppl: 2.5001\n",
      "08/21/2020 11:30:27 - INFO - __main__ -     steps: 89600  ppl: 2.5018\n",
      "08/21/2020 11:30:39 - INFO - __main__ -     steps: 89700  ppl: 2.4403\n",
      "08/21/2020 11:30:50 - INFO - __main__ -     steps: 89800  ppl: 2.5019\n",
      "08/21/2020 11:31:02 - INFO - __main__ -     steps: 89900  ppl: 2.5335\n",
      "08/21/2020 11:31:14 - INFO - __main__ -     steps: 90000  ppl: 2.514\n",
      "08/21/2020 11:31:18 - INFO - __main__ -     perplexity = 2.3638\n",
      "08/21/2020 11:31:18 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-90000-2.3638/config.json\n",
      "08/21/2020 11:31:18 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-90000-2.3638/pytorch_model.bin\n",
      "08/21/2020 11:31:18 - INFO - __main__ -   Saving model checkpoint to Bert/saved_models/checkpoint-90000-2.3638\n",
      "08/21/2020 11:31:18 - INFO - __main__ -   Saving linear to Bert/saved_models/linear.bin\n",
      "08/21/2020 11:31:18 - INFO - __main__ -   Saving embeddings to Bert/saved_models/embeddings.bin\n",
      "08/21/2020 11:31:18 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-last/config.json\n",
      "08/21/2020 11:31:18 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-last/pytorch_model.bin\n",
      "08/21/2020 11:31:18 - INFO - __main__ -   Saving linear to Bert/saved_models/checkpoint-last/linear.bin\n",
      "08/21/2020 11:31:18 - INFO - __main__ -   Saving embeddings to Bert/saved_models/checkpoint-last/embeddings.bin\n",
      "08/21/2020 11:31:18 - INFO - __main__ -   Saving model to Bert/saved_models/checkpoint-last/model.bin\n",
      "08/21/2020 11:31:19 - INFO - __main__ -   Saving optimizer and scheduler states to Bert/saved_models/checkpoint-last\n",
      "08/21/2020 11:31:30 - INFO - __main__ -     steps: 90100  ppl: 2.4491\n",
      "08/21/2020 11:31:43 - INFO - __main__ -     steps: 90200  ppl: 2.4496\n",
      "08/21/2020 11:31:54 - INFO - __main__ -     steps: 90300  ppl: 2.4834\n",
      "08/21/2020 11:32:06 - INFO - __main__ -     steps: 90400  ppl: 2.4874\n",
      "08/21/2020 11:32:18 - INFO - __main__ -     steps: 90500  ppl: 2.4754\n",
      "08/21/2020 11:32:30 - INFO - __main__ -     steps: 90600  ppl: 2.4496\n",
      "08/21/2020 11:32:42 - INFO - __main__ -     steps: 90700  ppl: 2.4945\n",
      "08/21/2020 11:32:53 - INFO - __main__ -     steps: 90800  ppl: 2.4336\n",
      "08/21/2020 11:33:05 - INFO - __main__ -     steps: 90900  ppl: 2.4889\n",
      "08/21/2020 11:33:16 - INFO - __main__ -     steps: 91000  ppl: 2.4843\n",
      "08/21/2020 11:33:28 - INFO - __main__ -     steps: 91100  ppl: 2.5222\n",
      "08/21/2020 11:33:39 - INFO - __main__ -     steps: 91200  ppl: 2.4244\n",
      "08/21/2020 11:33:51 - INFO - __main__ -     steps: 91300  ppl: 2.4723\n",
      "08/21/2020 11:34:02 - INFO - __main__ -     steps: 91400  ppl: 2.4893\n",
      "08/21/2020 11:34:14 - INFO - __main__ -     steps: 91500  ppl: 2.4283\n",
      "08/21/2020 11:34:25 - INFO - __main__ -     steps: 91600  ppl: 2.4765\n",
      "08/21/2020 11:34:37 - INFO - __main__ -     steps: 91700  ppl: 2.5724\n",
      "08/21/2020 11:34:49 - INFO - __main__ -     steps: 91800  ppl: 2.5085\n",
      "08/21/2020 11:35:00 - INFO - __main__ -     steps: 91900  ppl: 2.5344\n",
      "08/21/2020 11:35:12 - INFO - __main__ -     steps: 92000  ppl: 2.466\n",
      "08/21/2020 11:35:23 - INFO - __main__ -     steps: 92100  ppl: 2.4849\n",
      "08/21/2020 11:35:35 - INFO - __main__ -     steps: 92200  ppl: 2.5185\n",
      "08/21/2020 11:35:46 - INFO - __main__ -     steps: 92300  ppl: 2.6039\n",
      "08/21/2020 11:35:58 - INFO - __main__ -     steps: 92400  ppl: 2.4991\n",
      "08/21/2020 11:36:10 - INFO - __main__ -     steps: 92500  ppl: 2.4297\n",
      "08/21/2020 11:36:22 - INFO - __main__ -     steps: 92600  ppl: 2.4202\n",
      "08/21/2020 11:36:33 - INFO - __main__ -     steps: 92700  ppl: 2.5883\n",
      "08/21/2020 11:36:44 - INFO - __main__ -     steps: 92800  ppl: 2.4152\n",
      "08/21/2020 11:36:56 - INFO - __main__ -     steps: 92900  ppl: 2.4363\n",
      "08/21/2020 11:37:07 - INFO - __main__ -     steps: 93000  ppl: 2.41\n",
      "08/21/2020 11:37:19 - INFO - __main__ -     steps: 93100  ppl: 2.4954\n",
      "08/21/2020 11:37:30 - INFO - __main__ -     steps: 93200  ppl: 2.4851\n",
      "08/21/2020 11:37:41 - INFO - __main__ -     steps: 93300  ppl: 2.4973\n",
      "08/21/2020 11:37:53 - INFO - __main__ -     steps: 93400  ppl: 2.4332\n",
      "08/21/2020 11:38:04 - INFO - __main__ -     steps: 93500  ppl: 2.4912\n",
      "08/21/2020 11:38:16 - INFO - __main__ -     steps: 93600  ppl: 2.4017\n",
      "08/21/2020 11:38:27 - INFO - __main__ -     steps: 93700  ppl: 2.5851\n",
      "08/21/2020 11:38:39 - INFO - __main__ -     steps: 93800  ppl: 2.5062\n",
      "08/21/2020 11:38:50 - INFO - __main__ -     steps: 93900  ppl: 2.4587\n",
      "08/21/2020 11:39:02 - INFO - __main__ -     steps: 94000  ppl: 2.4506\n",
      "08/21/2020 11:39:13 - INFO - __main__ -     steps: 94100  ppl: 2.5037\n",
      "08/21/2020 11:39:25 - INFO - __main__ -     steps: 94200  ppl: 2.4653\n",
      "08/21/2020 11:39:36 - INFO - __main__ -     steps: 94300  ppl: 2.4857\n",
      "08/21/2020 11:39:48 - INFO - __main__ -     steps: 94400  ppl: 2.4186\n",
      "08/21/2020 11:40:00 - INFO - __main__ -     steps: 94500  ppl: 2.4515\n",
      "08/21/2020 11:40:11 - INFO - __main__ -     steps: 94600  ppl: 2.4717\n",
      "08/21/2020 11:40:23 - INFO - __main__ -     steps: 94700  ppl: 2.441\n",
      "08/21/2020 11:40:35 - INFO - __main__ -     steps: 94800  ppl: 2.4756\n",
      "08/21/2020 11:40:46 - INFO - __main__ -     steps: 94900  ppl: 2.3835\n",
      "08/21/2020 11:40:58 - INFO - __main__ -     steps: 95000  ppl: 2.487\n",
      "08/21/2020 11:41:10 - INFO - __main__ -     steps: 95100  ppl: 2.3947\n",
      "08/21/2020 11:41:21 - INFO - __main__ -     steps: 95200  ppl: 2.4384\n",
      "08/21/2020 11:41:32 - INFO - __main__ -     steps: 95300  ppl: 2.4573\n",
      "08/21/2020 11:41:44 - INFO - __main__ -     steps: 95400  ppl: 2.4434\n",
      "08/21/2020 11:41:56 - INFO - __main__ -     steps: 95500  ppl: 2.3848\n",
      "08/21/2020 11:42:07 - INFO - __main__ -     steps: 95600  ppl: 2.4255\n",
      "08/21/2020 11:42:19 - INFO - __main__ -     steps: 95700  ppl: 2.4486\n",
      "08/21/2020 11:42:30 - INFO - __main__ -     steps: 95800  ppl: 2.5389\n",
      "08/21/2020 11:42:41 - INFO - __main__ -     steps: 95900  ppl: 2.4925\n",
      "08/21/2020 11:42:53 - INFO - __main__ -     steps: 96000  ppl: 2.499\n",
      "08/21/2020 11:43:04 - INFO - __main__ -     steps: 96100  ppl: 2.4779\n",
      "08/21/2020 11:43:16 - INFO - __main__ -     steps: 96200  ppl: 2.4923\n",
      "08/21/2020 11:43:27 - INFO - __main__ -     steps: 96300  ppl: 2.4492\n",
      "08/21/2020 11:43:39 - INFO - __main__ -     steps: 96400  ppl: 2.513\n",
      "08/21/2020 11:43:51 - INFO - __main__ -     steps: 96500  ppl: 2.4252\n",
      "08/21/2020 11:44:02 - INFO - __main__ -     steps: 96600  ppl: 2.5504\n",
      "08/21/2020 11:44:14 - INFO - __main__ -     steps: 96700  ppl: 2.3992\n",
      "08/21/2020 11:44:25 - INFO - __main__ -     steps: 96800  ppl: 2.4012\n",
      "08/21/2020 11:44:37 - INFO - __main__ -     steps: 96900  ppl: 2.4655\n",
      "08/21/2020 11:44:48 - INFO - __main__ -     steps: 97000  ppl: 2.4967\n",
      "08/21/2020 11:45:00 - INFO - __main__ -     steps: 97100  ppl: 2.4771\n",
      "08/21/2020 11:45:11 - INFO - __main__ -     steps: 97200  ppl: 2.4144\n",
      "08/21/2020 11:45:23 - INFO - __main__ -     steps: 97300  ppl: 2.418\n",
      "08/21/2020 11:45:35 - INFO - __main__ -     steps: 97400  ppl: 2.4636\n",
      "08/21/2020 11:45:46 - INFO - __main__ -     steps: 97500  ppl: 2.4681\n",
      "08/21/2020 11:45:58 - INFO - __main__ -     steps: 97600  ppl: 2.4109\n",
      "08/21/2020 11:46:09 - INFO - __main__ -     steps: 97700  ppl: 2.548\n",
      "08/21/2020 11:46:21 - INFO - __main__ -     steps: 97800  ppl: 2.479\n",
      "08/21/2020 11:46:32 - INFO - __main__ -     steps: 97900  ppl: 2.5418\n",
      "08/21/2020 11:46:44 - INFO - __main__ -     steps: 98000  ppl: 2.4515\n",
      "08/21/2020 11:46:56 - INFO - __main__ -     steps: 98100  ppl: 2.4763\n",
      "08/21/2020 11:47:08 - INFO - __main__ -     steps: 98200  ppl: 2.4488\n",
      "08/21/2020 11:47:19 - INFO - __main__ -     steps: 98300  ppl: 2.4944\n",
      "08/21/2020 11:47:31 - INFO - __main__ -     steps: 98400  ppl: 2.5073\n",
      "08/21/2020 11:47:42 - INFO - __main__ -     steps: 98500  ppl: 2.5437\n",
      "08/21/2020 11:47:54 - INFO - __main__ -     steps: 98600  ppl: 2.4481\n",
      "08/21/2020 11:48:06 - INFO - __main__ -     steps: 98700  ppl: 2.4816\n",
      "08/21/2020 11:48:17 - INFO - __main__ -     steps: 98800  ppl: 2.4405\n",
      "08/21/2020 11:48:29 - INFO - __main__ -     steps: 98900  ppl: 2.529\n",
      "08/21/2020 11:48:41 - INFO - __main__ -     steps: 99000  ppl: 2.4019\n",
      "08/21/2020 11:48:52 - INFO - __main__ -     steps: 99100  ppl: 2.4574\n",
      "08/21/2020 11:49:04 - INFO - __main__ -     steps: 99200  ppl: 2.5118\n",
      "08/21/2020 11:49:15 - INFO - __main__ -     steps: 99300  ppl: 2.4624\n",
      "08/21/2020 11:49:27 - INFO - __main__ -     steps: 99400  ppl: 2.4515\n",
      "08/21/2020 11:49:39 - INFO - __main__ -     steps: 99500  ppl: 2.4891\n",
      "08/21/2020 11:49:50 - INFO - __main__ -     steps: 99600  ppl: 2.4785\n",
      "08/21/2020 11:50:02 - INFO - __main__ -     steps: 99700  ppl: 2.4501\n",
      "08/21/2020 11:50:13 - INFO - __main__ -     steps: 99800  ppl: 2.4747\n",
      "08/21/2020 11:50:24 - INFO - __main__ -     steps: 99900  ppl: 2.3787\n",
      "08/21/2020 11:50:36 - INFO - __main__ -     steps: 100000  ppl: 2.45\n",
      "08/21/2020 11:50:40 - INFO - __main__ -     perplexity = 2.3751\n",
      "08/21/2020 11:50:40 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-100000-2.3751/config.json\n",
      "08/21/2020 11:50:41 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-100000-2.3751/pytorch_model.bin\n",
      "08/21/2020 11:50:41 - INFO - __main__ -   Saving model checkpoint to Bert/saved_models/checkpoint-100000-2.3751\n",
      "08/21/2020 11:50:41 - INFO - __main__ -   Saving linear to Bert/saved_models/linear.bin\n",
      "08/21/2020 11:50:41 - INFO - __main__ -   Saving embeddings to Bert/saved_models/embeddings.bin\n",
      "08/21/2020 11:50:41 - INFO - transformers.configuration_utils -   Configuration saved in Bert/saved_models/checkpoint-last/config.json\n",
      "08/21/2020 11:50:41 - INFO - transformers.modeling_utils -   Model weights saved in Bert/saved_models/checkpoint-last/pytorch_model.bin\n",
      "08/21/2020 11:50:41 - INFO - __main__ -   Saving linear to Bert/saved_models/checkpoint-last/linear.bin\n",
      "08/21/2020 11:50:41 - INFO - __main__ -   Saving embeddings to Bert/saved_models/checkpoint-last/embeddings.bin\n",
      "08/21/2020 11:50:41 - INFO - __main__ -   Saving model to Bert/saved_models/checkpoint-last/model.bin\n",
      "08/21/2020 11:50:41 - INFO - __main__ -   Saving optimizer and scheduler states to Bert/saved_models/checkpoint-last\n"
     ]
    }
   ],
   "source": [
    "!python Bert/run.py \\\n",
    "    --output_dir Bert/saved_models \\\n",
    "    --model_type roberta \\\n",
    "    --config_name roberta-base \\\n",
    "    --mlm \\\n",
    "    --block_size 128 \\\n",
    "    --per_gpu_train_batch_size 64 \\\n",
    "    --per_gpu_eval_batch_size 64 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --learning_rate 5e-5 \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --adam_epsilon 1e-6 \\\n",
    "    --max_grad_norm 1.0 \\\n",
    "    --max_steps 100000 \\\n",
    "    --mlm_probability 0.2 \\\n",
    "    --warmup_steps 10000 \\\n",
    "    --logging_steps 50 \\\n",
    "    --save_steps 10000 \\\n",
    "    --evaluate_during_training \\\n",
    "    --save_total_limit 500 \\\n",
    "    --seed 123456 \\\n",
    "    --tensorboard_dir saved_models/tensorboard_logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRnBJctXHwV4"
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpE2nmWnNVQJ"
   },
   "outputs": [],
   "source": [
    "!cp -r saved_models/checkpoint-last bert-base\n",
    "!cp saved_models/vocab.pkl bert-base/vocab.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3864128,
     "status": "ok",
     "timestamp": 1599032447191,
     "user": {
      "displayName": "汪冉冉",
      "photoUrl": "",
      "userId": "08844405010106370208"
     },
     "user_tz": -480
    },
    "id": "BFThD14jNkMZ",
    "outputId": "5345213b-d0ba-4fc2-e2ac-08b71c2e9d65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-02 06:36:24.839998: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "09/02/2020 06:36:26 - INFO - summarizer.preprocessing.cleaner -   'pattern' package not found; tag filters are not available for English\n",
      "09/02/2020 06:36:26 - INFO - __main__ -   Argument Namespace(display_steps=100, epoch=10, eval_batch_size=512, eval_steps=5000, hidden_dropout_prob=0.1, hidden_size=384, index=1, kfold=5, lr=1e-05, max_grad_norm=1.0, max_len_text=32, num_hidden_layers=6, num_label=2, output_path='Fusionlayer/saved_models', pretrained_model_path='Bert/bert-base/checkpoint-last', seed=2020, train_batch_size=256, vocab_dim_v1=64, vocab_size_v1=500000)\n",
      "09/02/2020 06:36:26 - INFO - gensim.models.utils_any2vec -   loading projection weights from word2vecf/milestone_seq.128d\n",
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "09/02/2020 06:36:26 - INFO - gensim.models.utils_any2vec -   loading projection weights from word2vecf/CREATED_BY_seq.128d\n",
      "09/02/2020 06:36:26 - INFO - gensim.models.utils_any2vec -   loading projection weights from word2vecf/UPDATED_BY_seq.128d\n",
      "09/02/2020 06:37:23 - INFO - ctrNets -    device: cuda, n_gpu: 1\n",
      "09/02/2020 06:37:23 - INFO - transformers.configuration_utils -   loading configuration file Bert/bert-base/checkpoint-last/config.json\n",
      "09/02/2020 06:37:23 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 64,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 256,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_dim_v1\": 64,\n",
      "  \"vocab_size\": 5,\n",
      "  \"vocab_size_v1\": 1410\n",
      "}\n",
      "\n",
      "09/02/2020 06:37:23 - INFO - transformers.modeling_utils -   loading weights file Bert/bert-base/checkpoint-last/pytorch_model.bin\n",
      "09/02/2020 06:37:23 - INFO - model -   Load linear from Bert/bert-base/checkpoint-last/linear.bin\n",
      "09/02/2020 06:37:36 - INFO - model -   Load embeddings from Bert/bert-base/checkpoint-last/embeddings.bin\n",
      "09/02/2020 06:37:36 - INFO - __main__ -   Index: 1\n",
      "09/02/2020 06:37:37 - INFO - ctrNets -   ***** Running training *****\n",
      "09/02/2020 06:37:37 - INFO - ctrNets -     Num examples = 566560\n",
      "09/02/2020 06:37:37 - INFO - ctrNets -     Num Epochs = 10\n",
      "09/02/2020 06:37:37 - INFO - ctrNets -     Instantaneous batch size per GPU = 256\n",
      "09/02/2020 06:37:37 - INFO - ctrNets -     Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "09/02/2020 06:37:37 - INFO - ctrNets -     Total optimization steps = 22140\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
      "09/02/2020 06:37:53 - INFO - ctrNets -     epoch 0 step 100 loss 2509.30399\n",
      "09/02/2020 06:38:07 - INFO - ctrNets -     epoch 0 step 200 loss 2483.37906\n",
      "09/02/2020 06:38:22 - INFO - ctrNets -     epoch 0 step 300 loss 2438.30378\n",
      "09/02/2020 06:38:37 - INFO - ctrNets -     epoch 0 step 400 loss 2406.47331\n",
      "09/02/2020 06:38:51 - INFO - ctrNets -     epoch 0 step 500 loss 2364.785\n",
      "09/02/2020 06:39:06 - INFO - ctrNets -     epoch 0 step 600 loss 2341.44081\n",
      "09/02/2020 06:39:20 - INFO - ctrNets -     epoch 0 step 700 loss 2312.58029\n",
      "09/02/2020 06:39:35 - INFO - ctrNets -     epoch 0 step 800 loss 2272.15182\n",
      "09/02/2020 06:39:49 - INFO - ctrNets -     epoch 0 step 900 loss 2227.53242\n",
      "09/02/2020 06:40:03 - INFO - ctrNets -     epoch 0 step 1000 loss 2178.71555\n",
      "09/02/2020 06:40:18 - INFO - ctrNets -     epoch 0 step 1100 loss 2144.6809\n",
      "09/02/2020 06:40:32 - INFO - ctrNets -     epoch 0 step 1200 loss 2101.89448\n",
      "09/02/2020 06:40:47 - INFO - ctrNets -     epoch 0 step 1300 loss 2079.33232\n",
      "09/02/2020 06:41:01 - INFO - ctrNets -     epoch 0 step 1400 loss 2052.70412\n",
      "09/02/2020 06:41:15 - INFO - ctrNets -     epoch 0 step 1500 loss 2026.1096\n",
      "09/02/2020 06:41:30 - INFO - ctrNets -     epoch 0 step 1600 loss 2004.62151\n",
      "09/02/2020 06:41:44 - INFO - ctrNets -     epoch 0 step 1700 loss 1986.60385\n",
      "09/02/2020 06:41:59 - INFO - ctrNets -     epoch 0 step 1800 loss 1972.19366\n",
      "09/02/2020 06:42:13 - INFO - ctrNets -     epoch 0 step 1900 loss 1958.23515\n",
      "09/02/2020 06:42:27 - INFO - ctrNets -     epoch 0 step 2000 loss 1943.01155\n",
      "09/02/2020 06:42:42 - INFO - ctrNets -     epoch 0 step 2100 loss 1925.75166\n",
      "09/02/2020 06:42:56 - INFO - ctrNets -     epoch 0 step 2200 loss 1915.29225\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 06:43:51 - INFO - ctrNets -     eval_mse_loss = 0.0256\n",
      "09/02/2020 06:43:51 - INFO - ctrNets -     eval_R2 = -0.0285\n",
      "09/02/2020 06:43:51 - INFO - ctrNets -     ********************\n",
      "09/02/2020 06:43:51 - INFO - ctrNets -     Best R2:-0.0285\n",
      "09/02/2020 06:43:51 - INFO - ctrNets -     ********************\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 06:44:09 - INFO - ctrNets -     epoch 1 step 100 loss 1594.15521\n",
      "09/02/2020 06:44:24 - INFO - ctrNets -     epoch 1 step 200 loss 1685.99789\n",
      "09/02/2020 06:44:38 - INFO - ctrNets -     epoch 1 step 300 loss 1664.22649\n",
      "09/02/2020 06:44:53 - INFO - ctrNets -     epoch 1 step 400 loss 1642.33978\n",
      "09/02/2020 06:45:07 - INFO - ctrNets -     epoch 1 step 500 loss 1652.08782\n",
      "09/02/2020 06:45:22 - INFO - ctrNets -     epoch 1 step 600 loss 1668.82875\n",
      "09/02/2020 06:45:36 - INFO - ctrNets -     epoch 1 step 700 loss 1653.95348\n",
      "09/02/2020 06:45:51 - INFO - ctrNets -     epoch 1 step 800 loss 1631.7568\n",
      "09/02/2020 06:46:05 - INFO - ctrNets -     epoch 1 step 900 loss 1642.05748\n",
      "09/02/2020 06:46:19 - INFO - ctrNets -     epoch 1 step 1000 loss 1633.02579\n",
      "09/02/2020 06:46:34 - INFO - ctrNets -     epoch 1 step 1100 loss 1635.87116\n",
      "09/02/2020 06:46:49 - INFO - ctrNets -     epoch 1 step 1200 loss 1641.73865\n",
      "09/02/2020 06:47:03 - INFO - ctrNets -     epoch 1 step 1300 loss 1644.59501\n",
      "09/02/2020 06:47:18 - INFO - ctrNets -     epoch 1 step 1400 loss 1650.72365\n",
      "09/02/2020 06:47:32 - INFO - ctrNets -     epoch 1 step 1500 loss 1650.25998\n",
      "09/02/2020 06:47:46 - INFO - ctrNets -     epoch 1 step 1600 loss 1654.04921\n",
      "09/02/2020 06:48:01 - INFO - ctrNets -     epoch 1 step 1700 loss 1660.71325\n",
      "09/02/2020 06:48:15 - INFO - ctrNets -     epoch 1 step 1800 loss 1665.21873\n",
      "09/02/2020 06:48:30 - INFO - ctrNets -     epoch 1 step 1900 loss 1668.41095\n",
      "09/02/2020 06:48:44 - INFO - ctrNets -     epoch 1 step 2000 loss 1664.30292\n",
      "09/02/2020 06:48:59 - INFO - ctrNets -     epoch 1 step 2100 loss 1666.75663\n",
      "09/02/2020 06:49:13 - INFO - ctrNets -     epoch 1 step 2200 loss 1664.60681\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 06:50:08 - INFO - ctrNets -     eval_mse_loss = 0.0256\n",
      "09/02/2020 06:50:08 - INFO - ctrNets -     eval_R2 = -0.0289\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 06:50:24 - INFO - ctrNets -     epoch 2 step 100 loss 1719.10467\n",
      "09/02/2020 06:50:39 - INFO - ctrNets -     epoch 2 step 200 loss 1695.96877\n",
      "09/02/2020 06:50:53 - INFO - ctrNets -     epoch 2 step 300 loss 1643.18199\n",
      "09/02/2020 06:51:08 - INFO - ctrNets -     epoch 2 step 400 loss 1652.35595\n",
      "09/02/2020 06:51:23 - INFO - ctrNets -     epoch 2 step 500 loss 1677.92334\n",
      "09/02/2020 06:51:37 - INFO - ctrNets -     epoch 2 step 600 loss 1685.76193\n",
      "09/02/2020 06:51:51 - INFO - ctrNets -     epoch 2 step 700 loss 1681.12506\n",
      "09/02/2020 06:52:06 - INFO - ctrNets -     epoch 2 step 800 loss 1666.89659\n",
      "09/02/2020 06:52:20 - INFO - ctrNets -     epoch 2 step 900 loss 1658.46479\n",
      "09/02/2020 06:52:34 - INFO - ctrNets -     epoch 2 step 1000 loss 1657.57276\n",
      "09/02/2020 06:52:49 - INFO - ctrNets -     epoch 2 step 1100 loss 1652.15923\n",
      "09/02/2020 06:53:04 - INFO - ctrNets -     epoch 2 step 1200 loss 1656.34588\n",
      "09/02/2020 06:53:18 - INFO - ctrNets -     epoch 2 step 1300 loss 1654.41591\n",
      "09/02/2020 06:53:32 - INFO - ctrNets -     epoch 2 step 1400 loss 1652.27567\n",
      "09/02/2020 06:53:47 - INFO - ctrNets -     epoch 2 step 1500 loss 1649.25618\n",
      "09/02/2020 06:54:01 - INFO - ctrNets -     epoch 2 step 1600 loss 1648.64379\n",
      "09/02/2020 06:54:15 - INFO - ctrNets -     epoch 2 step 1700 loss 1651.17337\n",
      "09/02/2020 06:54:29 - INFO - ctrNets -     epoch 2 step 1800 loss 1649.81165\n",
      "09/02/2020 06:54:44 - INFO - ctrNets -     epoch 2 step 1900 loss 1651.72009\n",
      "09/02/2020 06:54:58 - INFO - ctrNets -     epoch 2 step 2000 loss 1650.10473\n",
      "09/02/2020 06:55:13 - INFO - ctrNets -     epoch 2 step 2100 loss 1658.18409\n",
      "09/02/2020 06:55:27 - INFO - ctrNets -     epoch 2 step 2200 loss 1658.26386\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 06:56:22 - INFO - ctrNets -     eval_mse_loss = 0.0251\n",
      "09/02/2020 06:56:22 - INFO - ctrNets -     eval_R2 = -0.0069\n",
      "09/02/2020 06:56:22 - INFO - ctrNets -     ********************\n",
      "09/02/2020 06:56:22 - INFO - ctrNets -     Best R2:-0.0069\n",
      "09/02/2020 06:56:22 - INFO - ctrNets -     ********************\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 06:56:37 - INFO - ctrNets -     epoch 3 step 100 loss 1674.08515\n",
      "09/02/2020 06:56:52 - INFO - ctrNets -     epoch 3 step 200 loss 1697.65157\n",
      "09/02/2020 06:57:07 - INFO - ctrNets -     epoch 3 step 300 loss 1663.00126\n",
      "09/02/2020 06:57:21 - INFO - ctrNets -     epoch 3 step 400 loss 1657.33659\n",
      "09/02/2020 06:57:36 - INFO - ctrNets -     epoch 3 step 500 loss 1657.43117\n",
      "09/02/2020 06:57:50 - INFO - ctrNets -     epoch 3 step 600 loss 1672.27468\n",
      "09/02/2020 06:58:05 - INFO - ctrNets -     epoch 3 step 700 loss 1663.97499\n",
      "09/02/2020 06:58:19 - INFO - ctrNets -     epoch 3 step 800 loss 1656.96328\n",
      "09/02/2020 06:58:34 - INFO - ctrNets -     epoch 3 step 900 loss 1653.75542\n",
      "09/02/2020 06:58:48 - INFO - ctrNets -     epoch 3 step 1000 loss 1647.92183\n",
      "09/02/2020 06:59:03 - INFO - ctrNets -     epoch 3 step 1100 loss 1643.67465\n",
      "09/02/2020 06:59:17 - INFO - ctrNets -     epoch 3 step 1200 loss 1638.43505\n",
      "09/02/2020 06:59:31 - INFO - ctrNets -     epoch 3 step 1300 loss 1638.52772\n",
      "09/02/2020 06:59:45 - INFO - ctrNets -     epoch 3 step 1400 loss 1637.71017\n",
      "09/02/2020 07:00:00 - INFO - ctrNets -     epoch 3 step 1500 loss 1637.71567\n",
      "09/02/2020 07:00:14 - INFO - ctrNets -     epoch 3 step 1600 loss 1639.80758\n",
      "09/02/2020 07:00:28 - INFO - ctrNets -     epoch 3 step 1700 loss 1642.30463\n",
      "09/02/2020 07:00:43 - INFO - ctrNets -     epoch 3 step 1800 loss 1639.71972\n",
      "09/02/2020 07:00:57 - INFO - ctrNets -     epoch 3 step 1900 loss 1636.43542\n",
      "09/02/2020 07:01:11 - INFO - ctrNets -     epoch 3 step 2000 loss 1635.34184\n",
      "09/02/2020 07:01:26 - INFO - ctrNets -     epoch 3 step 2100 loss 1634.72391\n",
      "09/02/2020 07:01:40 - INFO - ctrNets -     epoch 3 step 2200 loss 1638.11975\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:02:35 - INFO - ctrNets -     eval_mse_loss = 0.025\n",
      "09/02/2020 07:02:35 - INFO - ctrNets -     eval_R2 = -0.0029\n",
      "09/02/2020 07:02:35 - INFO - ctrNets -     ********************\n",
      "09/02/2020 07:02:35 - INFO - ctrNets -     Best R2:-0.0029\n",
      "09/02/2020 07:02:35 - INFO - ctrNets -     ********************\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:02:51 - INFO - ctrNets -     epoch 4 step 100 loss 1555.11574\n",
      "09/02/2020 07:03:05 - INFO - ctrNets -     epoch 4 step 200 loss 1547.11226\n",
      "09/02/2020 07:03:20 - INFO - ctrNets -     epoch 4 step 300 loss 1567.48235\n",
      "09/02/2020 07:03:35 - INFO - ctrNets -     epoch 4 step 400 loss 1565.39706\n",
      "09/02/2020 07:03:49 - INFO - ctrNets -     epoch 4 step 500 loss 1599.51756\n",
      "09/02/2020 07:04:03 - INFO - ctrNets -     epoch 4 step 600 loss 1624.84276\n",
      "09/02/2020 07:04:18 - INFO - ctrNets -     epoch 4 step 700 loss 1616.40919\n",
      "09/02/2020 07:04:32 - INFO - ctrNets -     epoch 4 step 800 loss 1615.73247\n",
      "09/02/2020 07:04:46 - INFO - ctrNets -     epoch 4 step 900 loss 1614.10693\n",
      "09/02/2020 07:05:01 - INFO - ctrNets -     epoch 4 step 1000 loss 1608.91982\n",
      "09/02/2020 07:05:15 - INFO - ctrNets -     epoch 4 step 1100 loss 1612.40395\n",
      "09/02/2020 07:05:30 - INFO - ctrNets -     epoch 4 step 1200 loss 1619.93822\n",
      "09/02/2020 07:05:44 - INFO - ctrNets -     epoch 4 step 1300 loss 1623.80176\n",
      "09/02/2020 07:05:58 - INFO - ctrNets -     epoch 4 step 1400 loss 1628.61858\n",
      "09/02/2020 07:06:12 - INFO - ctrNets -     epoch 4 step 1500 loss 1628.63738\n",
      "09/02/2020 07:06:27 - INFO - ctrNets -     epoch 4 step 1600 loss 1632.56708\n",
      "09/02/2020 07:06:41 - INFO - ctrNets -     epoch 4 step 1700 loss 1633.25208\n",
      "09/02/2020 07:06:55 - INFO - ctrNets -     epoch 4 step 1800 loss 1627.01663\n",
      "09/02/2020 07:07:10 - INFO - ctrNets -     epoch 4 step 1900 loss 1624.82397\n",
      "09/02/2020 07:07:24 - INFO - ctrNets -     epoch 4 step 2000 loss 1630.35974\n",
      "09/02/2020 07:07:39 - INFO - ctrNets -     epoch 4 step 2100 loss 1631.95972\n",
      "09/02/2020 07:07:53 - INFO - ctrNets -     epoch 4 step 2200 loss 1628.82929\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:08:47 - INFO - ctrNets -     eval_mse_loss = 0.0249\n",
      "09/02/2020 07:08:47 - INFO - ctrNets -     eval_R2 = -0.0005\n",
      "09/02/2020 07:08:47 - INFO - ctrNets -     ********************\n",
      "09/02/2020 07:08:47 - INFO - ctrNets -     Best R2:-0.0005\n",
      "09/02/2020 07:08:47 - INFO - ctrNets -     ********************\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:09:03 - INFO - ctrNets -     epoch 5 step 100 loss 1610.25709\n",
      "09/02/2020 07:09:18 - INFO - ctrNets -     epoch 5 step 200 loss 1610.8655\n",
      "09/02/2020 07:09:32 - INFO - ctrNets -     epoch 5 step 300 loss 1605.46967\n",
      "09/02/2020 07:09:47 - INFO - ctrNets -     epoch 5 step 400 loss 1619.82643\n",
      "09/02/2020 07:10:01 - INFO - ctrNets -     epoch 5 step 500 loss 1614.40604\n",
      "09/02/2020 07:10:15 - INFO - ctrNets -     epoch 5 step 600 loss 1600.08654\n",
      "09/02/2020 07:10:30 - INFO - ctrNets -     epoch 5 step 700 loss 1593.66038\n",
      "09/02/2020 07:10:44 - INFO - ctrNets -     epoch 5 step 800 loss 1591.42013\n",
      "09/02/2020 07:10:59 - INFO - ctrNets -     epoch 5 step 900 loss 1593.19818\n",
      "09/02/2020 07:11:13 - INFO - ctrNets -     epoch 5 step 1000 loss 1602.62362\n",
      "09/02/2020 07:11:27 - INFO - ctrNets -     epoch 5 step 1100 loss 1605.11516\n",
      "09/02/2020 07:11:41 - INFO - ctrNets -     epoch 5 step 1200 loss 1612.8743\n",
      "09/02/2020 07:11:56 - INFO - ctrNets -     epoch 5 step 1300 loss 1622.1581\n",
      "09/02/2020 07:12:10 - INFO - ctrNets -     epoch 5 step 1400 loss 1626.29978\n",
      "09/02/2020 07:12:24 - INFO - ctrNets -     epoch 5 step 1500 loss 1631.03959\n",
      "09/02/2020 07:12:38 - INFO - ctrNets -     epoch 5 step 1600 loss 1625.79857\n",
      "09/02/2020 07:12:53 - INFO - ctrNets -     epoch 5 step 1700 loss 1626.24734\n",
      "09/02/2020 07:13:07 - INFO - ctrNets -     epoch 5 step 1800 loss 1624.45955\n",
      "09/02/2020 07:13:22 - INFO - ctrNets -     epoch 5 step 1900 loss 1624.94591\n",
      "09/02/2020 07:13:36 - INFO - ctrNets -     epoch 5 step 2000 loss 1621.6311\n",
      "09/02/2020 07:13:50 - INFO - ctrNets -     epoch 5 step 2100 loss 1625.69965\n",
      "09/02/2020 07:14:05 - INFO - ctrNets -     epoch 5 step 2200 loss 1624.61058\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:14:59 - INFO - ctrNets -     eval_mse_loss = 0.0248\n",
      "09/02/2020 07:14:59 - INFO - ctrNets -     eval_R2 = 0.0016\n",
      "09/02/2020 07:14:59 - INFO - ctrNets -     ********************\n",
      "09/02/2020 07:14:59 - INFO - ctrNets -     Best R2:0.0016\n",
      "09/02/2020 07:14:59 - INFO - ctrNets -     ********************\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:15:15 - INFO - ctrNets -     epoch 6 step 100 loss 1651.11154\n",
      "09/02/2020 07:15:30 - INFO - ctrNets -     epoch 6 step 200 loss 1622.2477\n",
      "09/02/2020 07:15:44 - INFO - ctrNets -     epoch 6 step 300 loss 1623.62788\n",
      "09/02/2020 07:15:59 - INFO - ctrNets -     epoch 6 step 400 loss 1609.54854\n",
      "09/02/2020 07:16:13 - INFO - ctrNets -     epoch 6 step 500 loss 1600.33762\n",
      "09/02/2020 07:16:28 - INFO - ctrNets -     epoch 6 step 600 loss 1595.80717\n",
      "09/02/2020 07:16:42 - INFO - ctrNets -     epoch 6 step 700 loss 1603.247\n",
      "09/02/2020 07:16:56 - INFO - ctrNets -     epoch 6 step 800 loss 1609.46594\n",
      "09/02/2020 07:17:11 - INFO - ctrNets -     epoch 6 step 900 loss 1601.43306\n",
      "09/02/2020 07:17:25 - INFO - ctrNets -     epoch 6 step 1000 loss 1605.54305\n",
      "09/02/2020 07:17:39 - INFO - ctrNets -     epoch 6 step 1100 loss 1597.53584\n",
      "09/02/2020 07:17:53 - INFO - ctrNets -     epoch 6 step 1200 loss 1601.80481\n",
      "09/02/2020 07:18:08 - INFO - ctrNets -     epoch 6 step 1300 loss 1606.22272\n",
      "09/02/2020 07:18:22 - INFO - ctrNets -     epoch 6 step 1400 loss 1610.93511\n",
      "09/02/2020 07:18:36 - INFO - ctrNets -     epoch 6 step 1500 loss 1611.15038\n",
      "09/02/2020 07:18:51 - INFO - ctrNets -     epoch 6 step 1600 loss 1613.49327\n",
      "09/02/2020 07:19:05 - INFO - ctrNets -     epoch 6 step 1700 loss 1609.57349\n",
      "09/02/2020 07:19:19 - INFO - ctrNets -     epoch 6 step 1800 loss 1611.12701\n",
      "09/02/2020 07:19:33 - INFO - ctrNets -     epoch 6 step 1900 loss 1611.10242\n",
      "09/02/2020 07:19:48 - INFO - ctrNets -     epoch 6 step 2000 loss 1614.45972\n",
      "09/02/2020 07:20:02 - INFO - ctrNets -     epoch 6 step 2100 loss 1618.6042\n",
      "09/02/2020 07:20:16 - INFO - ctrNets -     epoch 6 step 2200 loss 1623.69982\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:21:10 - INFO - ctrNets -     eval_mse_loss = 0.0249\n",
      "09/02/2020 07:21:10 - INFO - ctrNets -     eval_R2 = 0.0005\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:21:26 - INFO - ctrNets -     epoch 7 step 100 loss 1689.22489\n",
      "09/02/2020 07:21:41 - INFO - ctrNets -     epoch 7 step 200 loss 1613.12965\n",
      "09/02/2020 07:21:55 - INFO - ctrNets -     epoch 7 step 300 loss 1616.24848\n",
      "09/02/2020 07:22:10 - INFO - ctrNets -     epoch 7 step 400 loss 1631.93224\n",
      "09/02/2020 07:22:24 - INFO - ctrNets -     epoch 7 step 500 loss 1623.81243\n",
      "09/02/2020 07:22:39 - INFO - ctrNets -     epoch 7 step 600 loss 1606.07194\n",
      "09/02/2020 07:22:53 - INFO - ctrNets -     epoch 7 step 700 loss 1621.27656\n",
      "09/02/2020 07:23:07 - INFO - ctrNets -     epoch 7 step 800 loss 1607.77286\n",
      "09/02/2020 07:23:22 - INFO - ctrNets -     epoch 7 step 900 loss 1616.68017\n",
      "09/02/2020 07:23:36 - INFO - ctrNets -     epoch 7 step 1000 loss 1605.61619\n",
      "09/02/2020 07:23:50 - INFO - ctrNets -     epoch 7 step 1100 loss 1613.94522\n",
      "09/02/2020 07:24:04 - INFO - ctrNets -     epoch 7 step 1200 loss 1618.93215\n",
      "09/02/2020 07:24:19 - INFO - ctrNets -     epoch 7 step 1300 loss 1624.95674\n",
      "09/02/2020 07:24:33 - INFO - ctrNets -     epoch 7 step 1400 loss 1627.45811\n",
      "09/02/2020 07:24:47 - INFO - ctrNets -     epoch 7 step 1500 loss 1625.10838\n",
      "09/02/2020 07:25:01 - INFO - ctrNets -     epoch 7 step 1600 loss 1624.31491\n",
      "09/02/2020 07:25:16 - INFO - ctrNets -     epoch 7 step 1700 loss 1622.41772\n",
      "09/02/2020 07:25:30 - INFO - ctrNets -     epoch 7 step 1800 loss 1622.36899\n",
      "09/02/2020 07:25:44 - INFO - ctrNets -     epoch 7 step 1900 loss 1617.41229\n",
      "09/02/2020 07:25:59 - INFO - ctrNets -     epoch 7 step 2000 loss 1615.94514\n",
      "09/02/2020 07:26:13 - INFO - ctrNets -     epoch 7 step 2100 loss 1620.15462\n",
      "09/02/2020 07:26:27 - INFO - ctrNets -     epoch 7 step 2200 loss 1623.29\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:27:22 - INFO - ctrNets -     eval_mse_loss = 0.0249\n",
      "09/02/2020 07:27:22 - INFO - ctrNets -     eval_R2 = 0.001\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:27:37 - INFO - ctrNets -     epoch 8 step 100 loss 1632.59812\n",
      "09/02/2020 07:27:52 - INFO - ctrNets -     epoch 8 step 200 loss 1660.83849\n",
      "09/02/2020 07:28:06 - INFO - ctrNets -     epoch 8 step 300 loss 1632.29143\n",
      "09/02/2020 07:28:21 - INFO - ctrNets -     epoch 8 step 400 loss 1637.35838\n",
      "09/02/2020 07:28:36 - INFO - ctrNets -     epoch 8 step 500 loss 1631.26177\n",
      "09/02/2020 07:28:50 - INFO - ctrNets -     epoch 8 step 600 loss 1636.73623\n",
      "09/02/2020 07:29:04 - INFO - ctrNets -     epoch 8 step 700 loss 1645.61547\n",
      "09/02/2020 07:29:19 - INFO - ctrNets -     epoch 8 step 800 loss 1647.50059\n",
      "09/02/2020 07:29:33 - INFO - ctrNets -     epoch 8 step 900 loss 1639.67671\n",
      "09/02/2020 07:29:48 - INFO - ctrNets -     epoch 8 step 1000 loss 1637.68365\n",
      "09/02/2020 07:30:02 - INFO - ctrNets -     epoch 8 step 1100 loss 1641.35216\n",
      "09/02/2020 07:30:16 - INFO - ctrNets -     epoch 8 step 1200 loss 1637.58638\n",
      "09/02/2020 07:30:31 - INFO - ctrNets -     epoch 8 step 1300 loss 1628.07195\n",
      "09/02/2020 07:30:45 - INFO - ctrNets -     epoch 8 step 1400 loss 1618.58837\n",
      "09/02/2020 07:30:59 - INFO - ctrNets -     epoch 8 step 1500 loss 1618.52117\n",
      "09/02/2020 07:31:13 - INFO - ctrNets -     epoch 8 step 1600 loss 1621.67757\n",
      "09/02/2020 07:31:28 - INFO - ctrNets -     epoch 8 step 1700 loss 1627.27746\n",
      "09/02/2020 07:31:42 - INFO - ctrNets -     epoch 8 step 1800 loss 1621.68783\n",
      "09/02/2020 07:31:56 - INFO - ctrNets -     epoch 8 step 1900 loss 1623.33415\n",
      "09/02/2020 07:32:11 - INFO - ctrNets -     epoch 8 step 2000 loss 1621.21489\n",
      "09/02/2020 07:32:25 - INFO - ctrNets -     epoch 8 step 2100 loss 1618.7966\n",
      "09/02/2020 07:32:39 - INFO - ctrNets -     epoch 8 step 2200 loss 1621.79432\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:33:34 - INFO - ctrNets -     eval_mse_loss = 0.0249\n",
      "09/02/2020 07:33:34 - INFO - ctrNets -     eval_R2 = 0.0009\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:33:50 - INFO - ctrNets -     epoch 9 step 100 loss 1605.61396\n",
      "09/02/2020 07:34:04 - INFO - ctrNets -     epoch 9 step 200 loss 1596.86293\n",
      "09/02/2020 07:34:19 - INFO - ctrNets -     epoch 9 step 300 loss 1571.53162\n",
      "09/02/2020 07:34:34 - INFO - ctrNets -     epoch 9 step 400 loss 1575.27429\n",
      "09/02/2020 07:34:48 - INFO - ctrNets -     epoch 9 step 500 loss 1585.13988\n",
      "09/02/2020 07:35:03 - INFO - ctrNets -     epoch 9 step 600 loss 1595.91364\n",
      "09/02/2020 07:35:17 - INFO - ctrNets -     epoch 9 step 700 loss 1614.86395\n",
      "09/02/2020 07:35:31 - INFO - ctrNets -     epoch 9 step 800 loss 1614.12935\n",
      "09/02/2020 07:35:46 - INFO - ctrNets -     epoch 9 step 900 loss 1611.62663\n",
      "09/02/2020 07:36:00 - INFO - ctrNets -     epoch 9 step 1000 loss 1625.42305\n",
      "09/02/2020 07:36:14 - INFO - ctrNets -     epoch 9 step 1100 loss 1618.74885\n",
      "09/02/2020 07:36:29 - INFO - ctrNets -     epoch 9 step 1200 loss 1616.2769\n",
      "09/02/2020 07:36:43 - INFO - ctrNets -     epoch 9 step 1300 loss 1624.64035\n",
      "09/02/2020 07:36:57 - INFO - ctrNets -     epoch 9 step 1400 loss 1630.24758\n",
      "09/02/2020 07:37:12 - INFO - ctrNets -     epoch 9 step 1500 loss 1630.4226\n",
      "09/02/2020 07:37:26 - INFO - ctrNets -     epoch 9 step 1600 loss 1626.32946\n",
      "09/02/2020 07:37:40 - INFO - ctrNets -     epoch 9 step 1700 loss 1625.07905\n",
      "09/02/2020 07:37:55 - INFO - ctrNets -     epoch 9 step 1800 loss 1621.89244\n",
      "09/02/2020 07:38:09 - INFO - ctrNets -     epoch 9 step 1900 loss 1624.02192\n",
      "09/02/2020 07:38:23 - INFO - ctrNets -     epoch 9 step 2000 loss 1622.03164\n",
      "09/02/2020 07:38:37 - INFO - ctrNets -     epoch 9 step 2100 loss 1622.9504\n",
      "09/02/2020 07:38:52 - INFO - ctrNets -     epoch 9 step 2200 loss 1623.31023\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "09/02/2020 07:39:47 - INFO - ctrNets -     eval_mse_loss = 0.0249\n",
      "09/02/2020 07:39:47 - INFO - ctrNets -     eval_R2 = 0.0007\n",
      "09/02/2020 07:39:47 - INFO - ctrNets -   Load model from Fusionlayer/saved_models/index_1/pytorch_model_escalated.bin\n",
      "Fusionlayer/mymain.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_df['{}_{}'.format(f,num)]=dev_preds\n",
      "09/02/2020 07:40:44 - INFO - __main__ -   Test escalated [nan]\n",
      "09/02/2020 07:40:44 - INFO - __main__ -   R2 escalated 0.00165\n",
      "mkdir: cannot create directory ‘submission’: File exists\n",
      "09/02/2020 07:40:44 - INFO - __main__ -     best_r2 = 0.0016\n"
     ]
    }
   ],
   "source": [
    "!python Fusionlayer/mymain.py \\\n",
    "      --kfold=5 \\\n",
    "      --index=1 \\\n",
    "      --train_batch_size=256 \\\n",
    "      --eval_steps=5000 \\\n",
    "      --max_len_text=32\\\n",
    "      --epoch=10 \\\n",
    "      --lr=1e-5 \\\n",
    "      --output_path=Fusionlayer/saved_models \\\n",
    "      --pretrained_model_path=Bert/bert-base/checkpoint-last \\\n",
    "      --eval_batch_size=512 2>&1 | tee Fusionlayer/saved_models/log/i.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fFQABCIDwf_c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "res=pd.read_csv('result/submission_test_escalated_1_000165.csv')\n",
    "res.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTuVsm8eNITc"
   },
   "outputs": [],
   "source": [
    "pp=[]\n",
    "for p in res['predict_escalated']:\n",
    "    if p<=0:\n",
    "        pp.append(0)\n",
    "    elif p>1:\n",
    "        pp.append(1)\n",
    "    else:\n",
    "        pp.append(p)\n",
    "res['label_tensor']=pp\n",
    "res[['label_tensor']].to_csv('result/tensor.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVPUDD2XjKX1"
   },
   "outputs": [],
   "source": [
    "res['predict_escalated'].to_csv('result/pytorch1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mH5FRG09vcPl"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNDP/9QpDNnFrrt9WO33zpy",
   "collapsed_sections": [],
   "name": "mytransformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
